{
    "problems": [
        {
            "superproblems": [
                "Abstract strategy games"
            ], 
            "name": "Superhuman mastery of arbitrary abstract strategy games", 
            "url": null, 
            "subproblems": [], 
            "metrics": [
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/strategy_games.py#L63", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "mastering chess", 
                    "parent": "Problem(Superhuman mastery of arbitrary abstract strategy games)", 
                    "url": null, 
                    "notes": "\n  Beating all humans at chess, given a corpus of past play amongst masters,\n  but no human-crafted policy constraints and heuristics. This will probably fall out\n  immediately once learning_abstract_game_rules is solved, since playing_with_hints\n  has been solved.\n", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }
            ], 
            "solved": false, 
            "attributes": [
                "super", 
                "abstract-games"
            ]
        }, 
        {
            "superproblems": [
                "Abstract strategy games"
            ], 
            "name": "Play an arbitrary abstract game, first learning the rules", 
            "url": null, 
            "subproblems": [], 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "agi", 
                "abstract-games"
            ]
        }, 
        {
            "superproblems": [
                "Given an arbitrary technical problem, solve it as well as a typical professional in that field"
            ], 
            "name": "Solve technical problems with clear constraints (proofs, circuit design, aerofoil design, etc)", 
            "url": null, 
            "subproblems": [
                "Given examples of proofs, find correct proofs of simple mathematical theorems", 
                "Given desired circuit characteristics, and many examples, design new circuits to spec"
            ], 
            "metrics": [], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [
                "Know how to build general AI agents that will behave as expected"
            ], 
            "name": "Know how to prevent an autonomous AI agent from reproducing itself an unbounded number of times", 
            "url": null, 
            "subproblems": [], 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "safety"
            ]
        }, 
        {
            "superproblems": [
                "Transfer learning: apply relevant knowledge from a prior setting to a new slightly different one"
            ], 
            "name": "Transfer of learning within simple arcade game paradigms", 
            "url": null, 
            "subproblems": [], 
            "metrics": [], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [], 
            "name": "Train machine learning systems on private user data, without transferring sensitive facts into the model", 
            "url": null, 
            "subproblems": [], 
            "metrics": [
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-38-7db95217a73d>#L2", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Federated Learning (distributed training with thresholded updates to models)", 
                    "parent": "Problem(Train machine learning systems on private user data, without transferring sensitive facts into the model)", 
                    "url": "https://arxiv.org/abs/1602.05629", 
                    "notes": "", 
                    "measures": [], 
                    "solved": true, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }
            ], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [
                "Vision"
            ], 
            "name": "Recognise events in videos", 
            "url": null, 
            "subproblems": [], 
            "metrics": [
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/vision.py#L36", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "YouTube-8M video labelling", 
                    "parent": "Problem(Recognise events in videos)", 
                    "url": "https://research.google.com/youtube8m/", 
                    "notes": "", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }
            ], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [
                "Know how to build general AI agents that will behave as expected"
            ], 
            "name": "Avoiding reward hacking", 
            "url": "https://arxiv.org/abs/1606.06565", 
            "subproblems": [], 
            "notes": "\nHumans have only partial resistance to reward hacking.\nAddiction seems to be one failure to exhibit this resistance.\nAvoiding learning something because it might make us feel bad, or even building elaborate systems of self-deception, are also sometimes\nseen in humans. So this problem is not tagged \"agi\".\n", 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "safety"
            ]
        }, 
        {
            "superproblems": [
                "Be able to generate complex scene e.g. a baboon receiving their degree at convocatoin."
            ], 
            "name": "Drawing pictures", 
            "url": null, 
            "subproblems": [], 
            "metrics": [
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/generative.py#L31", 
                    "scale": "Model Entropy", 
                    "target_label": null, 
                    "name": "Generative models of CIFAR-10 images", 
                    "parent": "Problem(Drawing pictures)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4.48, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "NICE", 
                            "minval": 4.48, 
                            "url": "https://arxiv.org/abs/1410.8516", 
                            "papername": "NICE: Non-linear Independent Components Estimation", 
                            "value": 4.48, 
                            "label": "NICE", 
                            "algorithm_src_url": "", 
                            "date": "2014-10-30", 
                            "algorithms": [], 
                            "max_date": "2015-04-10", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-10-30", 
                            "notes": "", 
                            "metric": "Metric(Generative models of CIFAR-10 images)                ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4.13, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DRAW", 
                            "minval": 4.13, 
                            "url": "https://arxiv.org/abs/1502.04623", 
                            "papername": "DRAW: A Recurrent Neural Network For Image Generation", 
                            "value": 4.13, 
                            "label": "DRAW", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-16", 
                            "algorithms": [], 
                            "max_date": "2015-05-20", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-02-16", 
                            "notes": "", 
                            "metric": "Metric(Generative models of CIFAR-10 images)                ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3.49, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Real NVP", 
                            "minval": 3.49, 
                            "url": "https://arxiv.org/abs/1605.08803", 
                            "papername": "Density estimation using Real NVP", 
                            "value": 3.49, 
                            "label": "Real NVP", 
                            "algorithm_src_url": "", 
                            "date": "2016-05-27", 
                            "algorithms": [], 
                            "max_date": "2017-02-27", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-05-27", 
                            "notes": "", 
                            "metric": "Metric(Generative models of CIFAR-10 images)                ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "PixelRNN", 
                            "minval": 3.0, 
                            "url": "https://arxiv.org/abs/1605.08803", 
                            "papername": "Density estimation using Real NVP", 
                            "value": 3.0, 
                            "label": "PixelRNN", 
                            "algorithm_src_url": "", 
                            "date": "2016-05-27", 
                            "algorithms": [], 
                            "max_date": "2017-02-27", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-05-27", 
                            "notes": "", 
                            "metric": "Metric(Generative models of CIFAR-10 images)                ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3.11, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "VAE with IAF", 
                            "minval": 3.11, 
                            "url": "https://papers.nips.cc/paper/6581-improved-variational-inference-with-inverse-autoregressive-flow", 
                            "papername": "Improved Variational Inference with Inverse Autoregressive Flow", 
                            "value": 3.11, 
                            "label": "VAE with IAF", 
                            "algorithm_src_url": "", 
                            "date": "2016-06-15", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Generative models of CIFAR-10 images)                ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2.92, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "PixelCNN++", 
                            "minval": 2.92, 
                            "url": "https://openreview.net/forum?id=BJrFC6ceg", 
                            "papername": "Forum | OpenReview", 
                            "value": 2.92, 
                            "label": "PixelCNN++", 
                            "algorithm_src_url": "", 
                            "date": "2016-11-04", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "https://github.com/openai/pixel-cnn", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Generative models of CIFAR-10 images)                ?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/generative.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Model entropy (bits per pixel)", 
                    "target": null
                }
            ], 
            "solved": false, 
            "attributes": [
                "vision", 
                "agi"
            ]
        }, 
        {
            "superproblems": [], 
            "name": "Correctly identify when an answer to a classification problem is uncertain", 
            "url": null, 
            "subproblems": [], 
            "notes": "Humans can usually tell when they don't know something. Present ML classifiers do not have this ability.", 
            "metrics": [], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [], 
            "name": "Deploy automated defensive security tools to protect valuable systems", 
            "url": null, 
            "subproblems": [], 
            "notes": "\nIt is clearly important is ensuring that the state of the art in defensive technology is deployed everywhere\nthat matters, including systems that perform important functions or have sensitive data on them (smartphones, for instance), and \nsystems that have signifcant computational resources. This \"Problem\" isn't \n", 
            "metrics": [], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [
                "Know how to build general AI agents that will behave as expected"
            ], 
            "name": "Scalable supervision of a learning system", 
            "url": "https://arxiv.org/abs/1606.06565", 
            "subproblems": [
                "Cooperative inverse reinforcement learning of objective functions"
            ], 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "safety", 
                "agi"
            ]
        }, 
        {
            "superproblems": [
                "Image classification"
            ], 
            "name": "Pedestrian, bicycle & obstacle detection", 
            "url": null, 
            "subproblems": [], 
            "metrics": [
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-35-13d9cddcfa63>#L9", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Caltech Pedestrians USA", 
                    "parent": "Problem(Pedestrian, bicycle & obstacle detection)", 
                    "url": "http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/", 
                    "notes": "", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }, 
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-35-13d9cddcfa63>#L11", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "INRIA persons", 
                    "parent": "Problem(Pedestrian, bicycle & obstacle detection)", 
                    "url": "http://pascal.inrialpes.fr/data/human/", 
                    "notes": "", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }, 
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-35-13d9cddcfa63>#L13", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "ETH Pedestrian", 
                    "parent": "Problem(Pedestrian, bicycle & obstacle detection)", 
                    "url": "http://www.vision.ee.ethz.ch/~aess/dataset/", 
                    "notes": "", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }, 
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-35-13d9cddcfa63>#L15", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "TUD-Brussels Pedestrian", 
                    "parent": "Problem(Pedestrian, bicycle & obstacle detection)", 
                    "url": "http://www.d2.mpi-inf.mpg.de/tud-brussels", 
                    "notes": "", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }, 
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-35-13d9cddcfa63>#L17", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Damiler Pedestrian", 
                    "parent": "Problem(Pedestrian, bicycle & obstacle detection)", 
                    "url": "http://www.gavrila.net/Datasets/Daimler_Pedestrian_Benchmark_D/Daimler_Mono_Ped__Detection_Be/daimler_mono_ped__detection_be.html", 
                    "notes": "", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }
            ], 
            "solved": false, 
            "attributes": [
                "safety", 
                "vision"
            ]
        }, 
        {
            "superproblems": [
                "Solve technical problems with clear constraints (proofs, circuit design, aerofoil design, etc)"
            ], 
            "name": "Given desired circuit characteristics, and many examples, design new circuits to spec", 
            "url": null, 
            "subproblems": [], 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "agi", 
                "math"
            ]
        }, 
        {
            "superproblems": [], 
            "name": "One shot learning: ingest important truths from a single example", 
            "url": null, 
            "subproblems": [], 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "agi", 
                "world-modelling"
            ]
        }, 
        {
            "superproblems": [
                "Conduct arbitrary sustained, probing conversation"
            ], 
            "name": "Language comprehension and question-answering", 
            "url": null, 
            "subproblems": [], 
            "metrics": [
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L128", 
                    "scale": "Percentage correct", 
                    "target_label": "Excellent performance", 
                    "name": "bAbi 20 QA (10k training examples)", 
                    "parent": "Problem(Language comprehension and question-answering)", 
                    "url": "http://fb.ai/babi", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": true, 
                            "maxval": 93.3, 
                            "long_label": true, 
                            "withdrawn": false, 
                            "name": "MemNN-AM+NG+NL (1k + strong supervision)", 
                            "minval": 93.3, 
                            "url": "https://arxiv.org/abs/1502.05698v1", 
                            "papername": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks", 
                            "value": 93.3, 
                            "label": "MemNN-AM+NG+NL (1k + strong supervision)", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(bAbi 20 QA (10k training examples))                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 93.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MemN2N-PE+LS+RN", 
                            "minval": 93.4, 
                            "url": "https://arxiv.org/abs/1503.08895", 
                            "papername": "End-To-End Memory Networks", 
                            "value": 93.4, 
                            "label": "MemN2N-PE+LS+RN", 
                            "algorithm_src_url": "", 
                            "date": "2015-03-31", 
                            "algorithms": [], 
                            "max_date": "2015-11-24", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-03-31", 
                            "notes": "", 
                            "metric": "Metric(bAbi 20 QA (10k training examples))                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 96.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DNC", 
                            "minval": 96.2, 
                            "url": "https://www.gwern.net/docs/2016-graves.pdf", 
                            "papername": null, 
                            "value": 96.2, 
                            "label": "DNC", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(bAbi 20 QA (10k training examples))                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 97.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DMN+", 
                            "minval": 97.2, 
                            "url": "https://arxiv.org/abs/1607.00036", 
                            "papername": "Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes", 
                            "value": 97.2, 
                            "label": "DMN+", 
                            "algorithm_src_url": "", 
                            "date": "2016-06-30", 
                            "algorithms": [], 
                            "max_date": "2017-03-17", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-06-30", 
                            "notes": "", 
                            "metric": "Metric(bAbi 20 QA (10k training examples))                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 97.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SDNC", 
                            "minval": 97.1, 
                            "url": "https://arxiv.org/abs/1606.04582v4", 
                            "papername": "Query-Reduction Networks for Question Answering", 
                            "value": 97.1, 
                            "label": "SDNC", 
                            "algorithm_src_url": "", 
                            "date": "2016-09-27", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(bAbi 20 QA (10k training examples))                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 99.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "QRN", 
                            "minval": 99.7, 
                            "url": "https://arxiv.org/abs/1606.04582v4", 
                            "papername": "Query-Reduction Networks for Question Answering", 
                            "value": 99.7, 
                            "label": "QRN", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-09", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(bAbi 20 QA (10k training examples))                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 99.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "EntNet", 
                            "minval": 99.5, 
                            "url": "https://arxiv.org/abs/1612.03969", 
                            "papername": "Tracking the World State with Recurrent Entity Networks", 
                            "value": 99.5, 
                            "label": "EntNet", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-12", 
                            "algorithms": [], 
                            "max_date": "2017-05-10", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-12-12", 
                            "notes": "", 
                            "metric": "Metric(bAbi 20 QA (10k training examples))                  SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "data/language.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": 99
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L127", 
                    "scale": "Percentage correct", 
                    "target_label": "Excellent performance", 
                    "name": "bAbi 20 QA (1k training examples)", 
                    "parent": "Problem(Language comprehension and question-answering)", 
                    "url": "http://fb.ai/babi", 
                    "notes": "\nA synthetic environment inspired by text adventures and SHRDLU, which enables generation\nof ground truths, describing sentences, and inferential questions. Includes:\nsupporting facts, relations, yes/no questions, counting, lists/sets, negation, indefiniteness,\nconference, conjunction, time, basic deduction and induction, reasoning about position, size,\npath finding and motivation.\n\nTable 3 of https://arxiv.org/abs/1502.05698 actually breaks this down into 20 submeasures\nbut initially we're lumping all of this together.\n\nOriginally \"solving\" bABI was defined as 95% accuracy (or perhaps) 95% accuracy on all submeasures,\nbut clearly humans and now algorithms are better than that.\n\nTODO: bAbi really needs to be decomposed into semi-supervised and unsupervised variants, and \nby amount of training data provided\n", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 86.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MemN2N-PE+LS+RN", 
                            "minval": 86.1, 
                            "url": "https://arxiv.org/abs/1503.08895", 
                            "papername": "End-To-End Memory Networks", 
                            "value": 86.1, 
                            "label": "MemN2N-PE+LS+RN", 
                            "algorithm_src_url": "", 
                            "date": "2015-03-31", 
                            "algorithms": [], 
                            "max_date": "2015-11-24", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-03-31", 
                            "notes": "", 
                            "metric": "Metric(bAbi 20 QA (1k training examples))                   not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 93.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DMN", 
                            "minval": 93.6, 
                            "url": "https://arxiv.org/abs/1506.07285", 
                            "papername": "Ask Me Anything: Dynamic Memory Networks for Natural Language Processing", 
                            "value": 93.6, 
                            "label": "DMN", 
                            "algorithm_src_url": "", 
                            "date": "2015-06-24", 
                            "algorithms": [], 
                            "max_date": "2016-03-05", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-06-24", 
                            "notes": "", 
                            "metric": "Metric(bAbi 20 QA (1k training examples))                   not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 66.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DMN+", 
                            "minval": 66.8, 
                            "url": "https://arxiv.org/abs/1606.04582v4", 
                            "papername": "Query-Reduction Networks for Question Answering", 
                            "value": 66.8, 
                            "label": "DMN+", 
                            "algorithm_src_url": "https://arxiv.org/abs/1607.00036", 
                            "date": "2016-12-09", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "https://github.com/therne/dmn-tensorflow", 
                            "src_name": "Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes", 
                            "min_date": "2016-06-30", 
                            "notes": "", 
                            "metric": "Metric(bAbi 20 QA (1k training examples))                   not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 90.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "QRN", 
                            "minval": 90.1, 
                            "url": "https://arxiv.org/abs/1606.04582v4", 
                            "papername": "Query-Reduction Networks for Question Answering", 
                            "value": 90.1, 
                            "label": "QRN", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-09", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(bAbi 20 QA (1k training examples))                   not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 89.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "EntNet", 
                            "minval": 89.1, 
                            "url": "https://arxiv.org/abs/1612.03969", 
                            "papername": "Tracking the World State with Recurrent Entity Networks", 
                            "value": 89.1, 
                            "label": "EntNet", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-12", 
                            "algorithms": [], 
                            "max_date": "2017-05-10", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-12-12", 
                            "notes": "", 
                            "metric": "Metric(bAbi 20 QA (1k training examples))                   not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/language.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": 99
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L138", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "Reading comprehension MCTest-160-all", 
                    "parent": "Problem(Language comprehension and question-answering)", 
                    "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/MCTest_EMNLP2013.pdf", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 69.16, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SW+D+RTE", 
                            "minval": 69.16, 
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/MCTest_EMNLP2013.pdf", 
                            "papername": "MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text", 
                            "value": 69.16, 
                            "label": "SW+D+RTE", 
                            "algorithm_src_url": "", 
                            "date": "2013-10-01", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Reading comprehension MCTest-160-all)                ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 73.27, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Narasimhan-model3", 
                            "minval": 73.27, 
                            "url": "https://people.csail.mit.edu/regina/my_papers/MCDR15.pdf", 
                            "papername": "Machine Comprehension with Discourse Relations", 
                            "value": 73.27, 
                            "label": "Narasimhan-model3", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Reading comprehension MCTest-160-all)                ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 75.27, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Wang-et-al", 
                            "minval": 75.27, 
                            "url": "https://arxiv.org/abs/1603.08884", 
                            "papername": "A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data", 
                            "value": 75.27, 
                            "label": "Wang-et-al", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Reading comprehension MCTest-160-all)                ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 74.58, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Parallel-Hierarchical", 
                            "minval": 74.58, 
                            "url": "https://arxiv.org/abs/1603.08884", 
                            "papername": "A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data", 
                            "value": 74.58, 
                            "label": "Parallel-Hierarchical", 
                            "algorithm_src_url": "", 
                            "date": "2016-03-29", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Reading comprehension MCTest-160-all)                ?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/language.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": null
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L145", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "Reading comprehension MCTest-500-all", 
                    "parent": "Problem(Language comprehension and question-answering)", 
                    "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/MCTest_EMNLP2013.pdf", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 63.33, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SW+D+RTE", 
                            "minval": 63.33, 
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/MCTest_EMNLP2013.pdf", 
                            "papername": "MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text", 
                            "value": 63.33, 
                            "label": "SW+D+RTE", 
                            "algorithm_src_url": "", 
                            "date": "2013-10-01", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Reading comprehension MCTest-500-all)                ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 63.75, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Narasimhan-model3", 
                            "minval": 63.75, 
                            "url": "https://people.csail.mit.edu/regina/my_papers/MCDR15.pdf", 
                            "papername": "Machine Comprehension with Discourse Relations", 
                            "value": 63.75, 
                            "label": "Narasimhan-model3", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Reading comprehension MCTest-500-all)                ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 67.83, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "LSSVM", 
                            "minval": 67.83, 
                            "url": "https://pdfs.semanticscholar.org/f26e/088bc4659a9b7fce28b6604d26de779bcf93.pdf", 
                            "papername": "Learning Answer-Entailing Structures for Machine Comprehension", 
                            "value": 67.83, 
                            "label": "LSSVM", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Reading comprehension MCTest-500-all)                ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 69.94, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Wang-et-al", 
                            "minval": 69.94, 
                            "url": "https://arxiv.org/abs/1603.08884", 
                            "papername": "A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data", 
                            "value": 69.94, 
                            "label": "Wang-et-al", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Reading comprehension MCTest-500-all)                ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 71.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Parallel-Hierarchical", 
                            "minval": 71.0, 
                            "url": "https://arxiv.org/abs/1603.08884", 
                            "papername": "A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data", 
                            "value": 71.0, 
                            "label": "Parallel-Hierarchical", 
                            "algorithm_src_url": "", 
                            "date": "2016-03-29", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Reading comprehension MCTest-500-all)                ?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/language.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": null
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L194", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "bAbi Children's Book comprehension CBtest NE", 
                    "parent": "Problem(Language comprehension and question-answering)", 
                    "url": "http://fb.ai/babi", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 70.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "AS reader (avg)", 
                            "minval": 70.6, 
                            "url": "https://arxiv.org/abs/1603.01547v1", 
                            "papername": "Text Understanding with the Attention Sum Reader Network", 
                            "value": 70.6, 
                            "label": "AS reader (avg)", 
                            "algorithm_src_url": "", 
                            "date": "2016-03-04", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 71.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "AS reader (greedy)", 
                            "minval": 71.0, 
                            "url": "https://arxiv.org/abs/1603.01547v1", 
                            "papername": "Text Understanding with the Attention Sum Reader Network", 
                            "value": 71.0, 
                            "label": "AS reader (greedy)", 
                            "algorithm_src_url": "", 
                            "date": "2016-03-04", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 71.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "GA reader", 
                            "minval": 71.9, 
                            "url": "https://arxiv.org/abs/1606.01549v1", 
                            "papername": "Gated-Attention Readers for Text Comprehension", 
                            "value": 71.9, 
                            "label": "GA reader", 
                            "algorithm_src_url": "", 
                            "date": "2016-06-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 69.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "EpiReader", 
                            "minval": 69.7, 
                            "url": "https://arxiv.org/abs/1606.02270", 
                            "papername": "Natural Language Comprehension with the EpiReader", 
                            "value": 69.7, 
                            "label": "EpiReader", 
                            "algorithm_src_url": "", 
                            "date": "2016-06-07", 
                            "algorithms": [], 
                            "max_date": "2016-06-10", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-06-07", 
                            "notes": "", 
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 71.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "AIA", 
                            "minval": 71.0, 
                            "url": "https://arxiv.org/abs/1606.02245v1", 
                            "papername": "Iterative Alternating Neural Attention for Machine Reading", 
                            "value": 71.0, 
                            "label": "AIA", 
                            "algorithm_src_url": "", 
                            "date": "2016-06-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 72.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "AIA", 
                            "minval": 72.0, 
                            "url": "https://arxiv.org/abs/1606.02245v1", 
                            "papername": "Iterative Alternating Neural Attention for Machine Reading", 
                            "value": 72.0, 
                            "label": "AIA", 
                            "algorithm_src_url": "", 
                            "date": "2016-06-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 72.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "AoA reader", 
                            "minval": 72.0, 
                            "url": "https://arxiv.org/abs/1607.04423", 
                            "papername": "Attention-over-Attention Neural Networks for Reading Comprehension", 
                            "value": 72.0, 
                            "label": "AoA reader", 
                            "algorithm_src_url": "", 
                            "date": "2016-08-04", 
                            "algorithms": [], 
                            "max_date": "2017-06-06", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-07-15", 
                            "notes": "", 
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 73.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "NSE", 
                            "minval": 73.2, 
                            "url": "https://arxiv.org/abs/1606.01549v2", 
                            "papername": "Gated-Attention Readers for Text Comprehension", 
                            "value": 73.2, 
                            "label": "NSE", 
                            "algorithm_src_url": "https://arxiv.org/abs/1607.04315", 
                            "date": "2016-12-01", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Neural Semantic Encoders", 
                            "min_date": "2016-07-04", 
                            "notes": "", 
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 74.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "GA +feature, fix L(w)", 
                            "minval": 74.9, 
                            "url": "https://arxiv.org/abs/1606.01549v2", 
                            "papername": "Gated-Attention Readers for Text Comprehension", 
                            "value": 74.9, 
                            "label": "GA +feature, fix L(w)", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-01", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/language.py", 
                    "target_source": "https://arxiv.org/abs/1511.02301", 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": 81.6
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L196", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "bAbi Children's Book comprehension CBtest CN", 
                    "parent": "Problem(Language comprehension and question-answering)", 
                    "url": "http://fb.ai/babi", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 67.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "AS reader (greedy)", 
                            "minval": 67.5, 
                            "url": "https://arxiv.org/abs/1603.01547v1", 
                            "papername": "Text Understanding with the Attention Sum Reader Network", 
                            "value": 67.5, 
                            "label": "AS reader (greedy)", 
                            "algorithm_src_url": "", 
                            "date": "2016-03-04", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(bAbi Children's Book comprehension CBtest CN)        not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 68.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "AS reader (avg)", 
                            "minval": 68.9, 
                            "url": "https://arxiv.org/abs/1603.01547v1", 
                            "papername": "Text Understanding with the Attention Sum Reader Network", 
                            "value": 68.9, 
                            "label": "AS reader (avg)", 
                            "algorithm_src_url": "", 
                            "date": "2016-03-04", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(bAbi Children's Book comprehension CBtest CN)        not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 69.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "GA reader", 
                            "minval": 69.4, 
                            "url": "https://arxiv.org/abs/1606.01549v1", 
                            "papername": "Gated-Attention Readers for Text Comprehension", 
                            "value": 69.4, 
                            "label": "GA reader", 
                            "algorithm_src_url": "", 
                            "date": "2016-06-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(bAbi Children's Book comprehension CBtest CN)        not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 67.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "EpiReader", 
                            "minval": 67.4, 
                            "url": "https://arxiv.org/abs/1606.02270", 
                            "papername": "Natural Language Comprehension with the EpiReader", 
                            "value": 67.4, 
                            "label": "EpiReader", 
                            "algorithm_src_url": "", 
                            "date": "2016-06-07", 
                            "algorithms": [], 
                            "max_date": "2016-06-10", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-06-07", 
                            "notes": "", 
                            "metric": "Metric(bAbi Children's Book comprehension CBtest CN)        not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 69.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "AoA reader", 
                            "minval": 69.4, 
                            "url": "https://arxiv.org/abs/1607.04423", 
                            "papername": "Attention-over-Attention Neural Networks for Reading Comprehension", 
                            "value": 69.4, 
                            "label": "AoA reader", 
                            "algorithm_src_url": "", 
                            "date": "2016-08-04", 
                            "algorithms": [], 
                            "max_date": "2017-06-06", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-07-15", 
                            "notes": "", 
                            "metric": "Metric(bAbi Children's Book comprehension CBtest CN)        not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 70.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "GA +feature, fix L(w)", 
                            "minval": 70.7, 
                            "url": "https://arxiv.org/abs/1606.01549v2", 
                            "papername": "Gated-Attention Readers for Text Comprehension", 
                            "value": 70.7, 
                            "label": "GA +feature, fix L(w)", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-01", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(bAbi Children's Book comprehension CBtest CN)        not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 71.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "NSE", 
                            "minval": 71.9, 
                            "url": "https://arxiv.org/abs/1606.01549v2", 
                            "papername": "Gated-Attention Readers for Text Comprehension", 
                            "value": 71.9, 
                            "label": "NSE", 
                            "algorithm_src_url": "https://arxiv.org/abs/1607.04315", 
                            "date": "2016-12-01", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Neural Semantic Encoders", 
                            "min_date": "2016-07-04", 
                            "notes": "", 
                            "metric": "Metric(bAbi Children's Book comprehension CBtest CN)        not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/language.py", 
                    "target_source": "https://arxiv.org/abs/1511.02301", 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": 81.6
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L190", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "CNN Comprehension test", 
                    "parent": "Problem(Language comprehension and question-answering)", 
                    "url": "https://github.com/deepmind/rc-data/", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 63.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Attentive reader", 
                            "minval": 63.0, 
                            "url": "https://arxiv.org/abs/1506.03340", 
                            "papername": "Teaching Machines to Read and Comprehend", 
                            "value": 63.0, 
                            "label": "Attentive reader", 
                            "algorithm_src_url": "", 
                            "date": "2015-06-10", 
                            "algorithms": [], 
                            "max_date": "2015-11-19", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-06-10", 
                            "notes": "", 
                            "metric": "Metric(CNN Comprehension test)                              ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 63.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Impatient reader", 
                            "minval": 63.8, 
                            "url": "https://arxiv.org/abs/1506.03340", 
                            "papername": "Teaching Machines to Read and Comprehend", 
                            "value": 63.8, 
                            "label": "Impatient reader", 
                            "algorithm_src_url": "", 
                            "date": "2015-06-10", 
                            "algorithms": [], 
                            "max_date": "2015-11-19", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-06-10", 
                            "notes": "", 
                            "metric": "Metric(CNN Comprehension test)                              ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 74.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "AS reader (greedy)", 
                            "minval": 74.8, 
                            "url": "https://arxiv.org/abs/1603.01547v1", 
                            "papername": "Text Understanding with the Attention Sum Reader Network", 
                            "value": 74.8, 
                            "label": "AS reader (greedy)", 
                            "algorithm_src_url": "", 
                            "date": "2016-03-04", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CNN Comprehension test)                              ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 75.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "AS reader (avg)", 
                            "minval": 75.4, 
                            "url": "https://arxiv.org/abs/1603.01547v1", 
                            "papername": "Text Understanding with the Attention Sum Reader Network", 
                            "value": 75.4, 
                            "label": "AS reader (avg)", 
                            "algorithm_src_url": "", 
                            "date": "2016-03-04", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CNN Comprehension test)                              ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 77.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "GA reader", 
                            "minval": 77.4, 
                            "url": "https://arxiv.org/abs/1606.01549v1", 
                            "papername": "Gated-Attention Readers for Text Comprehension", 
                            "value": 77.4, 
                            "label": "GA reader", 
                            "algorithm_src_url": "", 
                            "date": "2016-06-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CNN Comprehension test)                              ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 74.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "EpiReader", 
                            "minval": 74.0, 
                            "url": "https://arxiv.org/abs/1606.02270", 
                            "papername": "Natural Language Comprehension with the EpiReader", 
                            "value": 74.0, 
                            "label": "EpiReader", 
                            "algorithm_src_url": "", 
                            "date": "2016-06-07", 
                            "algorithms": [], 
                            "max_date": "2016-06-10", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-06-07", 
                            "notes": "", 
                            "metric": "Metric(CNN Comprehension test)                              ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 75.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "AIA", 
                            "minval": 75.7, 
                            "url": "https://arxiv.org/abs/1606.02245v1", 
                            "papername": "Iterative Alternating Neural Attention for Machine Reading", 
                            "value": 75.7, 
                            "label": "AIA", 
                            "algorithm_src_url": "", 
                            "date": "2016-06-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CNN Comprehension test)                              ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 74.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "AoA reader", 
                            "minval": 74.4, 
                            "url": "https://arxiv.org/abs/1607.04423", 
                            "papername": "Attention-over-Attention Neural Networks for Reading Comprehension", 
                            "value": 74.4, 
                            "label": "AoA reader", 
                            "algorithm_src_url": "", 
                            "date": "2016-08-04", 
                            "algorithms": [], 
                            "max_date": "2017-06-06", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-07-15", 
                            "notes": "", 
                            "metric": "Metric(CNN Comprehension test)                              ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 77.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Attentive+relabling+ensemble", 
                            "minval": 77.6, 
                            "url": "https://arxiv.org/abs/1606.02858", 
                            "papername": "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task", 
                            "value": 77.6, 
                            "label": "Attentive+relabling+ensem...", 
                            "algorithm_src_url": "", 
                            "date": "2016-08-08", 
                            "algorithms": [], 
                            "max_date": "2016-08-08", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-06-09", 
                            "notes": "", 
                            "metric": "Metric(CNN Comprehension test)                              ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 76.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "AIA", 
                            "minval": 76.1, 
                            "url": "https://arxiv.org/abs/1606.02245v4", 
                            "papername": "Iterative Alternating Neural Attention for Machine Reading", 
                            "value": 76.1, 
                            "label": "AIA", 
                            "algorithm_src_url": "", 
                            "date": "2016-11-09", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CNN Comprehension test)                              ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 77.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "GA update L(w)", 
                            "minval": 77.9, 
                            "url": "https://arxiv.org/abs/1606.01549v2", 
                            "papername": "Gated-Attention Readers for Text Comprehension", 
                            "value": 77.9, 
                            "label": "GA update L(w)", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-01", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CNN Comprehension test)                              ?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/language.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": null
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L192", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "Daily Mail Comprehension test", 
                    "parent": "Problem(Language comprehension and question-answering)", 
                    "url": "https://github.com/deepmind/rc-data/", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 68.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Impatient reader", 
                            "minval": 68.0, 
                            "url": "https://arxiv.org/abs/1506.03340", 
                            "papername": "Teaching Machines to Read and Comprehend", 
                            "value": 68.0, 
                            "label": "Impatient reader", 
                            "algorithm_src_url": "", 
                            "date": "2015-06-10", 
                            "algorithms": [], 
                            "max_date": "2015-11-19", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-06-10", 
                            "notes": "", 
                            "metric": "Metric(Daily Mail Comprehension test)                       ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 69.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Attentive reader", 
                            "minval": 69.0, 
                            "url": "https://arxiv.org/abs/1506.03340", 
                            "papername": "Teaching Machines to Read and Comprehend", 
                            "value": 69.0, 
                            "label": "Attentive reader", 
                            "algorithm_src_url": "", 
                            "date": "2015-06-10", 
                            "algorithms": [], 
                            "max_date": "2015-11-19", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-06-10", 
                            "notes": "", 
                            "metric": "Metric(Daily Mail Comprehension test)                       ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 77.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "AS reader (avg)", 
                            "minval": 77.1, 
                            "url": "https://arxiv.org/abs/1603.01547v1", 
                            "papername": "Text Understanding with the Attention Sum Reader Network", 
                            "value": 77.1, 
                            "label": "AS reader (avg)", 
                            "algorithm_src_url": "", 
                            "date": "2016-03-04", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Daily Mail Comprehension test)                       ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 77.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "AS reader (greedy)", 
                            "minval": 77.7, 
                            "url": "https://arxiv.org/abs/1603.01547v1", 
                            "papername": "Text Understanding with the Attention Sum Reader Network", 
                            "value": 77.7, 
                            "label": "AS reader (greedy)", 
                            "algorithm_src_url": "", 
                            "date": "2016-03-04", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Daily Mail Comprehension test)                       ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 78.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "GA reader", 
                            "minval": 78.1, 
                            "url": "https://arxiv.org/abs/1606.01549v1", 
                            "papername": "Gated-Attention Readers for Text Comprehension", 
                            "value": 78.1, 
                            "label": "GA reader", 
                            "algorithm_src_url": "", 
                            "date": "2016-06-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Daily Mail Comprehension test)                       ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 79.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Attentive+relabling+ensemble", 
                            "minval": 79.2, 
                            "url": "https://arxiv.org/abs/1606.02858", 
                            "papername": "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task", 
                            "value": 79.2, 
                            "label": "Attentive+relabling+ensem...", 
                            "algorithm_src_url": "", 
                            "date": "2016-08-08", 
                            "algorithms": [], 
                            "max_date": "2016-08-08", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-06-09", 
                            "notes": "", 
                            "metric": "Metric(Daily Mail Comprehension test)                       ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 80.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "GA update L(w)", 
                            "minval": 80.9, 
                            "url": "https://arxiv.org/abs/1606.01549v2", 
                            "papername": "Gated-Attention Readers for Text Comprehension", 
                            "value": 80.9, 
                            "label": "GA update L(w)", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-01", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Daily Mail Comprehension test)                       ?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/language.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": null
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L255", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Stanford Question Answering Dataset EM test", 
                    "parent": "Problem(Language comprehension and question-answering)", 
                    "url": "https://stanford-qa.com/", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 67.901, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Match-LSTM+Ans-Ptr", 
                            "minval": 67.901, 
                            "url": "https://arxiv.org/abs/1608.07905v2", 
                            "papername": "Machine Comprehension Using Match-LSTM and Answer Pointer", 
                            "value": 67.901, 
                            "label": "Match-LSTM+Ans-Ptr", 
                            "algorithm_src_url": "", 
                            "date": "2016-11-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 68.478, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "BiDAF (single model)", 
                            "minval": 68.478, 
                            "url": "https://arxiv.org/abs/1611.01603", 
                            "papername": "Bidirectional Attention Flow for Machine Comprehension", 
                            "value": 68.478, 
                            "label": "BiDAF (single model)", 
                            "algorithm_src_url": "", 
                            "date": "2016-11-29", 
                            "algorithms": [], 
                            "max_date": "2017-02-24", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-11-05", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 70.387, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MPM (single model)", 
                            "minval": 70.387, 
                            "url": "https://arxiv.org/abs/1612.04211", 
                            "papername": "Multi-Perspective Context Matching for Machine Comprehension", 
                            "value": 70.387, 
                            "label": "MPM (single model)", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-13", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 73.765, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MPM (ensemble)", 
                            "minval": 73.765, 
                            "url": "https://arxiv.org/abs/1612.04211", 
                            "papername": "Multi-Perspective Context Matching for Machine Comprehension", 
                            "value": 73.765, 
                            "label": "MPM (ensemble)", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-13", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 68.436, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "FastQA", 
                            "minval": 68.436, 
                            "url": "https://arxiv.org/abs/1703.04816", 
                            "papername": "Making Neural QA as Simple as Possible but not Simpler", 
                            "value": 68.436, 
                            "label": "FastQA", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-29", 
                            "algorithms": [], 
                            "max_date": "2017-06-08", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2017-03-14", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 70.849, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "FastQAExt", 
                            "minval": 70.849, 
                            "url": "https://arxiv.org/abs/1703.04816", 
                            "papername": "Making Neural QA as Simple as Possible but not Simpler", 
                            "value": 70.849, 
                            "label": "FastQAExt", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-29", 
                            "algorithms": [], 
                            "max_date": "2017-06-08", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2017-03-14", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 71.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Dynamic Coattention Networks (ensemble)", 
                            "minval": 71.2, 
                            "url": "https://arxiv.org/abs/1611.01604", 
                            "papername": "Dynamic Coattention Networks For Question Answering", 
                            "value": 71.2, 
                            "label": "Dynamic Coattention Netwo...", 
                            "algorithm_src_url": "", 
                            "date": "2017-02-13", 
                            "algorithms": [], 
                            "max_date": "2017-02-13", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-11-05", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 73.744, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "BiDAF (ensemble)", 
                            "minval": 73.744, 
                            "url": "https://arxiv.org/abs/1611.01603", 
                            "papername": "Bidirectional Attention Flow for Machine Comprehension", 
                            "value": 73.744, 
                            "label": "BiDAF (ensemble)", 
                            "algorithm_src_url": "", 
                            "date": "2017-02-24", 
                            "algorithms": [], 
                            "max_date": "2017-02-24", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-11-05", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 74.614, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "r-net (single model)", 
                            "minval": 74.614, 
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf", 
                            "papername": null, 
                            "value": 74.614, 
                            "label": "r-net (single model)", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 76.922, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "r-net (ensemble)", 
                            "minval": 76.922, 
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf", 
                            "papername": null, 
                            "value": 76.922, 
                            "label": "r-net (ensemble)", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 70.733, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Document Reader (single model)", 
                            "minval": 70.733, 
                            "url": "https://arxiv.org/abs/1704.00051", 
                            "papername": "Reading Wikipedia to Answer Open-Domain Questions", 
                            "value": 70.733, 
                            "label": "Document Reader (single m...", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-31", 
                            "algorithms": [], 
                            "max_date": "2017-04-28", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2017-03-31", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 68.478, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SEDT+BiDAF (single model)", 
                            "minval": 68.478, 
                            "url": "https://arxiv.org/abs/1703.00572", 
                            "papername": "Structural Embedding of Syntactic Trees for Machine Comprehension", 
                            "value": 68.478, 
                            "label": "SEDT+BiDAF (single model)", 
                            "algorithm_src_url": "", 
                            "date": "2017-04-20", 
                            "algorithms": [], 
                            "max_date": "2017-04-20", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2017-03-02", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 73.723, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SEDT+BiDAF (ensemble)", 
                            "minval": 73.723, 
                            "url": "https://arxiv.org/abs/1703.00572", 
                            "papername": "Structural Embedding of Syntactic Trees for Machine Comprehension", 
                            "value": 73.723, 
                            "label": "SEDT+BiDAF (ensemble)", 
                            "algorithm_src_url": "", 
                            "date": "2017-04-20", 
                            "algorithms": [], 
                            "max_date": "2017-04-20", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2017-03-02", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 70.639, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Ruminating Reader (single model)", 
                            "minval": 70.639, 
                            "url": "https://arxiv.org/abs/1704.07415", 
                            "papername": "Ruminating Reader: Reasoning with Gated Multi-Hop Attention", 
                            "value": 70.639, 
                            "label": "Ruminating Reader (single...", 
                            "algorithm_src_url": "", 
                            "date": "2017-04-24", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 69.863, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Mnemonic reader (single model)", 
                            "minval": 69.863, 
                            "url": "https://arxiv.org/abs/1705.02798", 
                            "papername": "Mnemonic Reader for Machine Comprehension", 
                            "value": 69.863, 
                            "label": "Mnemonic reader (single m...", 
                            "algorithm_src_url": "", 
                            "date": "2017-05-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 73.754, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Mnemonic reader (ensemble)", 
                            "minval": 73.754, 
                            "url": "https://arxiv.org/abs/1705.02798", 
                            "papername": "Mnemonic Reader for Machine Comprehension", 
                            "value": 73.754, 
                            "label": "Mnemonic reader (ensemble)", 
                            "algorithm_src_url": "", 
                            "date": "2017-05-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 70.607, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "jNet (single model)", 
                            "minval": 70.607, 
                            "url": "https://arxiv.org/abs/1703.04617", 
                            "papername": "Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering", 
                            "value": 70.607, 
                            "label": "jNet (single model)", 
                            "algorithm_src_url": "", 
                            "date": "2017-05-31", 
                            "algorithms": [], 
                            "max_date": "2017-03-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2017-05-01", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 70.849, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RaSoR (single model)", 
                            "minval": 70.849, 
                            "url": "https://arxiv.org/abs/1611.01436", 
                            "papername": "Learning Recurrent Span Representations for Extractive Question Answering", 
                            "value": 70.849, 
                            "label": "RaSoR (single model)", 
                            "algorithm_src_url": "", 
                            "date": "2017-05-31", 
                            "algorithms": [], 
                            "max_date": "2017-03-17", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2017-05-01", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 73.01, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "jNet (ensemble)", 
                            "minval": 73.01, 
                            "url": "https://arxiv.org/abs/1703.04617", 
                            "papername": "Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering", 
                            "value": 73.01, 
                            "label": "jNet (ensemble)", 
                            "algorithm_src_url": "", 
                            "date": "2017-05-31", 
                            "algorithms": [], 
                            "max_date": "2017-03-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2017-05-01", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/language.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L256", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Stanford Question Answering Dataset F1 test", 
                    "parent": "Problem(Language comprehension and question-answering)", 
                    "url": "https://stanford-qa.com/", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 77.022, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Match-LSTM+Ans-Ptr", 
                            "minval": 77.022, 
                            "url": "https://arxiv.org/abs/1608.07905v2", 
                            "papername": "Machine Comprehension Using Match-LSTM and Answer Pointer", 
                            "value": 77.022, 
                            "label": "Match-LSTM+Ans-Ptr", 
                            "algorithm_src_url": "", 
                            "date": "2016-11-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 77.971, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "BiDAF (single model)", 
                            "minval": 77.971, 
                            "url": "https://arxiv.org/abs/1611.01603", 
                            "papername": "Bidirectional Attention Flow for Machine Comprehension", 
                            "value": 77.971, 
                            "label": "BiDAF (single model)", 
                            "algorithm_src_url": "", 
                            "date": "2016-11-29", 
                            "algorithms": [], 
                            "max_date": "2017-02-24", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-11-05", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 78.784, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MPM (single model)", 
                            "minval": 78.784, 
                            "url": "https://arxiv.org/abs/1612.04211", 
                            "papername": "Multi-Perspective Context Matching for Machine Comprehension", 
                            "value": 78.784, 
                            "label": "MPM (single model)", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-13", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 81.257, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MPM (ensemble)", 
                            "minval": 81.257, 
                            "url": "https://arxiv.org/abs/1612.04211", 
                            "papername": "Multi-Perspective Context Matching for Machine Comprehension", 
                            "value": 81.257, 
                            "label": "MPM (ensemble)", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-13", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 77.07, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "FastQA", 
                            "minval": 77.07, 
                            "url": "https://arxiv.org/abs/1703.04816", 
                            "papername": "Making Neural QA as Simple as Possible but not Simpler", 
                            "value": 77.07, 
                            "label": "FastQA", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-29", 
                            "algorithms": [], 
                            "max_date": "2017-06-08", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2017-03-14", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 78.857, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "FastQAExt", 
                            "minval": 78.857, 
                            "url": "https://arxiv.org/abs/1703.04816", 
                            "papername": "Making Neural QA as Simple as Possible but not Simpler", 
                            "value": 78.857, 
                            "label": "FastQAExt", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-29", 
                            "algorithms": [], 
                            "max_date": "2017-06-08", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2017-03-14", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 80.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Dynamic Coattention Networks (ensemble)", 
                            "minval": 80.4, 
                            "url": "https://arxiv.org/abs/1611.01604", 
                            "papername": "Dynamic Coattention Networks For Question Answering", 
                            "value": 80.4, 
                            "label": "Dynamic Coattention Netwo...", 
                            "algorithm_src_url": "", 
                            "date": "2017-02-13", 
                            "algorithms": [], 
                            "max_date": "2017-02-13", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-11-05", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 81.525, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "BiDAF (ensemble)", 
                            "minval": 81.525, 
                            "url": "https://arxiv.org/abs/1611.01603", 
                            "papername": "Bidirectional Attention Flow for Machine Comprehension", 
                            "value": 81.525, 
                            "label": "BiDAF (ensemble)", 
                            "algorithm_src_url": "", 
                            "date": "2017-02-24", 
                            "algorithms": [], 
                            "max_date": "2017-02-24", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-11-05", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 82.458, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "r-net (single model)", 
                            "minval": 82.458, 
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf", 
                            "papername": null, 
                            "value": 82.458, 
                            "label": "r-net (single model)", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 84.006, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "r-net (ensemble)", 
                            "minval": 84.006, 
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf", 
                            "papername": null, 
                            "value": 84.006, 
                            "label": "r-net (ensemble)", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 79.353, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Document Reader (single model)", 
                            "minval": 79.353, 
                            "url": "https://arxiv.org/abs/1704.00051", 
                            "papername": "Reading Wikipedia to Answer Open-Domain Questions", 
                            "value": 79.353, 
                            "label": "Document Reader (single m...", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-31", 
                            "algorithms": [], 
                            "max_date": "2017-04-28", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2017-03-31", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 77.971, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SEDT+BiDAF (single model)", 
                            "minval": 77.971, 
                            "url": "https://arxiv.org/abs/1703.00572", 
                            "papername": "Structural Embedding of Syntactic Trees for Machine Comprehension", 
                            "value": 77.971, 
                            "label": "SEDT+BiDAF (single model)", 
                            "algorithm_src_url": "", 
                            "date": "2017-04-20", 
                            "algorithms": [], 
                            "max_date": "2017-04-20", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2017-03-02", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 81.53, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SEDT+BiDAF (ensemble)", 
                            "minval": 81.53, 
                            "url": "https://arxiv.org/abs/1703.00572", 
                            "papername": "Structural Embedding of Syntactic Trees for Machine Comprehension", 
                            "value": 81.53, 
                            "label": "SEDT+BiDAF (ensemble)", 
                            "algorithm_src_url": "", 
                            "date": "2017-04-20", 
                            "algorithms": [], 
                            "max_date": "2017-04-20", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2017-03-02", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 79.821, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Ruminating Reader (single model)", 
                            "minval": 79.821, 
                            "url": "https://arxiv.org/abs/1704.07415", 
                            "papername": "Ruminating Reader: Reasoning with Gated Multi-Hop Attention", 
                            "value": 79.821, 
                            "label": "Ruminating Reader (single...", 
                            "algorithm_src_url": "", 
                            "date": "2017-04-24", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 79.207, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Mnemonic reader (single model)", 
                            "minval": 79.207, 
                            "url": "https://arxiv.org/abs/1705.02798", 
                            "papername": "Mnemonic Reader for Machine Comprehension", 
                            "value": 79.207, 
                            "label": "Mnemonic reader (single m...", 
                            "algorithm_src_url": "", 
                            "date": "2017-05-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 81.863, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Mnemonic reader (ensemble)", 
                            "minval": 81.863, 
                            "url": "https://arxiv.org/abs/1705.02798", 
                            "papername": "Mnemonic Reader for Machine Comprehension", 
                            "value": 81.863, 
                            "label": "Mnemonic reader (ensemble)", 
                            "algorithm_src_url": "", 
                            "date": "2017-05-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 78.741, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RaSoR (single model)", 
                            "minval": 78.741, 
                            "url": "https://arxiv.org/abs/1611.01436", 
                            "papername": "Learning Recurrent Span Representations for Extractive Question Answering", 
                            "value": 78.741, 
                            "label": "RaSoR (single model)", 
                            "algorithm_src_url": "", 
                            "date": "2017-05-31", 
                            "algorithms": [], 
                            "max_date": "2017-03-17", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2017-05-01", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 79.456, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "jNet (single model)", 
                            "minval": 79.456, 
                            "url": "https://arxiv.org/abs/1703.04617", 
                            "papername": "Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering", 
                            "value": 79.456, 
                            "label": "jNet (single model)", 
                            "algorithm_src_url": "", 
                            "date": "2017-05-31", 
                            "algorithms": [], 
                            "max_date": "2017-03-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2017-05-01", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 81.517, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "jNet (ensemble)", 
                            "minval": 81.517, 
                            "url": "https://arxiv.org/abs/1703.04617", 
                            "papername": "Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering", 
                            "value": 81.517, 
                            "label": "jNet (ensemble)", 
                            "algorithm_src_url": "", 
                            "date": "2017-05-31", 
                            "algorithms": [], 
                            "max_date": "2017-03-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2017-05-01", 
                            "notes": "", 
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/language.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }
            ], 
            "solved": false, 
            "attributes": [
                "language", 
                "world-modelling", 
                "agi"
            ]
        }, 
        {
            "superproblems": [
                "Solve technical problems with clear constraints (proofs, circuit design, aerofoil design, etc)"
            ], 
            "name": "Given examples of proofs, find correct proofs of simple mathematical theorems", 
            "url": null, 
            "subproblems": [], 
            "metrics": [
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/stem.py#L39", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "HolStep", 
                    "parent": "Problem(Given examples of proofs, find correct proofs of simple mathematical theorems)", 
                    "url": "https://arxiv.org/abs/1703.00426", 
                    "notes": "", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }
            ], 
            "solved": false, 
            "attributes": [
                "agi", 
                "math"
            ]
        }, 
        {
            "superproblems": [
                "Games that require both understanding and speaking a language"
            ], 
            "name": "Games that require language comprehension", 
            "url": null, 
            "subproblems": [], 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "agi", 
                "languge"
            ]
        }, 
        {
            "superproblems": [
                "Games that require inventing novel language, forms of speech, or communication"
            ], 
            "name": "Games that require both understanding and speaking a language", 
            "url": null, 
            "subproblems": [
                "Games that require language comprehension"
            ], 
            "metrics": [
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/data/video_games.py#L10", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Starcraft", 
                    "parent": "Problem(Games that require both understanding and speaking a language)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }
            ], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [], 
            "name": "Learn a several tasks without undermining performance on a first task, avoiding catastrophic forgetting", 
            "url": "https://arxiv.org/abs/1612.00796", 
            "subproblems": [], 
            "metrics": [], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [], 
            "name": "Train ML classifiers in a manner that corrects for the impact of omitted-variable bias on certain groups", 
            "url": null, 
            "subproblems": [], 
            "notes": "\nSeveral standards are available for avoiding classification biases.\n\nThey include holding false-positive / false adverse prediction rates constant across protected categories (which roughly maps \nto \"equal opportunity\"), holding both false-positive and false-negative rates equal (\"demographic parity\"), and ensuring\nthat the fraction of each protected group that receives a given prediction is constant across all groups \n(roughly equivalent to \"affirmative action\").", 
            "metrics": [
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-37-8599bdd9b61a>#L18", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Adjust prediction models to have constant false-positive rates", 
                    "parent": "Problem(Train ML classifiers in a manner that corrects for the impact of omitted-variable bias on certain groups)", 
                    "url": "https://arxiv.org/abs/1610.02413", 
                    "notes": "", 
                    "measures": [], 
                    "solved": true, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }, 
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-37-8599bdd9b61a>#L19", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Adjust prediction models tos have constant false-positive and -negative rates", 
                    "parent": "Problem(Train ML classifiers in a manner that corrects for the impact of omitted-variable bias on certain groups)", 
                    "url": "http://www.jmlr.org/proceedings/papers/v28/zemel13.pdf", 
                    "notes": "", 
                    "measures": [], 
                    "solved": true, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }
            ], 
            "solved": true, 
            "attributes": []
        }, 
        {
            "superproblems": [], 
            "name": "Given an arbitrary technical problem, solve it as well as a typical professional in that field", 
            "url": null, 
            "subproblems": [
                "Writing software from specifications", 
                "Solve vaguely or under-constrained technical problems", 
                "Solve technical problems with clear constraints (proofs, circuit design, aerofoil design, etc)"
            ], 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "language", 
                "world-modelling"
            ]
        }, 
        {
            "superproblems": [
                "Given an arbitrary technical problem, solve it as well as a typical professional in that field"
            ], 
            "name": "Writing software from specifications", 
            "url": null, 
            "subproblems": [], 
            "metrics": [
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/stem.py#L22", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "Card2Code", 
                    "parent": "Problem(Writing software from specifications)", 
                    "url": "https://github.com/deepmind/card2code", 
                    "notes": "", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": null
                }
            ], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [], 
            "name": "Translation between human langauges", 
            "url": null, 
            "subproblems": [], 
            "metrics": [
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L285", 
                    "scale": "BLEU score", 
                    "target_label": "Identical to professional human translations", 
                    "name": "news-test-2014 En-Fr BLEU", 
                    "parent": "Problem(Translation between human langauges)", 
                    "url": "http://aclweb.org/anthology/P/P02/P02-1040.pdf", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 37, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "PBMT", 
                            "minval": 37, 
                            "url": "http://www.anthology.aclweb.org/W/W14/W14-33.pdf", 
                            "papername": "Edinburgh\u2019s phrase-based machine translation systems for WMT-14", 
                            "value": 37, 
                            "label": "PBMT", 
                            "algorithm_src_url": "", 
                            "date": "2014-02-24", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 36.15, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RNN-search50*", 
                            "minval": 36.15, 
                            "url": "https://arxiv.org/abs/1409.0473", 
                            "papername": "Neural Machine Translation by Jointly Learning to Align and Translate", 
                            "value": 36.15, 
                            "label": "RNN-search50*", 
                            "algorithm_src_url": "", 
                            "date": "2014-09-01", 
                            "algorithms": [], 
                            "max_date": "2016-05-19", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-09-01", 
                            "notes": "", 
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 34.81, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "LSTM", 
                            "minval": 34.81, 
                            "url": "https://arxiv.org/abs/1409.3215v1", 
                            "papername": "Sequence to Sequence Learning with Neural Networks", 
                            "value": 34.81, 
                            "label": "LSTM", 
                            "algorithm_src_url": "http://www.bioinf.jku.at/publications/older/2604.pdf", 
                            "date": "2014-09-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "http://www.bioinf.jku.at/publications/older/2604.pdf", 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 36.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SMT+LSTM5", 
                            "minval": 36.5, 
                            "url": "https://arxiv.org/abs/1409.3215v1", 
                            "papername": "Sequence to Sequence Learning with Neural Networks", 
                            "value": 36.5, 
                            "label": "SMT+LSTM5", 
                            "algorithm_src_url": "", 
                            "date": "2014-09-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 37.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "LSTM6 + PosUnk", 
                            "minval": 37.5, 
                            "url": "https://arxiv.org/abs/1410.8206", 
                            "papername": "Addressing the Rare Word Problem in Neural Machine Translation", 
                            "value": 37.5, 
                            "label": "LSTM6 + PosUnk", 
                            "algorithm_src_url": "", 
                            "date": "2014-10-30", 
                            "algorithms": [], 
                            "max_date": "2015-05-30", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-10-30", 
                            "notes": "", 
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 39.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep-Att + PosUnk", 
                            "minval": 39.2, 
                            "url": "https://arxiv.org/abs/1606.04199", 
                            "papername": "Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation", 
                            "value": 39.2, 
                            "label": "Deep-Att + PosUnk", 
                            "algorithm_src_url": "", 
                            "date": "2016-07-23", 
                            "algorithms": [], 
                            "max_date": "2016-07-23", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-06-14", 
                            "notes": "", 
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 39.92, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "GNMT+RL", 
                            "minval": 39.92, 
                            "url": "https://arxiv.org/abs/1609.08144", 
                            "papername": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation", 
                            "value": 39.92, 
                            "label": "GNMT+RL", 
                            "algorithm_src_url": "", 
                            "date": "2016-09-26", 
                            "algorithms": [], 
                            "max_date": "2016-10-08", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-09-26", 
                            "notes": "", 
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 40.56, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MoE 2048", 
                            "minval": 40.56, 
                            "url": "https://arxiv.org/abs/1701.06538", 
                            "papername": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer", 
                            "value": 40.56, 
                            "label": "MoE 2048", 
                            "algorithm_src_url": "", 
                            "date": "2017-01-23", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 41.29, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ConvS2S ensemble", 
                            "minval": 41.29, 
                            "url": "https://arxiv.org/abs/1705.03122v2", 
                            "papername": "Convolutional Sequence to Sequence Learning", 
                            "value": 41.29, 
                            "label": "ConvS2S ensemble", 
                            "algorithm_src_url": "", 
                            "date": "2017-05-12", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/language.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "BLEU score", 
                    "target": 50
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L289", 
                    "scale": "BLEU score", 
                    "target_label": "Identical to professional human translations", 
                    "name": "news-test-2014 En-De BLEU", 
                    "parent": "Problem(Translation between human langauges)", 
                    "url": "http://aclweb.org/anthology/P/P02/P02-1040.pdf", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "PBMT", 
                            "minval": 20.7, 
                            "url": "http://www.anthology.aclweb.org/W/W14/W14-33.pdf", 
                            "papername": "Edinburgh\u2019s phrase-based machine translation systems for WMT-14", 
                            "value": 20.7, 
                            "label": "PBMT", 
                            "algorithm_src_url": "", 
                            "date": "2014-02-24", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(news-test-2014 En-De BLEU)                           not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 17.93, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "NSE-NSE", 
                            "minval": 17.93, 
                            "url": "https://arxiv.org/abs/1607.04315v1", 
                            "papername": "Neural Semantic Encoders", 
                            "value": 17.93, 
                            "label": "NSE-NSE", 
                            "algorithm_src_url": "", 
                            "date": "2016-07-14", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(news-test-2014 En-De BLEU)                           not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep-Att", 
                            "minval": 20.7, 
                            "url": "https://arxiv.org/abs/1606.04199", 
                            "papername": "Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation", 
                            "value": 20.7, 
                            "label": "Deep-Att", 
                            "algorithm_src_url": "", 
                            "date": "2016-07-23", 
                            "algorithms": [], 
                            "max_date": "2016-07-23", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-06-14", 
                            "notes": "", 
                            "metric": "Metric(news-test-2014 En-De BLEU)                           not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 26.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "GNMT+RL", 
                            "minval": 26.3, 
                            "url": "https://arxiv.org/abs/1609.08144", 
                            "papername": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation", 
                            "value": 26.3, 
                            "label": "GNMT+RL", 
                            "algorithm_src_url": "", 
                            "date": "2016-09-26", 
                            "algorithms": [], 
                            "max_date": "2016-10-08", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-09-26", 
                            "notes": "", 
                            "metric": "Metric(news-test-2014 En-De BLEU)                           not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 26.03, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MoE 2048", 
                            "minval": 26.03, 
                            "url": "https://arxiv.org/abs/1701.06538", 
                            "papername": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer", 
                            "value": 26.03, 
                            "label": "MoE 2048", 
                            "algorithm_src_url": "", 
                            "date": "2017-01-23", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(news-test-2014 En-De BLEU)                           not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 26.36, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ConvS2S ensemble", 
                            "minval": 26.36, 
                            "url": "https://arxiv.org/abs/1705.03122v2", 
                            "papername": "Convolutional Sequence to Sequence Learning", 
                            "value": 26.36, 
                            "label": "ConvS2S ensemble", 
                            "algorithm_src_url": "", 
                            "date": "2017-05-12", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(news-test-2014 En-De BLEU)                           not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/language.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "BLEU score", 
                    "target": 50
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L292", 
                    "scale": "BLEU score", 
                    "target_label": "Identical to professional human translations", 
                    "name": "news-test-2016 En-Ro BLEU", 
                    "parent": "Problem(Translation between human langauges)", 
                    "url": "http://www.statmt.org/wmt16/book.pdf", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 28.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "GRU BPE90k", 
                            "minval": 28.9, 
                            "url": "http://www.statmt.org/wmt16/pdf/W16-2320.pdf", 
                            "papername": "The QT21/HimL Combined Machine Translation System", 
                            "value": 28.9, 
                            "label": "GRU BPE90k", 
                            "algorithm_src_url": "", 
                            "date": "2016-07-11", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(news-test-2016 En-Ro BLEU)                           not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 29.88, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ConvS2S BPE40k", 
                            "minval": 29.88, 
                            "url": "https://arxiv.org/abs/1705.03122v2", 
                            "papername": "Convolutional Sequence to Sequence Learning", 
                            "value": 29.88, 
                            "label": "ConvS2S BPE40k", 
                            "algorithm_src_url": "", 
                            "date": "2017-05-12", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(news-test-2016 En-Ro BLEU)                           not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/language.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "BLEU score", 
                    "target": 50
                }
            ], 
            "solved": false, 
            "attributes": [
                "agi", 
                "language"
            ]
        }, 
        {
            "superproblems": [], 
            "name": "Fairness in machine learning towards people with a preference for privacy", 
            "url": null, 
            "subproblems": [], 
            "notes": "\nPeople who care strongly about their own privacy take many measures to obfuscate their tracks through\ntechnological society, including using fictitious names, email addresses, etc in their routine dealings with\ncorporations, installing software to block or send inacurate data to online trackers. Like many other groups,\nthese people may be subject to unfairly adverse algorithmic decisionmaking. Treating them as a protected\ngroup will be more difficult, because they are in many respects harder to identify.\n", 
            "metrics": [], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [
                "Know how to build general AI agents that will behave as expected"
            ], 
            "name": "Safe exploration", 
            "url": "https://arxiv.org/abs/1606.06565", 
            "subproblems": [], 
            "notes": "\nSometimes, even doing something once is catastrophic. In such situations, how can an RL agent or some other AI system\nlearn about the catastrophic consequences without even taking the action once? This is an ability that most humans acquire\nat some point between childhood and adolescence.\n", 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "safety", 
                "agi", 
                "world-modelling"
            ]
        }, 
        {
            "superproblems": [], 
            "name": "Speech Recognition", 
            "url": null, 
            "subproblems": [], 
            "metrics": [
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/acoustics.py#L41", 
                    "scale": "Percentage error", 
                    "target_label": null, 
                    "name": "Word error rate on Switchboard trained against the Hub5'00 dataset", 
                    "parent": "Problem(Speech Recognition)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 16.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "CD-DNN", 
                            "minval": 16.1, 
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/CD-DNN-HMM-SWB-Interspeech2011-Pub.pdf", 
                            "papername": null, 
                            "value": 16.1, 
                            "label": "CD-DNN", 
                            "algorithm_src_url": "", 
                            "date": "2011-08-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 18.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DNN-HMM", 
                            "minval": 18.5, 
                            "url": "https://pdfs.semanticscholar.org/ce25/00257fda92338ec0a117bea1dbc0381d7c73.pdf?_ga=1.195375081.452266805.1483390947", 
                            "papername": null, 
                            "value": 18.5, 
                            "label": "DNN-HMM", 
                            "algorithm_src_url": "", 
                            "date": "2012-04-27", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DNN sMBR", 
                            "minval": 12.6, 
                            "url": "http://www.danielpovey.com/files/2013_interspeech_dnn.pdf", 
                            "papername": null, 
                            "value": 12.6, 
                            "label": "DNN sMBR", 
                            "algorithm_src_url": "", 
                            "date": "2013-08-25", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DNN MMI", 
                            "minval": 12.9, 
                            "url": "http://www.danielpovey.com/files/2013_interspeech_dnn.pdf", 
                            "papername": null, 
                            "value": 12.9, 
                            "label": "DNN MMI", 
                            "algorithm_src_url": "", 
                            "date": "2013-08-25", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DNN MPE", 
                            "minval": 12.9, 
                            "url": "http://www.danielpovey.com/files/2013_interspeech_dnn.pdf", 
                            "papername": null, 
                            "value": 12.9, 
                            "label": "DNN MPE", 
                            "algorithm_src_url": "", 
                            "date": "2013-08-25", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DNN BMMI", 
                            "minval": 12.9, 
                            "url": "http://www.danielpovey.com/files/2013_interspeech_dnn.pdf", 
                            "papername": null, 
                            "value": 12.9, 
                            "label": "DNN BMMI", 
                            "algorithm_src_url": "", 
                            "date": "2013-08-25", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 16, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DNN", 
                            "minval": 16, 
                            "url": "https://arxiv.org/abs/1406.7806v1", 
                            "papername": "Increasing Deep Neural Network Acoustic Model Size for Large Vocabulary Continuous Speech Recognition", 
                            "value": 16, 
                            "label": "DNN", 
                            "algorithm_src_url": "", 
                            "date": "2014-06-30", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep Speech + FSH", 
                            "minval": 12.6, 
                            "url": "https://arxiv.org/abs/1412.5567", 
                            "papername": "Deep Speech: Scaling up end-to-end speech recognition", 
                            "value": 12.6, 
                            "label": "Deep Speech + FSH", 
                            "algorithm_src_url": "", 
                            "date": "2014-12-07", 
                            "algorithms": [], 
                            "max_date": "2014-12-19", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-12-17", 
                            "notes": "", 
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep Speech", 
                            "minval": 20, 
                            "url": "https://arxiv.org/abs/1412.5567", 
                            "papername": "Deep Speech: Scaling up end-to-end speech recognition", 
                            "value": 20, 
                            "label": "Deep Speech", 
                            "algorithm_src_url": "", 
                            "date": "2014-12-07", 
                            "algorithms": [], 
                            "max_date": "2014-12-19", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-12-17", 
                            "notes": "", 
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "IBM 2015", 
                            "minval": 8.0, 
                            "url": "https://arxiv.org/abs/1505.05899", 
                            "papername": "The IBM 2015 English Conversational Telephone Speech Recognition System", 
                            "value": 8.0, 
                            "label": "IBM 2015", 
                            "algorithm_src_url": "", 
                            "date": "2015-05-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "IBM 2016", 
                            "minval": 6.9, 
                            "url": "https://arxiv.org/abs/1604.08242v1", 
                            "papername": "The IBM 2016 English Conversational Telephone Speech Recognition System", 
                            "value": 6.9, 
                            "label": "IBM 2016", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-27", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "CNN-LSTM", 
                            "minval": 5.9, 
                            "url": "https://arxiv.org/abs/1610.05256", 
                            "papername": "Achieving Human Parity in Conversational Speech Recognition", 
                            "value": 5.9, 
                            "label": "CNN-LSTM", 
                            "algorithm_src_url": "", 
                            "date": "2016-10-17", 
                            "algorithms": [], 
                            "max_date": "2017-02-17", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-10-17", 
                            "notes": "", 
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "CNN-LSTM", 
                            "minval": 6.6, 
                            "url": "https://arxiv.org/abs/1610.05256", 
                            "papername": "Achieving Human Parity in Conversational Speech Recognition", 
                            "value": 6.6, 
                            "label": "CNN-LSTM", 
                            "algorithm_src_url": "", 
                            "date": "2016-10-17", 
                            "algorithms": [], 
                            "max_date": "2017-02-17", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-10-17", 
                            "notes": "", 
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Microsoft 2016", 
                            "minval": 6.2, 
                            "url": "https://arxiv.org/abs/1609.03528", 
                            "papername": "The Microsoft 2016 Conversational Speech Recognition System", 
                            "value": 6.2, 
                            "label": "Microsoft 2016", 
                            "algorithm_src_url": "", 
                            "date": "2017-02-17", 
                            "algorithms": [], 
                            "max_date": "2017-01-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-09-12", 
                            "notes": "", 
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RNNLM", 
                            "minval": 6.9, 
                            "url": "https://arxiv.org/abs/1609.03528", 
                            "papername": "The Microsoft 2016 Conversational Speech Recognition System", 
                            "value": 6.9, 
                            "label": "RNNLM", 
                            "algorithm_src_url": "", 
                            "date": "2017-02-17", 
                            "algorithms": [], 
                            "max_date": "2017-01-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-09-12", 
                            "notes": "", 
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "data/acoustics.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Percentage error", 
                    "target": 5.9
                }
            ], 
            "solved": true, 
            "attributes": [
                "language", 
                "agi"
            ]
        }, 
        {
            "superproblems": [
                "Conduct arbitrary sustained, probing conversation"
            ], 
            "name": "Turing test for casual conversation", 
            "url": null, 
            "subproblems": [], 
            "metrics": [
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L86", 
                    "scale": "Percentage correct", 
                    "target_label": "Completely plausible answers", 
                    "name": "The Loebner Prize scored selection answers", 
                    "parent": "Problem(Turing test for casual conversation)", 
                    "url": "http://www.aisb.org.uk/events/loebner-prize", 
                    "notes": "\nThe Loebner Prize is an actual enactment of the Turing Test. Importantly, judges are instructed to engage in casual, natural\nconversation rather than deliberately probing to determine if participants are \"intelligent\" (Brian Christian, The Most Human Human).\nThis makes it considerably easier than a probing Turing Test, and it is close to being solved. \n\nHowever these aren't scores for the full Loebner Turing Test; since 2014 the Loebner prize has scored its entrants by\ngiving them a corpus of conversation and scoring their answers. We use these numbers because they remove variability\nin the behaviour of the judges. Unfortunately, these questions change from year to year (and have to, since \nentrants will test with last year's data).\n", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 76.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "The Professor 2014", 
                            "minval": 76.7, 
                            "url": "http://www.aisb.org.uk/events/loebner-prize#contest2014", 
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize", 
                            "value": 76.7, 
                            "label": "The Professor 2014", 
                            "algorithm_src_url": "", 
                            "date": "2014-11-15", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 80.83, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Tutor 2014", 
                            "minval": 80.83, 
                            "url": "http://www.aisb.org.uk/events/loebner-prize#contest2014", 
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize", 
                            "value": 80.83, 
                            "label": "Tutor 2014", 
                            "algorithm_src_url": "", 
                            "date": "2014-11-15", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 81.67, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Uberbot 2014", 
                            "minval": 81.67, 
                            "url": "http://www.aisb.org.uk/events/loebner-prize#contest2014", 
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize", 
                            "value": 81.67, 
                            "label": "Uberbot 2014", 
                            "algorithm_src_url": "", 
                            "date": "2014-11-15", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 88.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Izar 2014", 
                            "minval": 88.3, 
                            "url": "http://www.aisb.org.uk/events/loebner-prize#contest2014", 
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize", 
                            "value": 88.3, 
                            "label": "Izar 2014", 
                            "algorithm_src_url": "", 
                            "date": "2014-11-15", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 88.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Misuku 2014", 
                            "minval": 88.3, 
                            "url": "http://www.aisb.org.uk/events/loebner-prize#contest2014", 
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize", 
                            "value": 88.3, 
                            "label": "Misuku 2014", 
                            "algorithm_src_url": "", 
                            "date": "2014-11-15", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 89.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Rose 2014", 
                            "minval": 89.2, 
                            "url": "http://www.aisb.org.uk/events/loebner-prize#contest2014", 
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize", 
                            "value": 89.2, 
                            "label": "Rose 2014", 
                            "algorithm_src_url": "", 
                            "date": "2014-11-15", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 75, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Rose 2015", 
                            "minval": 75, 
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results15", 
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize", 
                            "value": 75, 
                            "label": "Rose 2015", 
                            "algorithm_src_url": "", 
                            "date": "2015-09-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 76.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Izar 2015", 
                            "minval": 76.7, 
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results15", 
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize", 
                            "value": 76.7, 
                            "label": "Izar 2015", 
                            "algorithm_src_url": "", 
                            "date": "2015-09-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 80, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Lisa 2015", 
                            "minval": 80, 
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results15", 
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize", 
                            "value": 80, 
                            "label": "Lisa 2015", 
                            "algorithm_src_url": "", 
                            "date": "2015-09-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 83.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Mitsuku 2015", 
                            "minval": 83.3, 
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results15", 
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize", 
                            "value": 83.3, 
                            "label": "Mitsuku 2015", 
                            "algorithm_src_url": "", 
                            "date": "2015-09-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 76.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Katie 2016", 
                            "minval": 76.7, 
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results16", 
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize", 
                            "value": 76.7, 
                            "label": "Katie 2016", 
                            "algorithm_src_url": "", 
                            "date": "2016-09-17", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 77.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Rose 2016", 
                            "minval": 77.5, 
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results16", 
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize", 
                            "value": 77.5, 
                            "label": "Rose 2016", 
                            "algorithm_src_url": "", 
                            "date": "2016-09-17", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 77.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Arckon 2016", 
                            "minval": 77.5, 
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results16", 
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize", 
                            "value": 77.5, 
                            "label": "Arckon 2016", 
                            "algorithm_src_url": "", 
                            "date": "2016-09-17", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 78.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Tutor 2016", 
                            "minval": 78.3, 
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results16", 
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize", 
                            "value": 78.3, 
                            "label": "Tutor 2016", 
                            "algorithm_src_url": "", 
                            "date": "2016-09-17", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 90, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Mitsuku 2016", 
                            "minval": 90, 
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results16", 
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize", 
                            "value": 90, 
                            "label": "Mitsuku 2016", 
                            "algorithm_src_url": "", 
                            "date": "2016-09-17", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/language.py", 
                    "target_source": null, 
                    "changeable": true, 
                    "axis_label": "Percentage of answers rated plausible\n(each year is a different test)", 
                    "target": 100
                }
            ], 
            "solved": false, 
            "attributes": [
                "agi", 
                "language", 
                "world-modelling", 
                "communication"
            ]
        }, 
        {
            "superproblems": [
                "Solve vaguely or under-constrained technical problems"
            ], 
            "name": "Write computer programs from specifications", 
            "url": null, 
            "subproblems": [
                "Parse and implement complex conditional expressions"
            ], 
            "metrics": [
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/stem.py#L53", 
                    "scale": "Percentage correct", 
                    "target_label": "Bug-free card implementation", 
                    "name": "Card2Code MTG accuracy", 
                    "parent": "Problem(Write computer programs from specifications)", 
                    "url": "https://github.com/deepmind/card2code", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "LPN", 
                            "minval": 4.8, 
                            "url": "https://arxiv.org/abs/1603.06744v1", 
                            "papername": "Latent Predictor Networks for Code Generation", 
                            "value": 4.8, 
                            "label": "LPN", 
                            "algorithm_src_url": "", 
                            "date": "2016-03-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Card2Code MTG accuracy)                              not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/stem.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": 100
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/stem.py#L58", 
                    "scale": "Percentage correct", 
                    "target_label": "Bug-free card implementation", 
                    "name": "Card2Code Hearthstone accuracy", 
                    "parent": "Problem(Write computer programs from specifications)", 
                    "url": "https://github.com/deepmind/card2code", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "LPN", 
                            "minval": 6.1, 
                            "url": "https://arxiv.org/abs/1603.06744v1", 
                            "papername": "Latent Predictor Networks for Code Generation", 
                            "value": 6.1, 
                            "label": "LPN", 
                            "algorithm_src_url": "", 
                            "date": "2016-03-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Card2Code Hearthstone accuracy)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "NMT", 
                            "minval": 1.5, 
                            "url": "https://arxiv.org/abs/1704.01696v1", 
                            "papername": "A Syntactic Neural Model for General-Purpose Code Generation", 
                            "value": 1.5, 
                            "label": "NMT", 
                            "algorithm_src_url": "https://arxiv.org/abs/1409.0473v1", 
                            "date": "2017-04-06", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Neural Machine Translation by Jointly Learning to Align and Translate", 
                            "min_date": "2014-09-01", 
                            "notes": "", 
                            "metric": "Metric(Card2Code Hearthstone accuracy)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 13.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Seq2Tree-Unk", 
                            "minval": 13.6, 
                            "url": "https://arxiv.org/abs/1704.01696v1", 
                            "papername": "A Syntactic Neural Model for General-Purpose Code Generation", 
                            "value": 13.6, 
                            "label": "Seq2Tree-Unk", 
                            "algorithm_src_url": "https://arxiv.org/abs/1601.01280v1", 
                            "date": "2017-04-06", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Language to Logical Form with Neural Attention", 
                            "min_date": "2016-01-06", 
                            "notes": "", 
                            "metric": "Metric(Card2Code Hearthstone accuracy)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 16.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SNM -frontier embed", 
                            "minval": 16.7, 
                            "url": "https://arxiv.org/abs/1704.01696v1", 
                            "papername": "A Syntactic Neural Model for General-Purpose Code Generation", 
                            "value": 16.7, 
                            "label": "SNM -frontier embed", 
                            "algorithm_src_url": "", 
                            "date": "2017-04-06", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Card2Code Hearthstone accuracy)                      not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/stem.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": 100
                }
            ], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [
                "Building systems that solve a wide range of diverse problems, rather than just specific ones"
            ], 
            "name": "Transfer learning: apply relevant knowledge from a prior setting to a new slightly different one", 
            "url": null, 
            "subproblems": [
                "Transfer of learning within simple arcade game paradigms"
            ], 
            "metrics": [], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [], 
            "name": "Play real-time computer & video games", 
            "url": null, 
            "subproblems": [
                "Games that require inventing novel language, forms of speech, or communication", 
                "Simple video games"
            ], 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "world-modelling", 
                "realtime-games", 
                "agi", 
                "language"
            ]
        }, 
        {
            "superproblems": [
                "Read a scientific or technical paper, and comprehend its contents"
            ], 
            "name": "Extract major numerical results or progress claims from a STEM paper", 
            "url": null, 
            "subproblems": [], 
            "notes": "\nThis metric is the ability to automatically update the ipython Notebook you are reading by spotting results in pdfs uploaded to arxiv.org.\nPull requests demonstrating solutions are welcome :)\n", 
            "metrics": [
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/stem.py#L12", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Automatically find new relevant ML results on arXiv", 
                    "parent": "Problem(Extract major numerical results or progress claims from a STEM paper)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }
            ], 
            "solved": false, 
            "attributes": [
                "language", 
                "world-modelling", 
                "agi"
            ]
        }, 
        {
            "superproblems": [], 
            "name": "Abstract strategy games", 
            "url": null, 
            "subproblems": [
                "Playing abstract games with extensive hints", 
                "Superhuman mastery of arbitrary abstract strategy games", 
                "Learning the rules of complex strategy games from examples", 
                "Play an arbitrary abstract game, first learning the rules"
            ], 
            "metrics": [], 
            "solved": true, 
            "attributes": [
                "agi", 
                "abstract-games"
            ]
        }, 
        {
            "superproblems": [
                "Scalable supervision of a learning system"
            ], 
            "name": "Cooperative inverse reinforcement learning of objective functions", 
            "url": "https://arxiv.org/abs/1606.03137", 
            "subproblems": [], 
            "notes": "This is tagged agi because most humans are able to learn ethics from their surrounding community", 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "safety", 
                "agi"
            ]
        }, 
        {
            "superproblems": [
                "Modify arbitrary ML systems in order to be able to provide comprehensible human explanations of their decisions"
            ], 
            "name": "Provide mathematical or technical explanations of decisions from classifiers", 
            "url": null, 
            "subproblems": [], 
            "notes": "\nProviding explanations with techniques such as monte carlo analysis may in general\nbe easier than providing robust ones in natural language (since those may or may not\nexist in all cases)\n", 
            "metrics": [], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [
                "Vision"
            ], 
            "name": "Image classification", 
            "url": null, 
            "subproblems": [
                "Image comprehension", 
                "Pedestrian, bicycle & obstacle detection"
            ], 
            "metrics": [
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/vision.py#L32", 
                    "scale": "Error rate", 
                    "target_label": null, 
                    "name": "Imagenet Image Recognition", 
                    "parent": "Problem(Image classification)", 
                    "url": "http://image-net.org", 
                    "notes": "\nCorrectly label images from the Imagenet dataset. As of 2016, this includes:\n - Object localization for 1000 categories.\n - Object detection for 200 fully labeled categories.\n - Object detection from video for 30 fully labeled categories.\n - Scene classification for 365 scene categories (Joint with MIT Places team) on Places2 Database http://places2.csail.mit.edu.\n - Scene parsing for 150 stuff and discrete object categories (Joint with MIT Places team).\n", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.28191, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "NEC UIUC", 
                            "minval": 0.28191, 
                            "url": "http://image-net.org/challenges/LSVRC/2010/results", 
                            "papername": "ImageNet Large Scale Visual Recognition Competition 2010 (ILSVRC2010)", 
                            "value": 0.28191, 
                            "label": "NEC UIUC", 
                            "algorithm_src_url": "", 
                            "date": "2010-08-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Imagenet Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.2577, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "XRCE", 
                            "minval": 0.2577, 
                            "url": "http://image-net.org/challenges/LSVRC/2011/results", 
                            "papername": "ImageNet Large Scale Visual Recognition Competition 2011 (ILSVRC2011)", 
                            "value": 0.2577, 
                            "label": "XRCE", 
                            "algorithm_src_url": "", 
                            "date": "2011-10-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Imagenet Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.16422, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SuperVision", 
                            "minval": 0.16422, 
                            "url": "http://image-net.org/challenges/LSVRC/2012/results.html", 
                            "papername": "ImageNet Large Scale Visual Recognition Competition 2012 (ILSVRC2012)", 
                            "value": 0.16422, 
                            "label": "SuperVision", 
                            "algorithm_src_url": "", 
                            "date": "2012-10-13", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Imagenet Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.11743, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Clarifai", 
                            "minval": 0.11743, 
                            "url": "http://www.image-net.org/challenges/LSVRC/2013/results.php", 
                            "papername": "ImageNet Large Scale Visual Recognition Competition 2013 (ILSVRC2013)", 
                            "value": 0.11743, 
                            "label": "Clarifai", 
                            "algorithm_src_url": "", 
                            "date": "2013-11-14", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Imagenet Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.07405, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "VGG", 
                            "minval": 0.07405, 
                            "url": "http://image-net.org/challenges/LSVRC/2014/index", 
                            "papername": "ImageNet Large Scale Visual Recognition Competition 2014 (ILSVRC2014)", 
                            "value": 0.07405, 
                            "label": "VGG", 
                            "algorithm_src_url": "", 
                            "date": "2014-08-18", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Imagenet Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.0458, 
                            "long_label": false, 
                            "withdrawn": true, 
                            "name": "withdrawn", 
                            "minval": 0.0458, 
                            "url": "https://arxiv.org/abs/1501.02876", 
                            "papername": "Deep Image: Scaling up Image Recognition", 
                            "value": 0.0458, 
                            "label": "withdrawn", 
                            "algorithm_src_url": "", 
                            "date": "2015-04-10", 
                            "algorithms": [], 
                            "max_date": "2015-07-06", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-01-13", 
                            "notes": "", 
                            "metric": "Metric(Imagenet Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.03567, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MSRA", 
                            "minval": 0.03567, 
                            "url": "http://image-net.org/challenges/LSVRC/2015/results", 
                            "papername": "ILSVRC2015 Results", 
                            "value": 0.03567, 
                            "label": "MSRA", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-10", 
                            "algorithms": [
                                "residual-networks"
                            ], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Imagenet Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.02991, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Trimps-Soushen", 
                            "minval": 0.02991, 
                            "url": "http://image-net.org/challenges/LSVRC/2016/results", 
                            "papername": "ILSVRC2016", 
                            "value": 0.02991, 
                            "label": "Trimps-Soushen", 
                            "algorithm_src_url": "", 
                            "date": "2016-09-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Imagenet Image Recognition)                          SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "data/vision.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Error rate", 
                    "target": 0.051
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/awty.py#L233", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "MSRC-21 image semantic labelling (per-class)", 
                    "parent": "Problem(Image classification)", 
                    "url": "http://jamie.shotton.org/work/data.html", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 67.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "STF", 
                            "minval": 67.0, 
                            "url": "http://mi.eng.cam.ac.uk/~cipolla/publications/inproceedings/2008-CVPR-semantic-texton-forests.pdf", 
                            "papername": "Semantic Texton Forests for Image Categorization and Segmentation", 
                            "value": 67.0, 
                            "label": "STF", 
                            "algorithm_src_url": "", 
                            "date": "2008-07-01", 
                            "algorithms": [], 
                            "max_date": "2008-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2008-01-01", 
                            "notes": "", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 57.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "TextonBoost", 
                            "minval": 57.0, 
                            "url": "http://research.microsoft.com/pubs/117885/ijcv07a.pdf", 
                            "papername": "TextonBoost for Image Understanding", 
                            "value": 57.0, 
                            "label": "TextonBoost", 
                            "algorithm_src_url": "", 
                            "date": "2009-07-01", 
                            "algorithms": [], 
                            "max_date": "2009-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2009-01-01", 
                            "notes": "?? / 69.6 % (per-class / per-pixel) the unaries alone (no CRF on top)", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 69.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Auto-Context", 
                            "minval": 69.0, 
                            "url": "http://pages.ucsd.edu/~ztu/publication/pami_autocontext.pdf", 
                            "papername": "Auto-Context and Its Application to High-Level Vision Tasks and 3D Brain Image Segmentation", 
                            "value": 69.0, 
                            "label": "Auto-Context", 
                            "algorithm_src_url": "", 
                            "date": "2010-07-01", 
                            "algorithms": [], 
                            "max_date": "2010-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2010-01-01", 
                            "notes": "", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 77.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "HCRF+CO", 
                            "minval": 77.0, 
                            "url": "http://research.microsoft.com/en-us/um/people/pkohli/papers/lrkt_eccv2010.pdf", 
                            "papername": "Graph Cut based Inference with Co-occurrence Statistics", 
                            "value": 77.0, 
                            "label": "HCRF+CO", 
                            "algorithm_src_url": "", 
                            "date": "2010-07-01", 
                            "algorithms": [], 
                            "max_date": "2010-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2010-01-01", 
                            "notes": "", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 77.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Are Spatial and Global Constraints Really Necessary for Segmentation?", 
                            "minval": 77.0, 
                            "url": "http://infoscience.epfl.ch/record/169178/files/lucchi_ICCV11.pdf", 
                            "papername": "Are Spatial and Global Constraints Really Necessary for Segmentation?", 
                            "value": 77.0, 
                            "label": "Are Spatial and Global Co...", 
                            "algorithm_src_url": "", 
                            "date": "2011-07-01", 
                            "algorithms": [], 
                            "max_date": "2011-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2011-01-01", 
                            "notes": "Several variants are examined, no single method attains the overall best results, i.e. both best per-class and per-pixel averages simultaneously. Indicated result corresponds to the method that we best on the average (per-class + per-pixel / 2). Experiment data available.", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 78.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "FC CRF", 
                            "minval": 78.0, 
                            "url": "http://graphics.stanford.edu/projects/densecrf/densecrf.pdf", 
                            "papername": "Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials", 
                            "value": 78.0, 
                            "label": "FC CRF", 
                            "algorithm_src_url": "", 
                            "date": "2011-12-17", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Strong unary used provides 76.6% / 84.0%", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 79.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Describing the Scene as a Whole: Joint Object Detection, Scene Classification and Semantic Segmentation", 
                            "minval": 79.0, 
                            "url": "http://ttic.uchicago.edu/~rurtasun/publications/yao_et_al_cvpr12.pdf", 
                            "papername": "Describing the Scene as a Whole: Joint Object Detection, Scene Classification and Semantic Segmentation", 
                            "value": 79.0, 
                            "label": "Describing the Scene as a...", 
                            "algorithm_src_url": "", 
                            "date": "2012-06-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 80.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Harmony Potentials", 
                            "minval": 80.0, 
                            "url": "http://link.springer.com/article/10.1007%2Fs11263-011-0449-8", 
                            "papername": "Harmony Potentials - Fusing Local and Global Scale for Semantic Image Segmentation", 
                            "value": 80.0, 
                            "label": "Harmony Potentials", 
                            "algorithm_src_url": "", 
                            "date": "2012-07-01", 
                            "algorithms": [], 
                            "max_date": "2012-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2012-01-01", 
                            "notes": "per-class % / per-pixel %", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 72.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "PMG", 
                            "minval": 72.8, 
                            "url": "http://users.cecs.anu.edu.au/~sgould/papers/eccv12-patchGraph.pdf", 
                            "papername": "PatchMatchGraph: Building a Graph of Dense Patch Correspondences for Label Transfer", 
                            "value": 72.8, 
                            "label": "PMG", 
                            "algorithm_src_url": "", 
                            "date": "2012-10-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "8% / 63.3% raw PatchMatchGraph accuracy, 72.8% / 79.0% when using Boosted CRF. Code available.", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 76.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Kernelized SSVM/CRF", 
                            "minval": 76.0, 
                            "url": "https://infoscience.epfl.ch/record/180188/files/top.pdf", 
                            "papername": "Structured Image Segmentation using Kernelized Features", 
                            "value": 76.0, 
                            "label": "Kernelized SSVM/CRF", 
                            "algorithm_src_url": "", 
                            "date": "2012-10-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "70 % / 73 % when using only local features (not considering global features)", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 78.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MPP", 
                            "minval": 78.2, 
                            "url": "http://mediatum.ub.tum.de/doc/1175516/1175516.pdf", 
                            "papername": "Morphological Proximity Priors: Spatial Relationships for Semantic Segmentation", 
                            "value": 78.2, 
                            "label": "MPP", 
                            "algorithm_src_url": "", 
                            "date": "2013-10-29", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 80.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Large FC CRF", 
                            "minval": 80.9, 
                            "url": "http://ai2-s2-pdfs.s3.amazonaws.com/daba/eb9185990f65f807c95ff4d09057c2bf1cf0.pdf", 
                            "papername": "Large-Scale Semantic Co-Labeling of Image Sets", 
                            "value": 80.9, 
                            "label": "Large FC CRF", 
                            "algorithm_src_url": "", 
                            "date": "2014-07-01", 
                            "algorithms": [], 
                            "max_date": "2014-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-01-01", 
                            "notes": "", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/awty.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": null
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/awty.py#L246", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "MSRC-21 image semantic labelling (per-pixel)", 
                    "parent": "Problem(Image classification)", 
                    "url": "http://jamie.shotton.org/work/data.html", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 72.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "STF", 
                            "minval": 72.0, 
                            "url": "http://mi.eng.cam.ac.uk/~cipolla/publications/inproceedings/2008-CVPR-semantic-texton-forests.pdf", 
                            "papername": "Semantic Texton Forests for Image Categorization and Segmentation", 
                            "value": 72.0, 
                            "label": "STF", 
                            "algorithm_src_url": "", 
                            "date": "2008-07-01", 
                            "algorithms": [], 
                            "max_date": "2008-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2008-01-01", 
                            "notes": "", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 72.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "TextonBoost", 
                            "minval": 72.0, 
                            "url": "http://research.microsoft.com/pubs/117885/ijcv07a.pdf", 
                            "papername": "TextonBoost for Image Understanding", 
                            "value": 72.0, 
                            "label": "TextonBoost", 
                            "algorithm_src_url": "", 
                            "date": "2009-07-01", 
                            "algorithms": [], 
                            "max_date": "2009-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2009-01-01", 
                            "notes": "?? / 69.6 % (per-class / per-pixel) the unaries alone (no CRF on top)", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 78.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Auto-Context", 
                            "minval": 78.0, 
                            "url": "http://pages.ucsd.edu/~ztu/publication/pami_autocontext.pdf", 
                            "papername": "Auto-Context and Its Application to High-Level Vision Tasks and 3D Brain Image Segmentation", 
                            "value": 78.0, 
                            "label": "Auto-Context", 
                            "algorithm_src_url": "", 
                            "date": "2010-07-01", 
                            "algorithms": [], 
                            "max_date": "2010-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2010-01-01", 
                            "notes": "", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 87.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "HCRF+CO", 
                            "minval": 87.0, 
                            "url": "http://research.microsoft.com/en-us/um/people/pkohli/papers/lrkt_eccv2010.pdf", 
                            "papername": "Graph Cut based Inference with Co-occurrence Statistics", 
                            "value": 87.0, 
                            "label": "HCRF+CO", 
                            "algorithm_src_url": "", 
                            "date": "2010-07-01", 
                            "algorithms": [], 
                            "max_date": "2010-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2010-01-01", 
                            "notes": "", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 85.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Are Spatial and Global Constraints Really Necessary for Segmentation?", 
                            "minval": 85.0, 
                            "url": "http://infoscience.epfl.ch/record/169178/files/lucchi_ICCV11.pdf", 
                            "papername": "Are Spatial and Global Constraints Really Necessary for Segmentation?", 
                            "value": 85.0, 
                            "label": "Are Spatial and Global Co...", 
                            "algorithm_src_url": "", 
                            "date": "2011-07-01", 
                            "algorithms": [], 
                            "max_date": "2011-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2011-01-01", 
                            "notes": "Several variants are examined, no single method attains the overall best results, i.e. both best per-class and per-pixel averages simultaneously. Indicated result corresponds to the method that we best on the average (per-class + per-pixel / 2). Experiment data available.", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 86.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "FC CRF", 
                            "minval": 86.0, 
                            "url": "http://graphics.stanford.edu/projects/densecrf/densecrf.pdf", 
                            "papername": "Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials", 
                            "value": 86.0, 
                            "label": "FC CRF", 
                            "algorithm_src_url": "", 
                            "date": "2011-12-17", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Strong unary used provides 76.6% / 84.0%", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 86.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Describing the Scene as a Whole: Joint Object Detection, Scene Classification and Semantic Segmentation", 
                            "minval": 86.0, 
                            "url": "http://ttic.uchicago.edu/~rurtasun/publications/yao_et_al_cvpr12.pdf", 
                            "papername": "Describing the Scene as a Whole: Joint Object Detection, Scene Classification and Semantic Segmentation", 
                            "value": 86.0, 
                            "label": "Describing the Scene as a...", 
                            "algorithm_src_url": "", 
                            "date": "2012-06-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 83.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Harmony Potentials", 
                            "minval": 83.0, 
                            "url": "http://link.springer.com/article/10.1007%2Fs11263-011-0449-8", 
                            "papername": "Harmony Potentials - Fusing Local and Global Scale for Semantic Image Segmentation", 
                            "value": 83.0, 
                            "label": "Harmony Potentials", 
                            "algorithm_src_url": "", 
                            "date": "2012-07-01", 
                            "algorithms": [], 
                            "max_date": "2012-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2012-01-01", 
                            "notes": "per-class % / per-pixel %", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 79.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "PatchMatchGraph", 
                            "minval": 79.0, 
                            "url": "http://users.cecs.anu.edu.au/~sgould/papers/eccv12-patchGraph.pdf", 
                            "papername": "PatchMatchGraph: Building a Graph of Dense Patch Correspondences for Label Transfer", 
                            "value": 79.0, 
                            "label": "PatchMatchGraph", 
                            "algorithm_src_url": "", 
                            "date": "2012-10-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "8% / 63.3% raw PatchMatchGraph accuracy, 72.8% / 79.0% when using Boosted CRF. Code available.", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 82.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Kernelized SSVM/CRF", 
                            "minval": 82.0, 
                            "url": "https://infoscience.epfl.ch/record/180188/files/top.pdf", 
                            "papername": "Structured Image Segmentation using Kernelized Features", 
                            "value": 82.0, 
                            "label": "Kernelized SSVM/CRF", 
                            "algorithm_src_url": "", 
                            "date": "2012-10-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "70 % / 73 % when using only local features (not considering global features)", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 85.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MPP", 
                            "minval": 85.0, 
                            "url": "http://mediatum.ub.tum.de/doc/1175516/1175516.pdf", 
                            "papername": "Morphological Proximity Priors: Spatial Relationships for Semantic Segmentation", 
                            "value": 85.0, 
                            "label": "MPP", 
                            "algorithm_src_url": "", 
                            "date": "2013-10-29", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 86.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Large FC CRF", 
                            "minval": 86.8, 
                            "url": "http://ai2-s2-pdfs.s3.amazonaws.com/daba/eb9185990f65f807c95ff4d09057c2bf1cf0.pdf", 
                            "papername": "Large-Scale Semantic Co-Labeling of Image Sets", 
                            "value": 86.8, 
                            "label": "Large FC CRF", 
                            "algorithm_src_url": "", 
                            "date": "2014-07-01", 
                            "algorithms": [], 
                            "max_date": "2014-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-01-01", 
                            "notes": "", 
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/awty.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": null
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/awty.py#L114", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "CIFAR-100 Image Recognition", 
                    "parent": "Problem(Image classification)", 
                    "url": "http://https://www.cs.toronto.edu/~kriz/cifar.html", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 54.23, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Receptive Field Learning", 
                            "minval": 54.23, 
                            "url": "http://www.eecs.berkeley.edu/~jiayq/assets/pdf/cvpr12_pooling.pdf", 
                            "papername": "Beyond Spatial Pyramids: Receptive Field Learning for Pooled Image Features", 
                            "value": 54.23, 
                            "label": "Receptive Field Learning", 
                            "algorithm_src_url": "", 
                            "date": "2012-06-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 57.49, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Stochastic Pooling", 
                            "minval": 57.49, 
                            "url": "https://arxiv.org/abs/1301.3557", 
                            "papername": "Stochastic Pooling for Regularization of Deep Convolutional Neural Networks", 
                            "value": 57.49, 
                            "label": "Stochastic Pooling", 
                            "algorithm_src_url": "", 
                            "date": "2013-01-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 61.43, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Maxout Networks", 
                            "minval": 61.43, 
                            "url": "http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf", 
                            "papername": "Maxout Networks", 
                            "value": 61.43, 
                            "label": "Maxout Networks", 
                            "algorithm_src_url": "", 
                            "date": "2013-06-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Uses convolution. Does not use dataset agumentation.", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 56.29, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Smooth Pooling Regions", 
                            "minval": 56.29, 
                            "url": "http://www.d2.mpi-inf.mpg.de/content/learning-smooth-pooling-regions-visual-recognition", 
                            "papername": "Smooth Pooling Regions", 
                            "value": 56.29, 
                            "label": "Smooth Pooling Regions", 
                            "algorithm_src_url": "", 
                            "date": "2013-07-01", 
                            "algorithms": [], 
                            "max_date": "2013-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2013-01-01", 
                            "notes": "No data augmentation.", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 63.15, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Tree Priors", 
                            "minval": 63.15, 
                            "url": "http://www.cs.toronto.edu/~nitish/treebasedpriors.pdf", 
                            "papername": "Discriminative Transfer Learning with Tree-based Priors", 
                            "value": 63.15, 
                            "label": "Tree Priors", 
                            "algorithm_src_url": "", 
                            "date": "2013-07-01", 
                            "algorithms": [], 
                            "max_date": "2013-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2013-01-01", 
                            "notes": "The baseline Convnet + max pooling + dropout reaches 62.80% (without any tree prior).", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 61.86, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DNN+Probabilistic Maxout", 
                            "minval": 61.86, 
                            "url": "http://openreview.net/document/28d9c3ab-fe88-4836-b898-403d207a037c#28d9c3ab-fe88-4836-b898-403d207a037c", 
                            "papername": "Improving Deep Neural Networks with Probabilistic Maxout Units", 
                            "value": 61.86, 
                            "label": "DNN+Probabilistic Maxout", 
                            "algorithm_src_url": "", 
                            "date": "2014-04-14", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 64.32, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "NiN", 
                            "minval": 64.32, 
                            "url": "http://openreview.net/document/9b05a3bb-3a5e-49cb-91f7-0f482af65aea#9b05a3bb-3a5e-49cb-91f7-0f482af65aea", 
                            "papername": "Network in Network", 
                            "value": 64.32, 
                            "label": "NiN", 
                            "algorithm_src_url": "", 
                            "date": "2014-04-14", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "NIN + Dropout The code for NIN available at https://github.com/mavenlin/cuda-convnet", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 60.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Stable and Efficient Representation Learning with Nonnegativity Constraints ", 
                            "minval": 60.8, 
                            "url": "http://jmlr.org/proceedings/papers/v32/line14.pdf", 
                            "papername": "Stable and Efficient Representation Learning with Nonnegativity Constraints ", 
                            "value": 60.8, 
                            "label": "Stable and Efficient Repr...", 
                            "algorithm_src_url": "", 
                            "date": "2014-06-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "3-layers + multi-dict. 7 with 3-layers only. 3 with 1-layers only.", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 65.43, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DSN", 
                            "minval": 65.43, 
                            "url": "http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/", 
                            "papername": "Deeply-Supervised Nets", 
                            "value": 65.43, 
                            "label": "DSN", 
                            "algorithm_src_url": "", 
                            "date": "2014-07-01", 
                            "algorithms": [], 
                            "max_date": "2014-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-01-01", 
                            "notes": "Single model, without data augmentation.", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 75.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SSCNN", 
                            "minval": 75.7, 
                            "url": "https://arxiv.org/abs/1409.6070", 
                            "papername": "Spatially-sparse convolutional neural networks", 
                            "value": 75.7, 
                            "label": "SSCNN", 
                            "algorithm_src_url": "", 
                            "date": "2014-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 66.22, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep Networks with Internal Selective Attention through Feedback Connections", 
                            "minval": 66.22, 
                            "url": "http://papers.nips.cc/paper/5276-deep-networks-with-internal-selective-attention-through-feedback-connections.pdf", 
                            "papername": "Deep Networks with Internal Selective Attention through Feedback Connections", 
                            "value": 66.22, 
                            "label": "Deep Networks with Intern...", 
                            "algorithm_src_url": "", 
                            "date": "2014-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 66.29, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ACN", 
                            "minval": 66.29, 
                            "url": "https://arxiv.org/abs/1412.6806", 
                            "papername": "Striving for Simplicity: The All Convolutional Net", 
                            "value": 66.29, 
                            "label": "ACN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-15", 
                            "algorithms": [], 
                            "max_date": "2015-04-13", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-12-21", 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 69.17, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "NiN+APL", 
                            "minval": 69.17, 
                            "url": "https://arxiv.org/abs/1412.6830", 
                            "papername": "Learning Activation Functions to Improve Deep Neural Networks", 
                            "value": 69.17, 
                            "label": "NiN+APL", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-19", 
                            "algorithms": [], 
                            "max_date": "2015-04-21", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-12-21", 
                            "notes": "Uses a piecewise linear activation function. 69.17% accuracy with data augmentation and 65.6% accuracy without data augmentation.", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 73.61, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Fractional MP", 
                            "minval": 73.61, 
                            "url": "https://arxiv.org/abs/1412.6071", 
                            "papername": "Fractional Max-Pooling", 
                            "value": 73.61, 
                            "label": "Fractional MP", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-28", 
                            "algorithms": [], 
                            "max_date": "2015-05-12", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-12-18", 
                            "notes": "Uses 12 passes at test time. Reaches 68.55% when using a single pass at test time. Uses data augmentation during training.", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 72.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Tuned CNN", 
                            "minval": 72.6, 
                            "url": "https://arxiv.org/abs/1502.05700", 
                            "papername": "Scalable Bayesian Optimization Using Deep Neural Networks", 
                            "value": 72.6, 
                            "label": "Tuned CNN", 
                            "algorithm_src_url": "", 
                            "date": "2015-05-02", 
                            "algorithms": [], 
                            "max_date": "2015-07-13", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-02-19", 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 68.25, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RCNN-96", 
                            "minval": 68.25, 
                            "url": "http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_004.pdf", 
                            "papername": "Recurrent Convolutional Neural Network for Object Recognition", 
                            "value": 68.25, 
                            "label": "RCNN-96", 
                            "algorithm_src_url": "", 
                            "date": "2015-06-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 64.77, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep Representation Learning with Target Coding", 
                            "minval": 64.77, 
                            "url": "http://personal.ie.cuhk.edu.hk/~ccloy/files/aaai_2015_target_coding.pdf", 
                            "papername": "Deep Representation Learning with Target Coding", 
                            "value": 64.77, 
                            "label": "Deep Representation Learn...", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-01", 
                            "algorithms": [], 
                            "max_date": "2015-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-01-01", 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 67.38, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "HD-CNN", 
                            "minval": 67.38, 
                            "url": "https://sites.google.com/site/homepagezhichengyan/home/hdcnn", 
                            "papername": "HD-CNN: Hierarchical Deep Convolutional Neural Network for Large Scale Visual Recognition", 
                            "value": 67.38, 
                            "label": "HD-CNN", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-01", 
                            "algorithms": [], 
                            "max_date": "2015-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-01-01", 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 68.53, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MLR DNN", 
                            "minval": 68.53, 
                            "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7258343", 
                            "papername": "Multi-Loss Regularized Deep Neural Network", 
                            "value": 68.53, 
                            "label": "MLR DNN", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-01", 
                            "algorithms": [], 
                            "max_date": "2015-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-01-01", 
                            "notes": "With data augmentation, 65.82% without. Based on NiN architecture.", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 67.68, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DCNN+GFE", 
                            "minval": 67.68, 
                            "url": "http://www.isip.uni-luebeck.de/fileadmin/uploads/tx_wapublications/hertel_ijcnn_2015.pdf", 
                            "papername": "Deep Convolutional Neural Networks as Generic Feature Extractors", 
                            "value": 67.68, 
                            "label": "DCNN+GFE", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-12", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "feature extraction part of convnet is trained on imagenet (external training data), classification part is trained on cifar-100", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 59.75, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RReLU", 
                            "minval": 59.75, 
                            "url": "https://arxiv.org/abs/1505.00853", 
                            "papername": "Empirical Evaluation of Rectified Activations in Convolution Network", 
                            "value": 59.75, 
                            "label": "RReLU", 
                            "algorithm_src_url": "", 
                            "date": "2015-08-16", 
                            "algorithms": [], 
                            "max_date": "2015-11-27", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-05-05", 
                            "notes": "Using Randomized Leaky ReLU", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 71.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MIM", 
                            "minval": 70.6, 
                            "url": "https://arxiv.org/abs/1508.00330", 
                            "papername": "On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units", 
                            "value": 70.8, 
                            "label": "MIM", 
                            "algorithm_src_url": "", 
                            "date": "2015-09-17", 
                            "algorithms": [], 
                            "max_date": "2015-11-01", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-08-03", 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 67.63, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Tree+Max-Avg pooling", 
                            "minval": 67.63, 
                            "url": "https://arxiv.org/abs/1509.08985", 
                            "papername": "Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree", 
                            "value": 67.63, 
                            "label": "Tree+Max-Avg pooling", 
                            "algorithm_src_url": "", 
                            "date": "2015-10-05", 
                            "algorithms": [], 
                            "max_date": "2015-10-10", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-09-30", 
                            "notes": "Single model without data augmentation", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 69.12, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SWWAE", 
                            "minval": 69.12, 
                            "url": "https://arxiv.org/abs/1506.02351", 
                            "papername": "Stacked What-Where Auto-encoders", 
                            "value": 69.12, 
                            "label": "SWWAE", 
                            "algorithm_src_url": "", 
                            "date": "2015-10-11", 
                            "algorithms": [], 
                            "max_date": "2016-02-14", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-06-08", 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 71.14, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "BNM NiN", 
                            "minval": 71.14, 
                            "url": "https://arxiv.org/abs/1511.02583", 
                            "papername": "Batch-normalized Maxout Network in Network", 
                            "value": 71.14, 
                            "label": "BNM NiN", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-09", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "(k=5 maxout pieces in each maxout unit).", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 72.44, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "CMsC", 
                            "minval": 72.44, 
                            "url": "https://arxiv.org/abs/1511.05635", 
                            "papername": "Competitive Multi-scale Convolution", 
                            "value": 72.44, 
                            "label": "CMsC", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-18", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 67.76, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "VDN", 
                            "minval": 67.76, 
                            "url": "http://people.idsia.ch/~rupesh/very_deep_learning/", 
                            "papername": "Training Very Deep Networks", 
                            "value": 67.76, 
                            "label": "VDN", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Best result selected on test set. 67.61% average over multiple trained models.", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 68.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Spectral Representations for Convolutional Neural Networks", 
                            "minval": 68.4, 
                            "url": "http://papers.nips.cc/paper/5649-spectral-representations-for-convolutional-neural-networks.pdf", 
                            "papername": "Spectral Representations for Convolutional Neural Networks", 
                            "value": 68.4, 
                            "label": "Spectral Representations ...", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 72.34, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Fitnet4-LSUV", 
                            "minval": 72.34, 
                            "url": "https://arxiv.org/abs/1511.06422", 
                            "papername": "All you need is a good init", 
                            "value": 72.34, 
                            "label": "Fitnet4-LSUV", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-04", 
                            "algorithms": [], 
                            "max_date": "2016-02-19", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-19", 
                            "notes": "Using RMSProp optimizer", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 75.72, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Exponential Linear Units", 
                            "minval": 75.72, 
                            "url": "https://arxiv.org/abs/1511.07289", 
                            "papername": "Fast and Accurate Deep Network Learning by Exponential Linear Units", 
                            "value": 75.72, 
                            "label": "Exponential Linear Units", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-07", 
                            "algorithms": [], 
                            "max_date": "2016-02-22", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-23", 
                            "notes": "Without data augmentation.", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 67.16, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Universum Prescription", 
                            "minval": 67.16, 
                            "url": "https://arxiv.org/abs/1511.03719", 
                            "papername": "Universum Prescription: Regularization using Unlabeled Data", 
                            "value": 67.16, 
                            "label": "Universum Prescription", 
                            "algorithm_src_url": "", 
                            "date": "2016-05-15", 
                            "algorithms": [], 
                            "max_date": "2016-11-18", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-11", 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 77.50999999999999, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ResNet-1001", 
                            "minval": 77.07, 
                            "url": "https://arxiv.org/abs/1603.05027", 
                            "papername": "Identity Mappings in Deep Residual Networks", 
                            "value": 77.28999999999999, 
                            "label": "ResNet-1001", 
                            "algorithm_src_url": "", 
                            "date": "2016-05-20", 
                            "algorithms": [], 
                            "max_date": "2016-07-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-03-16", 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 69.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "NiN+Superclass+CDJ", 
                            "minval": 69.0, 
                            "url": "https://arxiv.org/abs/1706.02003", 
                            "papername": "Deep Convolutional Decision Jungle for Image Classification", 
                            "value": 69.0, 
                            "label": "NiN+Superclass+CDJ", 
                            "algorithm_src_url": "", 
                            "date": "2017-06-06", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/awty.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": null
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/awty.py#L165", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "CIFAR-10 Image Recognition", 
                    "parent": "Problem(Image classification)", 
                    "url": "http://https://www.cs.toronto.edu/~kriz/cifar.html", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 79.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "An Analysis of Single-Layer Networks in Unsupervised Feature Learning ", 
                            "minval": 79.6, 
                            "url": "http://www.stanford.edu/~acoates/papers/coatesleeng_aistats_2011.pdf", 
                            "papername": "An Analysis of Single-Layer Networks in Unsupervised Feature Learning ", 
                            "value": 79.6, 
                            "label": "An Analysis of Single-Lay...", 
                            "algorithm_src_url": "", 
                            "date": "2011-07-01", 
                            "algorithms": [], 
                            "max_date": "2011-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2011-01-01", 
                            "notes": "6% obtained using K-means over whitened patches, with triangle encoding and 4000 features (clusters).", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 80.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Hierarchical Kernel Descriptors", 
                            "minval": 80.0, 
                            "url": "http://research.cs.washington.edu/istc/lfb/paper/cvpr11.pdf", 
                            "papername": "Object Recognition with Hierarchical Kernel Descriptors", 
                            "value": 80.0, 
                            "label": "Hierarchical Kernel Descr...", 
                            "algorithm_src_url": "", 
                            "date": "2011-07-01", 
                            "algorithms": [], 
                            "max_date": "2011-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2011-01-01", 
                            "notes": "", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 88.79, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MCDNN", 
                            "minval": 88.79, 
                            "url": "http://www.idsia.ch/~ciresan/data/cvpr2012.pdf", 
                            "papername": "Multi-Column Deep Neural Networks for Image Classification ", 
                            "value": 88.79, 
                            "label": "MCDNN", 
                            "algorithm_src_url": "", 
                            "date": "2012-06-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Supplemental material, Technical Report", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 82.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Local Transformations", 
                            "minval": 82.2, 
                            "url": "http://icml.cc/2012/papers/659.pdf", 
                            "papername": "Learning Invariant Representations with Local Transformations", 
                            "value": 82.2, 
                            "label": "Local Transformations", 
                            "algorithm_src_url": "", 
                            "date": "2012-06-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "K= 4,000", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 84.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Improving neural networks by preventing co-adaptation of feature detectors", 
                            "minval": 84.4, 
                            "url": "https://arxiv.org/abs/1207.0580", 
                            "papername": "Improving neural networks by preventing co-adaptation of feature detectors", 
                            "value": 84.4, 
                            "label": "Improving neural networks...", 
                            "algorithm_src_url": "", 
                            "date": "2012-07-03", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "So called \"dropout\" method.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 79.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Learning with Recursive Perceptual Representations", 
                            "minval": 79.7, 
                            "url": "http://papers.nips.cc/paper/4747-learning-with-recursive-perceptual-representations", 
                            "papername": "Learning with Recursive Perceptual Representations", 
                            "value": 79.7, 
                            "label": "Learning with Recursive P...", 
                            "algorithm_src_url": "", 
                            "date": "2012-12-03", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Code size 1600.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 83.96, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Discriminative Learning of Sum-Product Networks", 
                            "minval": 83.96, 
                            "url": "http://papers.nips.cc/paper/4516-discriminative-learning-of-sum-product-networks", 
                            "papername": "Discriminative Learning of Sum-Product Networks", 
                            "value": 83.96, 
                            "label": "Discriminative Learning o...", 
                            "algorithm_src_url": "", 
                            "date": "2012-12-03", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 89.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DCNN", 
                            "minval": 89.0, 
                            "url": "http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks", 
                            "papername": "ImageNet Classification with Deep Convolutional Neural Networks", 
                            "value": 89.0, 
                            "label": "DCNN", 
                            "algorithm_src_url": "", 
                            "date": "2012-12-03", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "87% error on the unaugmented data.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 90.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "GP EI", 
                            "minval": 90.5, 
                            "url": "http://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf", 
                            "papername": "Practical Bayesian Optimization of Machine Learning Algorithms ", 
                            "value": 90.5, 
                            "label": "GP EI", 
                            "algorithm_src_url": "", 
                            "date": "2012-12-03", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Reaches 85.02% without data augmentation. With data augmented with horizontal reflections and translations, 90.5% accuracy on test set is achieved.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 84.87, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Stochastic Pooling", 
                            "minval": 84.87, 
                            "url": "https://arxiv.org/abs/1301.3557", 
                            "papername": "Stochastic Pooling for Regularization of Deep Convolutional Neural Networks", 
                            "value": 84.87, 
                            "label": "Stochastic Pooling", 
                            "algorithm_src_url": "", 
                            "date": "2013-01-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 90.65, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Maxout Networks", 
                            "minval": 90.65, 
                            "url": "http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf", 
                            "papername": "Maxout Networks", 
                            "value": 90.65, 
                            "label": "Maxout Networks", 
                            "algorithm_src_url": "", 
                            "date": "2013-06-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "This result was obtained using both convolution and synthetic translations / horizontal reflections of the training data. Reaches 88.32% when using convolution, but without any synthetic transformations of the training data.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 90.68, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DropConnect", 
                            "minval": 90.68, 
                            "url": "http://cs.nyu.edu/~wanli/dropc/", 
                            "papername": "Regularization of Neural Networks using DropConnect", 
                            "value": 90.68, 
                            "label": "DropConnect", 
                            "algorithm_src_url": "", 
                            "date": "2013-06-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 80.02, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Smooth Pooling Regions", 
                            "minval": 80.02, 
                            "url": "http://www.d2.mpi-inf.mpg.de/content/learning-smooth-pooling-regions-visual-recognition", 
                            "papername": "Learning Smooth Pooling Regions for Visual Recognition", 
                            "value": 80.02, 
                            "label": "Smooth Pooling Regions", 
                            "algorithm_src_url": "", 
                            "date": "2013-07-01", 
                            "algorithms": [], 
                            "max_date": "2013-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2013-01-01", 
                            "notes": "", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 90.61, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DNN+Probabilistic Maxout", 
                            "minval": 90.61, 
                            "url": "http://openreview.net/document/28d9c3ab-fe88-4836-b898-403d207a037c#28d9c3ab-fe88-4836-b898-403d207a037c", 
                            "papername": "Improving Deep Neural Networks with Probabilistic Maxout Units", 
                            "value": 90.61, 
                            "label": "DNN+Probabilistic Maxout", 
                            "algorithm_src_url": "", 
                            "date": "2014-04-14", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "65% without data augmentation. 61% when using data augmentation.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 91.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "NiN", 
                            "minval": 91.2, 
                            "url": "http://openreview.net/document/9b05a3bb-3a5e-49cb-91f7-0f482af65aea#9b05a3bb-3a5e-49cb-91f7-0f482af65aea", 
                            "papername": "Network In Network", 
                            "value": 91.2, 
                            "label": "NiN", 
                            "algorithm_src_url": "", 
                            "date": "2014-04-14", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "The code for NIN available at https://github.com/mavenlin/cuda-convnet NIN + Dropout 89.6% NIN + Dropout + Data Augmentation 91.2%", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 78.67, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "PCANet", 
                            "minval": 78.67, 
                            "url": "https://arxiv.org/abs/1404.3606", 
                            "papername": "PCANet: A Simple Deep Learning Baseline for Image Classification?", 
                            "value": 78.67, 
                            "label": "PCANet", 
                            "algorithm_src_url": "", 
                            "date": "2014-06-21", 
                            "algorithms": [], 
                            "max_date": "2014-08-28", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-04-14", 
                            "notes": "No data augmentation. Multiple feature scales combined. 77.14% when using only a single scale.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 82.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nonnegativity Constraints ", 
                            "minval": 82.9, 
                            "url": "http://jmlr.org/proceedings/papers/v32/line14.pdf", 
                            "papername": "Stable and Efficient Representation Learning with Nonnegativity Constraints ", 
                            "value": 82.9, 
                            "label": "Nonnegativity Constraints ", 
                            "algorithm_src_url": "", 
                            "date": "2014-06-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Full data, 3-layers + multi-dict. 4 with 3-layers only. 0 with 1-layers only.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 91.78, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DSN", 
                            "minval": 91.78, 
                            "url": "http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/", 
                            "papername": "Deeply-Supervised Nets", 
                            "value": 91.78, 
                            "label": "DSN", 
                            "algorithm_src_url": "", 
                            "date": "2014-07-01", 
                            "algorithms": [], 
                            "max_date": "2014-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-01-01", 
                            "notes": "Single model, with data augmentation: 91.78%. Without data augmentation: 90.22%.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 82.18, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "CKN", 
                            "minval": 82.18, 
                            "url": "https://arxiv.org/abs/1406.3332", 
                            "papername": "Convolutional Kernel Networks", 
                            "value": 82.18, 
                            "label": "CKN", 
                            "algorithm_src_url": "", 
                            "date": "2014-08-28", 
                            "algorithms": [], 
                            "max_date": "2014-11-14", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-06-12", 
                            "notes": "No data augmentation.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 93.72, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SSCNN", 
                            "minval": 93.72, 
                            "url": "https://arxiv.org/abs/1409.6070", 
                            "papername": "Spatially-sparse convolutional neural networks", 
                            "value": 93.72, 
                            "label": "SSCNN", 
                            "algorithm_src_url": "", 
                            "date": "2014-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 82.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Discriminative Unsupervised Feature Learning with Convolutional Neural Networks", 
                            "minval": 82.0, 
                            "url": "http://papers.nips.cc/paper/5548-discriminative-unsupervised-feature-learning-with-convolutional-neural-networks.pdf", 
                            "papername": "Discriminative Unsupervised Feature Learning with Convolutional Neural Networks", 
                            "value": 82.0, 
                            "label": "Discriminative Unsupervis...", 
                            "algorithm_src_url": "", 
                            "date": "2014-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Unsupervised feature learning + linear SVM", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 90.78, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep Networks with Internal Selective Attention through Feedback Connections", 
                            "minval": 90.78, 
                            "url": "http://papers.nips.cc/paper/5276-deep-networks-with-internal-selective-attention-through-feedback-connections.pdf", 
                            "papername": "Deep Networks with Internal Selective Attention through Feedback Connections", 
                            "value": 90.78, 
                            "label": "Deep Networks with Intern...", 
                            "algorithm_src_url": "", 
                            "date": "2014-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "No data augmentation", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 86.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "An Analysis of Unsupervised Pre-training in Light of Recent Advances", 
                            "minval": 86.7, 
                            "url": "https://arxiv.org/abs/1412.6597", 
                            "papername": "An Analysis of Unsupervised Pre-training in Light of Recent Advances", 
                            "value": 86.7, 
                            "label": "An Analysis of Unsupervis...", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-13", 
                            "algorithms": [], 
                            "max_date": "2015-04-10", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-12-20", 
                            "notes": "Unsupervised pre-training, with supervised fine-tuning. Uses dropout and data-augmentation.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 95.59, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ACN", 
                            "minval": 95.59, 
                            "url": "https://arxiv.org/abs/1412.6806", 
                            "papername": "Striving for Simplicity: The All Convolutional Net", 
                            "value": 95.59, 
                            "label": "ACN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-15", 
                            "algorithms": [], 
                            "max_date": "2015-04-13", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-12-21", 
                            "notes": "92% without data augmentation, 92.75% with small data augmentation, 95.59% when using agressive data augmentation and larger network.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 92.49, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "NiN+APL", 
                            "minval": 92.49, 
                            "url": "https://arxiv.org/abs/1412.6830", 
                            "papername": "Learning Activation Functions to Improve Deep Neural Networks", 
                            "value": 92.49, 
                            "label": "NiN+APL", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-19", 
                            "algorithms": [], 
                            "max_date": "2015-04-21", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-12-21", 
                            "notes": "Uses an adaptive piecewise linear activation function. 92.49% accuracy with data augmentation and 90.41% accuracy without data augmentation.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 96.53, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Fractional MP", 
                            "minval": 96.53, 
                            "url": "https://arxiv.org/abs/1412.6071", 
                            "papername": "Fractional Max-Pooling", 
                            "value": 96.53, 
                            "label": "Fractional MP", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-28", 
                            "algorithms": [], 
                            "max_date": "2015-05-12", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-12-18", 
                            "notes": "Uses 100 passes at test time. Reaches 95.5% when using a single pass at test time, and 96.33% when using 12 passes.. Uses data augmentation during training.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 93.63, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Tuned CNN", 
                            "minval": 93.63, 
                            "url": "https://arxiv.org/abs/1502.05700", 
                            "papername": "Scalable Bayesian Optimization Using Deep Neural Networks", 
                            "value": 93.63, 
                            "label": "Tuned CNN", 
                            "algorithm_src_url": "", 
                            "date": "2015-05-02", 
                            "algorithms": [], 
                            "max_date": "2015-07-13", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-02-19", 
                            "notes": "", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 89.67, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "APAC", 
                            "minval": 89.67, 
                            "url": "https://arxiv.org/abs/1505.03229", 
                            "papername": "APAC: Augmented PAttern Classification with Neural Networks", 
                            "value": 89.67, 
                            "label": "APAC", 
                            "algorithm_src_url": "", 
                            "date": "2015-05-13", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 75.86, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "FLSCNN", 
                            "minval": 75.86, 
                            "url": "https://arxiv.org/abs/1503.04596", 
                            "papername": "Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network", 
                            "value": 75.86, 
                            "label": "FLSCNN", 
                            "algorithm_src_url": "", 
                            "date": "2015-05-31", 
                            "algorithms": [], 
                            "max_date": "2015-08-15", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-03-16", 
                            "notes": "No data augmentation", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 92.91, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RCNN-96", 
                            "minval": 92.91, 
                            "url": "http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_004.pdf", 
                            "papername": "Recurrent Convolutional Neural Network for Object Recognition", 
                            "value": 92.91, 
                            "label": "RCNN-96", 
                            "algorithm_src_url": "", 
                            "date": "2015-06-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Reaches 91.31% without data augmentation.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 87.65, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ReNet", 
                            "minval": 87.65, 
                            "url": "https://arxiv.org/abs/1505.00393", 
                            "papername": "ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks", 
                            "value": 87.65, 
                            "label": "ReNet", 
                            "algorithm_src_url": "", 
                            "date": "2015-06-12", 
                            "algorithms": [], 
                            "max_date": "2015-07-23", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-05-03", 
                            "notes": "", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 91.19, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ELC", 
                            "minval": 91.19, 
                            "url": "http://aad.informatik.uni-freiburg.de/papers/15-IJCAI-Extrapolation_of_Learning_Curves.pdf", 
                            "papername": "Speeding up Automatic Hyperparameter Optimization of Deep Neural Networks by Extrapolation of Learning Curves", 
                            "value": 91.19, 
                            "label": "ELC", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-01", 
                            "algorithms": [], 
                            "max_date": "2015-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-01-01", 
                            "notes": "Based on the \"call convolutional\" architecture. which reaches 90.92% by itself.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 91.88, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MLR DNN", 
                            "minval": 91.88, 
                            "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7258343", 
                            "papername": "Multi-Loss Regularized Deep Neural Network", 
                            "value": 91.88, 
                            "label": "MLR DNN", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-01", 
                            "algorithms": [], 
                            "max_date": "2015-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-01-01", 
                            "notes": "With data augmentation, 90.45% without. Based on NiN architecture.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 92.45, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "cifar.torch", 
                            "minval": 92.45, 
                            "url": "http://torch.ch/blog/2015/07/30/cifar.html", 
                            "papername": "cifar.torch", 
                            "value": 92.45, 
                            "label": "cifar.torch", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-01", 
                            "algorithms": [], 
                            "max_date": "2015-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-01-01", 
                            "notes": "Code available at https://github.com/szagoruyko/cifar.torch", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 89.14, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DCNN+GFE", 
                            "minval": 89.14, 
                            "url": "http://www.isip.uni-luebeck.de/fileadmin/uploads/tx_wapublications/hertel_ijcnn_2015.pdf", 
                            "papername": "Deep Convolutional Neural Networks as Generic Feature Extractors", 
                            "value": 89.14, 
                            "label": "DCNN+GFE", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-12", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "feature extraction part of convnet is trained on imagenet (external training data), classification part is trained on cifar-10", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 88.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RReLU", 
                            "minval": 88.8, 
                            "url": "https://arxiv.org/abs/1505.00853", 
                            "papername": "Empirical Evaluation of Rectified Activations in Convolution Network", 
                            "value": 88.8, 
                            "label": "RReLU", 
                            "algorithm_src_url": "", 
                            "date": "2015-08-16", 
                            "algorithms": [], 
                            "max_date": "2015-11-27", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-05-05", 
                            "notes": "Using Randomized Leaky ReLU", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 91.68, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MIM", 
                            "minval": 91.28, 
                            "url": "https://arxiv.org/abs/1508.00330", 
                            "papername": "On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units", 
                            "value": 91.48, 
                            "label": "MIM", 
                            "algorithm_src_url": "", 
                            "date": "2015-09-17", 
                            "algorithms": [], 
                            "max_date": "2015-11-01", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-08-03", 
                            "notes": "", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 93.95, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Tree+Max-Avg pooling", 
                            "minval": 93.95, 
                            "url": "https://arxiv.org/abs/1509.08985", 
                            "papername": "Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree", 
                            "value": 93.95, 
                            "label": "Tree+Max-Avg pooling", 
                            "algorithm_src_url": "", 
                            "date": "2015-10-05", 
                            "algorithms": [], 
                            "max_date": "2015-10-10", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-09-30", 
                            "notes": "Single model with data augmentation, 92.38% without.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 92.23, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SWWAE", 
                            "minval": 92.23, 
                            "url": "https://arxiv.org/abs/1506.02351", 
                            "papername": "Stacked What-Where Auto-encoders", 
                            "value": 92.23, 
                            "label": "SWWAE", 
                            "algorithm_src_url": "", 
                            "date": "2015-10-11", 
                            "algorithms": [], 
                            "max_date": "2016-02-14", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-06-08", 
                            "notes": "", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 93.25, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "BNM NiN", 
                            "minval": 93.25, 
                            "url": "https://arxiv.org/abs/1511.02583", 
                            "papername": "Batch-normalized Maxout Network in Network", 
                            "value": 93.25, 
                            "label": "BNM NiN", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-09", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "(k=5 maxout pieces in each maxout unit). Reaches 92.15% without data augmentation.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 93.13, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "CMsC", 
                            "minval": 93.13, 
                            "url": "https://arxiv.org/abs/1511.05635", 
                            "papername": "Competitive Multi-scale Convolution", 
                            "value": 93.13, 
                            "label": "CMsC", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-18", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 91.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Spectral Representations for Convolutional Neural Networks", 
                            "minval": 91.4, 
                            "url": "http://papers.nips.cc/paper/5649-spectral-representations-for-convolutional-neural-networks.pdf", 
                            "papername": "Spectral Representations for Convolutional Neural Networks", 
                            "value": 91.4, 
                            "label": "Spectral Representations ...", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 91.73, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "BinaryConnect", 
                            "minval": 91.73, 
                            "url": "http://papers.nips.cc/paper/5647-binaryconnect-training-deep-neural-networks-with-binary-weights-during-propagations.pdf", 
                            "papername": "BinaryConnect: Training Deep Neural Networks with binary weights during propagations", 
                            "value": 91.73, 
                            "label": "BinaryConnect", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "These results were obtained without using any data-augmentation.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 92.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "VDN", 
                            "minval": 92.4, 
                            "url": "http://people.idsia.ch/~rupesh/very_deep_learning/", 
                            "papername": "Training Very Deep Networks", 
                            "value": 92.4, 
                            "label": "VDN", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Best result selected on test set. 92.31% average over multiple trained models.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 93.57, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DRL", 
                            "minval": 93.57, 
                            "url": "https://arxiv.org/abs/1512.03385", 
                            "papername": "Deep Residual Learning for Image Recognition", 
                            "value": 93.57, 
                            "label": "DRL", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Best performance reached with 110 layers. Using 1202 layers leads to 92.07%, 56 layers lead to 93.03%.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 94.16, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Fitnet4-LSUV", 
                            "minval": 94.16, 
                            "url": "https://arxiv.org/abs/1511.06422", 
                            "papername": "All you need is a good init", 
                            "value": 94.16, 
                            "label": "Fitnet4-LSUV", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-04", 
                            "algorithms": [], 
                            "max_date": "2016-02-19", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-19", 
                            "notes": "Only mirroring and random shifts, no extreme data augmentation. Uses thin deep residual net with maxout activations.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 93.45, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Exponential Linear Units", 
                            "minval": 93.45, 
                            "url": "https://arxiv.org/abs/1511.07289", 
                            "papername": "Fast and Accurate Deep Network Learning by Exponential Linear Units", 
                            "value": 93.45, 
                            "label": "Exponential Linear Units", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-07", 
                            "algorithms": [], 
                            "max_date": "2016-02-22", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-23", 
                            "notes": "Without data augmentation.", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 93.34, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Universum Prescription", 
                            "minval": 93.34, 
                            "url": "https://arxiv.org/abs/1511.03719", 
                            "papername": "Universum Prescription: Regularization using Unlabeled Data", 
                            "value": 93.34, 
                            "label": "Universum Prescription", 
                            "algorithm_src_url": "", 
                            "date": "2016-05-15", 
                            "algorithms": [], 
                            "max_date": "2016-11-18", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-11", 
                            "notes": "", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 95.58, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ResNet-1001", 
                            "minval": 95.17999999999999, 
                            "url": "https://arxiv.org/abs/1603.05027", 
                            "papername": "Identity Mappings in Deep Residual Networks", 
                            "value": 95.38, 
                            "label": "ResNet-1001", 
                            "algorithm_src_url": "", 
                            "date": "2016-05-20", 
                            "algorithms": [], 
                            "max_date": "2016-07-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-03-16", 
                            "notes": "", 
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "data/awty.py", 
                    "target_source": "http://karpathy.github.io/2011/04/27/manually-classifying-cifar10/", 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": 94
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/awty.py#L82", 
                    "scale": "Percentage error", 
                    "target_label": null, 
                    "name": "Street View House Numbers (SVHN)", 
                    "parent": "Problem(Image classification)", 
                    "url": "http://ufldl.stanford.edu/housenumbers/", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Convolutional neural networks applied to house numbers digit classification", 
                            "minval": 4.9, 
                            "url": "http://yann.lecun.com/exdb/publis/pdf/sermanet-icpr-12.pdf", 
                            "papername": "Convolutional neural networks applied to house numbers digit classification", 
                            "value": 4.9, 
                            "label": "Convolutional neural netw...", 
                            "algorithm_src_url": "", 
                            "date": "2012-07-01", 
                            "algorithms": [], 
                            "max_date": "2012-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2012-01-01", 
                            "notes": "ConvNet / MS / L4 / Padded", 
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Stochastic Pooling", 
                            "minval": 2.8, 
                            "url": "https://arxiv.org/abs/1301.3557", 
                            "papername": "Stochastic Pooling for Regularization of Deep Convolutional Neural Networks", 
                            "value": 2.8, 
                            "label": "Stochastic Pooling", 
                            "algorithm_src_url": "", 
                            "date": "2013-01-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "64-64-128 Stochastic Pooling", 
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.94, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Regularization of Neural Networks using DropConnect", 
                            "minval": 1.94, 
                            "url": "http://cs.nyu.edu/~wanli/dropc/", 
                            "papername": "Regularization of Neural Networks using DropConnect", 
                            "value": 1.94, 
                            "label": "Regularization of Neural ...", 
                            "algorithm_src_url": "", 
                            "date": "2013-06-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2.47, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Maxout", 
                            "minval": 2.47, 
                            "url": "http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf", 
                            "papername": "Maxout Networks", 
                            "value": 2.47, 
                            "label": "Maxout", 
                            "algorithm_src_url": "", 
                            "date": "2013-06-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "This result was obtained using convolution but not any synthetic transformations of the training data.", 
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2.16, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DCNN", 
                            "minval": 2.16, 
                            "url": "http://openreview.net/document/0c571b22-f4b6-4d58-87e4-99d7de42a893#0c571b22-f4b6-4d58-87e4-99d7de42a893", 
                            "papername": "Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks", 
                            "value": 2.16, 
                            "label": "DCNN", 
                            "algorithm_src_url": "", 
                            "date": "2014-04-14", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "For classification of individual digits with a single network, error rate is 2.16%. For classification of the entire digit sequence (first paper doing this): error rate of 3.97%.", 
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2.35, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "NiN", 
                            "minval": 2.35, 
                            "url": "http://openreview.net/document/9b05a3bb-3a5e-49cb-91f7-0f482af65aea#9b05a3bb-3a5e-49cb-91f7-0f482af65aea", 
                            "papername": "Network in Network", 
                            "value": 2.35, 
                            "label": "NiN", 
                            "algorithm_src_url": "", 
                            "date": "2014-04-14", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "NIN + Dropout The code for NIN available at https://github.com/mavenlin/cuda-convnet", 
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.92, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DSN", 
                            "minval": 1.92, 
                            "url": "http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/", 
                            "papername": "Deeply-Supervised Nets", 
                            "value": 1.92, 
                            "label": "DSN", 
                            "algorithm_src_url": "", 
                            "date": "2014-07-01", 
                            "algorithms": [], 
                            "max_date": "2014-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-01-01", 
                            "notes": "", 
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3.96, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "FLSCNN", 
                            "minval": 3.96, 
                            "url": "https://arxiv.org/abs/1503.04596", 
                            "papername": "Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network", 
                            "value": 3.96, 
                            "label": "FLSCNN", 
                            "algorithm_src_url": "", 
                            "date": "2015-05-31", 
                            "algorithms": [], 
                            "max_date": "2015-08-15", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-03-16", 
                            "notes": "No data augmentation", 
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.77, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RCNN-96", 
                            "minval": 1.77, 
                            "url": "http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_004.pdf", 
                            "papername": "Recurrent Convolutional Neural Network for Object Recognition", 
                            "value": 1.77, 
                            "label": "RCNN-96", 
                            "algorithm_src_url": "", 
                            "date": "2015-06-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Without data augmentation", 
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2.38, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ReNet", 
                            "minval": 2.38, 
                            "url": "https://arxiv.org/abs/1505.00393", 
                            "papername": "ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks", 
                            "value": 2.38, 
                            "label": "ReNet", 
                            "algorithm_src_url": "", 
                            "date": "2015-06-12", 
                            "algorithms": [], 
                            "max_date": "2015-07-23", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-05-03", 
                            "notes": "", 
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.92, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MLR DNN", 
                            "minval": 1.92, 
                            "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7258343", 
                            "papername": "Multi-Loss Regularized Deep Neural Network", 
                            "value": 1.92, 
                            "label": "MLR DNN", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-01", 
                            "algorithms": [], 
                            "max_date": "2015-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-01-01", 
                            "notes": "Based on NiN architecture.", 
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2.05, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MIM", 
                            "minval": 1.89, 
                            "url": "https://arxiv.org/abs/1508.00330", 
                            "papername": "On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units", 
                            "value": 1.97, 
                            "label": "MIM", 
                            "algorithm_src_url": "", 
                            "date": "2015-09-17", 
                            "algorithms": [], 
                            "max_date": "2015-11-01", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-08-03", 
                            "notes": "", 
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.69, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Tree+Max-Avg pooling", 
                            "minval": 1.69, 
                            "url": "https://arxiv.org/abs/1509.08985", 
                            "papername": "Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree", 
                            "value": 1.69, 
                            "label": "Tree+Max-Avg pooling", 
                            "algorithm_src_url": "", 
                            "date": "2015-10-05", 
                            "algorithms": [], 
                            "max_date": "2015-10-10", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-09-30", 
                            "notes": "Single model without data augmentation", 
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.81, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "BNM NiN", 
                            "minval": 1.81, 
                            "url": "https://arxiv.org/abs/1511.02583", 
                            "papername": "Batch-normalized Maxout Network in Network", 
                            "value": 1.81, 
                            "label": "BNM NiN", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-09", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "(k=5 maxout pieces in each maxout unit).", 
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.76, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "CMsC", 
                            "minval": 1.76, 
                            "url": "https://arxiv.org/abs/1511.05635", 
                            "papername": "Competitive Multi-scale Convolution", 
                            "value": 1.76, 
                            "label": "CMsC", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-18", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2.15, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "BinaryConnect", 
                            "minval": 2.15, 
                            "url": "http://papers.nips.cc/paper/5647-binaryconnect-training-deep-neural-networks-with-binary-weights-during-propagations.pdf", 
                            "papername": "BinaryConnect: Training Deep Neural Networks with binary weights during propagations", 
                            "value": 2.15, 
                            "label": "BinaryConnect", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "data/awty.py", 
                    "target_source": "http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf", 
                    "changeable": false, 
                    "axis_label": "Percentage error", 
                    "target": 2.0
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/awty.py#L217", 
                    "scale": "Percentage error", 
                    "target_label": null, 
                    "name": "MNIST handwritten digit recognition", 
                    "parent": "Problem(Image classification)", 
                    "url": "http://yann.lecun.com/exdb/mnist/", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.56, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ISVM", 
                            "minval": 0.56, 
                            "url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.9924&rep=rep1&type=pdf", 
                            "papername": "Training Invariant Support Vector Machines", 
                            "value": 0.56, 
                            "label": "ISVM", 
                            "algorithm_src_url": "", 
                            "date": "2002-07-01", 
                            "algorithms": [], 
                            "max_date": "2002-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2002-01-01", 
                            "notes": "Virtual SVM, deg-9 poly, 2-pixel jittered (Preprocessing: deskewing)", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.63, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Shape contexts", 
                            "minval": 0.63, 
                            "url": "http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=B2AAC2BC3824F19757CAC66986D5F3FF?doi=10.1.1.18.8852&rep=rep1&type=pdf", 
                            "papername": "Shape matching and object recognition using shape contexts", 
                            "value": 0.63, 
                            "label": "Shape contexts", 
                            "algorithm_src_url": "", 
                            "date": "2002-07-01", 
                            "algorithms": [], 
                            "max_date": "2002-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2002-01-01", 
                            "notes": "K-NN, shape context matching (preprocessing: shape context feature extraction)", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis", 
                            "minval": 0.4, 
                            "url": "http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=D1C7D701BD39935473808DA5A93426C5?doi=10.1.1.160.8494&rep=rep1&type=pdf", 
                            "papername": "Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis", 
                            "value": 0.4, 
                            "label": "Best Practices for Convol...", 
                            "algorithm_src_url": "", 
                            "date": "2003-07-01", 
                            "algorithms": [], 
                            "max_date": "2003-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2003-01-01", 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.68, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "CNN+Gabor Filters", 
                            "minval": 0.68, 
                            "url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.133.6559&rep=rep1&type=pdf", 
                            "papername": "Handwritten Digit Recognition using Convolutional Neural Networks and Gabor Filters", 
                            "value": 0.68, 
                            "label": "CNN+Gabor Filters", 
                            "algorithm_src_url": "", 
                            "date": "2003-07-01", 
                            "algorithms": [], 
                            "max_date": "2003-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2003-01-01", 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.19, 
                            "long_label": false, 
                            "withdrawn": null, 
                            "name": "CNN", 
                            "minval": 1.19, 
                            "url": "", 
                            "papername": "Convolutional Neural Networks", 
                            "value": 1.19, 
                            "label": "CNN", 
                            "algorithm_src_url": "", 
                            "date": "2003-07-01", 
                            "algorithms": [], 
                            "max_date": "2003-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2003-01-01", 
                            "notes": "The ConvNN is based on the paper \"Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis\".", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.39, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Energy-Based Sparse Represenation", 
                            "minval": 0.39, 
                            "url": "http://papers.nips.cc/paper/3112-efficient-learning-of-sparse-representations-with-an-energy-based-model", 
                            "papername": "Efficient Learning of Sparse Representations with an Energy-Based Model", 
                            "value": 0.39, 
                            "label": "Energy-Based Sparse Repre...", 
                            "algorithm_src_url": "", 
                            "date": "2006-07-01", 
                            "algorithms": [], 
                            "max_date": "2006-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2006-01-01", 
                            "notes": "Large conv. net, unsup pretraining, uses elastic distortions", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.2, 
                            "long_label": false, 
                            "withdrawn": null, 
                            "name": "Reducing the dimensionality of data with neural networks", 
                            "minval": 1.2, 
                            "url": "", 
                            "papername": "Reducing the dimensionality of data with neural networks", 
                            "value": 1.2, 
                            "label": "Reducing the dimensionali...", 
                            "algorithm_src_url": "", 
                            "date": "2006-07-01", 
                            "algorithms": [], 
                            "max_date": "2006-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2006-01-01", 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.54, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deformation Models", 
                            "minval": 0.54, 
                            "url": "http://www.keysers.net/daniel/files/Keysers--Deformation-Models--TPAMI2007.pdf", 
                            "papername": "Deformation Models for Image Recognition", 
                            "value": 0.54, 
                            "label": "Deformation Models", 
                            "algorithm_src_url": "", 
                            "date": "2007-07-01", 
                            "algorithms": [], 
                            "max_date": "2007-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2007-01-01", 
                            "notes": "K-NN with non-linear deformation (IDM) (Preprocessing: shiftable edges)", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.54, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Trainable feature extractor", 
                            "minval": 0.54, 
                            "url": "http://hal.inria.fr/docs/00/05/75/61/PDF/LauerSuenBlochPR.pdf", 
                            "papername": "A trainable feature extractor for handwritten digit recognition", 
                            "value": 0.54, 
                            "label": "Trainable feature extractor", 
                            "algorithm_src_url": "", 
                            "date": "2007-07-01", 
                            "algorithms": [], 
                            "max_date": "2007-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2007-01-01", 
                            "notes": "Trainable feature extractor + SVMs, uses affine distortions", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.62, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "invariant feature hierarchies", 
                            "minval": 0.62, 
                            "url": "http://yann.lecun.com/exdb/publis/pdf/ranzato-cvpr-07.pdf", 
                            "papername": "Unsupervised learning of invariant feature hierarchies with applications to object recognition", 
                            "value": 0.62, 
                            "label": "invariant feature hierarc...", 
                            "algorithm_src_url": "", 
                            "date": "2007-07-01", 
                            "algorithms": [], 
                            "max_date": "2007-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2007-01-01", 
                            "notes": "Large conv. net, unsup features, no distortions", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.59, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Sparse Coding", 
                            "minval": 0.59, 
                            "url": "http://www.inb.uni-luebeck.de/publikationen/pdfs/LaBaMa08c.pdf", 
                            "papername": "Simple Methods for High-Performance Digit Recognition Based on Sparse Coding", 
                            "value": 0.59, 
                            "label": "Sparse Coding", 
                            "algorithm_src_url": "", 
                            "date": "2008-07-01", 
                            "algorithms": [], 
                            "max_date": "2008-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2008-01-01", 
                            "notes": "Unsupervised sparse features + SVM, no distortions", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.12, 
                            "long_label": false, 
                            "withdrawn": null, 
                            "name": "DBN", 
                            "minval": 1.12, 
                            "url": "", 
                            "papername": "CS81: Learning words with Deep Belief Networks", 
                            "value": 1.12, 
                            "label": "DBN", 
                            "algorithm_src_url": "", 
                            "date": "2008-07-01", 
                            "algorithms": [], 
                            "max_date": "2008-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2008-01-01", 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.5, 
                            "long_label": false, 
                            "withdrawn": null, 
                            "name": "Deep learning via semi-supervised embedding", 
                            "minval": 1.5, 
                            "url": "", 
                            "papername": "Deep learning via semi-supervised embedding", 
                            "value": 1.5, 
                            "label": "Deep learning via semi-su...", 
                            "algorithm_src_url": "", 
                            "date": "2008-07-01", 
                            "algorithms": [], 
                            "max_date": "2008-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2008-01-01", 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.53, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "The Best Multi-Stage Architecture", 
                            "minval": 0.53, 
                            "url": "http://yann.lecun.com/exdb/publis/pdf/jarrett-iccv-09.pdf", 
                            "papername": "What is the Best Multi-Stage Architecture for Object Recognition?", 
                            "value": 0.53, 
                            "label": "The Best Multi-Stage Arch...", 
                            "algorithm_src_url": "", 
                            "date": "2009-07-01", 
                            "algorithms": [], 
                            "max_date": "2009-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2009-01-01", 
                            "notes": "Large conv. net, unsup pretraining, no distortions", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.82, 
                            "long_label": false, 
                            "withdrawn": null, 
                            "name": "CDBN", 
                            "minval": 0.82, 
                            "url": "", 
                            "papername": "Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations", 
                            "value": 0.82, 
                            "label": "CDBN", 
                            "algorithm_src_url": "", 
                            "date": "2009-07-01", 
                            "algorithms": [], 
                            "max_date": "2009-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2009-01-01", 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.94, 
                            "long_label": false, 
                            "withdrawn": null, 
                            "name": "Large-Margin kNN", 
                            "minval": 0.94, 
                            "url": "", 
                            "papername": "Large-Margin kNN Classification using a Deep Encoder Network", 
                            "value": 0.94, 
                            "label": "Large-Margin kNN", 
                            "algorithm_src_url": "", 
                            "date": "2009-07-01", 
                            "algorithms": [], 
                            "max_date": "2009-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2009-01-01", 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.95, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep Boltzmann Machines", 
                            "minval": 0.95, 
                            "url": "http://www.utstat.toronto.edu/~rsalakhu/papers/dbm.pdf", 
                            "papername": "Deep Boltzmann Machines", 
                            "value": 0.95, 
                            "label": "Deep Boltzmann Machines", 
                            "algorithm_src_url": "", 
                            "date": "2009-07-01", 
                            "algorithms": [], 
                            "max_date": "2009-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2009-01-01", 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.35, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DBSNN", 
                            "minval": 0.35, 
                            "url": "https://arxiv.org/abs/1003.0358", 
                            "papername": "Deep Big Simple Neural Nets Excel on Handwritten Digit Recognition", 
                            "value": 0.35, 
                            "label": "DBSNN", 
                            "algorithm_src_url": "", 
                            "date": "2010-03-01", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "6-layer NN 784-2500-2000-1500-1000-500-10 (on GPU), uses elastic distortions", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.84, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Supervised Translation-Invariant Sparse Coding", 
                            "minval": 0.84, 
                            "url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.206.339&rep=rep1&type=pdf", 
                            "papername": "Supervised Translation-Invariant Sparse Coding", 
                            "value": 0.84, 
                            "label": "Supervised Translation-In...", 
                            "algorithm_src_url": "", 
                            "date": "2010-07-01", 
                            "algorithms": [], 
                            "max_date": "2010-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2010-01-01", 
                            "notes": "Uses sparse coding + svm.", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.69, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "On Optimization Methods for Deep Learning", 
                            "minval": 0.69, 
                            "url": "http://ai.stanford.edu/~quocle/LeNgiCoaLahProNg11.pdf", 
                            "papername": "On Optimization Methods for Deep Learning", 
                            "value": 0.69, 
                            "label": "On Optimization Methods f...", 
                            "algorithm_src_url": "", 
                            "date": "2011-07-01", 
                            "algorithms": [], 
                            "max_date": "2011-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2011-01-01", 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.23, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MCDNN", 
                            "minval": 0.23, 
                            "url": "http://www.idsia.ch/~ciresan/data/cvpr2012.pdf", 
                            "papername": "Multi-column Deep Neural Networks for Image Classification ", 
                            "value": 0.23, 
                            "label": "MCDNN", 
                            "algorithm_src_url": "", 
                            "date": "2012-06-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.64, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Receptive Field Learning", 
                            "minval": 0.64, 
                            "url": "http://www.icsi.berkeley.edu/pubs/vision/beyondspatial12.pdf", 
                            "papername": "Beyond Spatial Pyramids: Receptive Field Learning for Pooled Image Features", 
                            "value": 0.64, 
                            "label": "Receptive Field Learning", 
                            "algorithm_src_url": "", 
                            "date": "2012-06-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.52, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "COSFIRE", 
                            "minval": 0.52, 
                            "url": "http://www.cs.rug.nl/~george/articles/PAMI2013.pdf", 
                            "papername": "Trainable COSFIRE Filters for Keypoint Detection and Pattern Recognition", 
                            "value": 0.52, 
                            "label": "COSFIRE", 
                            "algorithm_src_url": "", 
                            "date": "2013-02-28", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.21, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DropConnect", 
                            "minval": 0.21, 
                            "url": "http://cs.nyu.edu/~wanli/dropc/", 
                            "papername": "Regularization of Neural Networks using DropConnect", 
                            "value": 0.21, 
                            "label": "DropConnect", 
                            "algorithm_src_url": "", 
                            "date": "2013-06-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.45, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Maxout Networks", 
                            "minval": 0.45, 
                            "url": "http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf", 
                            "papername": "Maxout Networks", 
                            "value": 0.45, 
                            "label": "Maxout Networks", 
                            "algorithm_src_url": "", 
                            "date": "2013-06-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Uses convolution. Does not use dataset augmentation.", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.75, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Sparse Activity and Sparse Connectivity in Supervised Learning", 
                            "minval": 0.75, 
                            "url": "http://jmlr.org/papers/v14/thom13a.html", 
                            "papername": "Sparse Activity and Sparse Connectivity in Supervised Learning", 
                            "value": 0.75, 
                            "label": "Sparse Activity and Spars...", 
                            "algorithm_src_url": "", 
                            "date": "2013-07-01", 
                            "algorithms": [], 
                            "max_date": "2013-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2013-01-01", 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.47, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "NiN", 
                            "minval": 0.47, 
                            "url": "http://openreview.net/document/9b05a3bb-3a5e-49cb-91f7-0f482af65aea#9b05a3bb-3a5e-49cb-91f7-0f482af65aea", 
                            "papername": "Network in Network", 
                            "value": 0.47, 
                            "label": "NiN", 
                            "algorithm_src_url": "", 
                            "date": "2014-04-14", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "NIN + Dropout The code for NIN available at https://github.com/mavenlin/cuda-convnet", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.62, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "PCANet", 
                            "minval": 0.62, 
                            "url": "https://arxiv.org/abs/1404.3606", 
                            "papername": "PCANet: A Simple Deep Learning Baseline for Image Classification?", 
                            "value": 0.62, 
                            "label": "PCANet", 
                            "algorithm_src_url": "", 
                            "date": "2014-06-21", 
                            "algorithms": [], 
                            "max_date": "2014-08-28", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-04-14", 
                            "notes": "No data augmentation.", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.39, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DSN", 
                            "minval": 0.39, 
                            "url": "http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/", 
                            "papername": "Deeply-Supervised Nets", 
                            "value": 0.39, 
                            "label": "DSN", 
                            "algorithm_src_url": "", 
                            "date": "2014-07-01", 
                            "algorithms": [], 
                            "max_date": "2014-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-01-01", 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "StrongNet", 
                            "minval": 1.1, 
                            "url": "http://www.alglib.net/articles/tr-20140813-strongnet.pdf", 
                            "papername": "StrongNet: mostly unsupervised image recognition with strong neurons", 
                            "value": 1.1, 
                            "label": "StrongNet", 
                            "algorithm_src_url": "", 
                            "date": "2014-07-01", 
                            "algorithms": [], 
                            "max_date": "2014-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-01-01", 
                            "notes": "StrongNet is a neural design which uses two innovations: (a) strong neurons - highly nonlinear neurons with multiple outputs and (b) mostly unsupervised architecture  backpropagation-free design with all layers except for the last one being trained in a completely unsupervised setting.", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.39, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "CKN", 
                            "minval": 0.39, 
                            "url": "https://arxiv.org/abs/1406.3332", 
                            "papername": "Convolutional Kernel Networks", 
                            "value": 0.39, 
                            "label": "CKN", 
                            "algorithm_src_url": "", 
                            "date": "2014-08-28", 
                            "algorithms": [], 
                            "max_date": "2014-11-14", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-06-12", 
                            "notes": "No data augmentation.", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.78, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Explaining and Harnessing Adversarial Examples", 
                            "minval": 0.78, 
                            "url": "https://arxiv.org/abs/1412.6572", 
                            "papername": "Explaining and Harnessing Adversarial Examples", 
                            "value": 0.78, 
                            "label": "Explaining and Harnessing...", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-03", 
                            "algorithms": [], 
                            "max_date": "2015-03-20", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-12-20", 
                            "notes": "permutation invariant network used", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.32, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Fractional MP", 
                            "minval": 0.32, 
                            "url": "https://arxiv.org/abs/1412.6071", 
                            "papername": "Fractional Max-Pooling", 
                            "value": 0.32, 
                            "label": "Fractional MP", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-28", 
                            "algorithms": [], 
                            "max_date": "2015-05-12", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-12-18", 
                            "notes": "Uses 12 passes at test time. Reaches 0.5% when using a single pass at test time.", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.35, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C-SVDDNet", 
                            "minval": 0.35, 
                            "url": "https://arxiv.org/abs/1412.7259", 
                            "papername": "C-SVDDNet: An Effective Single-Layer Network for Unsupervised Feature Learning", 
                            "value": 0.35, 
                            "label": "C-SVDDNet", 
                            "algorithm_src_url": "", 
                            "date": "2015-03-11", 
                            "algorithms": [], 
                            "max_date": "2015-05-29", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-12-23", 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "HOPE", 
                            "minval": 0.4, 
                            "url": "https://arxiv.org/abs/1502.00702", 
                            "papername": "Hybrid Orthogonal Projection and Estimation (HOPE): A New Framework to Probe and Learn Neural Networks", 
                            "value": 0.4, 
                            "label": "HOPE", 
                            "algorithm_src_url": "", 
                            "date": "2015-04-05", 
                            "algorithms": [], 
                            "max_date": "2015-06-06", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-02-03", 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.23, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "APAC", 
                            "minval": 0.23, 
                            "url": "https://arxiv.org/abs/1505.03229", 
                            "papername": "APAC: Augmented PAttern Classification with Neural Networks", 
                            "value": 0.23, 
                            "label": "APAC", 
                            "algorithm_src_url": "", 
                            "date": "2015-05-13", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.37, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "FLSCNN", 
                            "minval": 0.37, 
                            "url": "https://arxiv.org/abs/1503.04596", 
                            "papername": "Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network", 
                            "value": 0.37, 
                            "label": "FLSCNN", 
                            "algorithm_src_url": "", 
                            "date": "2015-05-31", 
                            "algorithms": [], 
                            "max_date": "2015-08-15", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-03-16", 
                            "notes": "No data augmentation", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.31, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RCNN-96", 
                            "minval": 0.31, 
                            "url": "http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_004.pdf", 
                            "papername": "Recurrent Convolutional Neural Network for Object Recognition", 
                            "value": 0.31, 
                            "label": "RCNN-96", 
                            "algorithm_src_url": "", 
                            "date": "2015-06-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.45, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ReNet", 
                            "minval": 0.45, 
                            "url": "https://arxiv.org/abs/1505.00393", 
                            "papername": "ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks", 
                            "value": 0.45, 
                            "label": "ReNet", 
                            "algorithm_src_url": "", 
                            "date": "2015-06-12", 
                            "algorithms": [], 
                            "max_date": "2015-07-23", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-05-03", 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.42, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MLR DNN", 
                            "minval": 0.42, 
                            "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7258343", 
                            "papername": "Multi-Loss Regularized Deep Neural Network", 
                            "value": 0.42, 
                            "label": "MLR DNN", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-01", 
                            "algorithms": [], 
                            "max_date": "2015-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-01-01", 
                            "notes": "Based on NiN architecture.", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.71, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep Fried Convnets", 
                            "minval": 0.71, 
                            "url": "http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yang_Deep_Fried_Convnets_ICCV_2015_paper.pdf", 
                            "papername": "Deep Fried Convnets", 
                            "value": 0.71, 
                            "label": "Deep Fried Convnets", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-01", 
                            "algorithms": [], 
                            "max_date": "2015-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-01-01", 
                            "notes": "Uses about 10x fewer parameters than the reference model, which reaches 0.87%.", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.46, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DCNN+GFE", 
                            "minval": 0.46, 
                            "url": "http://www.isip.uni-luebeck.de/fileadmin/uploads/tx_wapublications/hertel_ijcnn_2015.pdf", 
                            "papername": "Deep Convolutional Neural Networks as Generic Feature Extractors", 
                            "value": 0.46, 
                            "label": "DCNN+GFE", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-12", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "feature extraction part of convnet is trained on imagenet (external training data), classification part is trained on cifar-10", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.38, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MIM", 
                            "minval": 0.31999999999999995, 
                            "url": "https://arxiv.org/abs/1508.00330", 
                            "papername": "On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units", 
                            "value": 0.35, 
                            "label": "MIM", 
                            "algorithm_src_url": "", 
                            "date": "2015-09-17", 
                            "algorithms": [], 
                            "max_date": "2015-11-01", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-08-03", 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.29, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Tree+Max-Avg pooling", 
                            "minval": 0.29, 
                            "url": "https://arxiv.org/abs/1509.08985", 
                            "papername": "Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree", 
                            "value": 0.29, 
                            "label": "Tree+Max-Avg pooling", 
                            "algorithm_src_url": "", 
                            "date": "2015-10-05", 
                            "algorithms": [], 
                            "max_date": "2015-10-10", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-09-30", 
                            "notes": "Single model without data augmentation", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.24, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "BNM NiN", 
                            "minval": 0.24, 
                            "url": "https://arxiv.org/abs/1511.02583", 
                            "papername": "Batch-normalized Maxout Network in Network", 
                            "value": 0.24, 
                            "label": "BNM NiN", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-09", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "(k=5 maxout pieces in each maxout unit).", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.33, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "CMsC", 
                            "minval": 0.33, 
                            "url": "https://arxiv.org/abs/1511.05635", 
                            "papername": "Competitive Multi-scale Convolution", 
                            "value": 0.33, 
                            "label": "CMsC", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-18", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.45, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "VDN", 
                            "minval": 0.45, 
                            "url": "http://people.idsia.ch/~rupesh/very_deep_learning/", 
                            "papername": "Training Very Deep Networks", 
                            "value": 0.45, 
                            "label": "VDN", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Best result selected on test set. 0.46% average over multiple trained models.", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.01, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "BinaryConnect", 
                            "minval": 1.01, 
                            "url": "http://papers.nips.cc/paper/5647-binaryconnect-training-deep-neural-networks-with-binary-weights-during-propagations.pdf", 
                            "papername": "BinaryConnect: Training Deep Neural Networks with binary weights during propagations", 
                            "value": 1.01, 
                            "label": "BinaryConnect", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Using 50% dropout", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Convolutional Clustering", 
                            "minval": 1.4, 
                            "url": "https://arxiv.org/abs/1511.06241", 
                            "papername": "Convolutional Clustering for Unsupervised Learning", 
                            "value": 1.4, 
                            "label": "Convolutional Clustering", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-02", 
                            "algorithms": [], 
                            "max_date": "2016-02-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-19", 
                            "notes": "2 layers + multi dict.", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.38, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Fitnet-LSUV-SVM", 
                            "minval": 0.38, 
                            "url": "https://arxiv.org/abs/1511.06422", 
                            "papername": "All you need is a good init", 
                            "value": 0.38, 
                            "label": "Fitnet-LSUV-SVM", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-04", 
                            "algorithms": [], 
                            "max_date": "2016-02-19", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-19", 
                            "notes": "", 
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "data/awty.py", 
                    "target_source": "http://people.idsia.ch/~juergen/superhumanpatternrecognition.html", 
                    "changeable": false, 
                    "axis_label": "Percentage error", 
                    "target": 0.2
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/awty.py#L63", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "STL-10 Image Recognition", 
                    "parent": "Problem(Image classification)", 
                    "url": "https://cs.stanford.edu/~acoates/stl10/", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 60.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Receptive Fields", 
                            "minval": 60.1, 
                            "url": "http://www.stanford.edu/~acoates/papers/coatesng_nips_2011.pdf", 
                            "papername": "Selecting Receptive Fields in Deep Networks ", 
                            "value": 60.1, 
                            "label": "Receptive Fields", 
                            "algorithm_src_url": "", 
                            "date": "2011-12-17", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 58.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Invariant Representations with Local Transformations", 
                            "minval": 58.7, 
                            "url": "http://web.eecs.umich.edu/~honglak/icml12-invariantFeatureLearning.pdf", 
                            "papername": "Learning Invariant Representations with Local Transformations", 
                            "value": 58.7, 
                            "label": "Invariant Representations...", 
                            "algorithm_src_url": "", 
                            "date": "2012-06-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 61.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Simulated Fixations", 
                            "minval": 61.0, 
                            "url": "http://papers.nips.cc/paper/4730-deep-learning-of-invariant-features-via-simulated-fixations-in-video", 
                            "papername": "Deep Learning of Invariant Features via Simulated Fixations in Video", 
                            "value": 61.0, 
                            "label": "Simulated Fixations", 
                            "algorithm_src_url": "", 
                            "date": "2012-07-01", 
                            "algorithms": [], 
                            "max_date": "2012-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2012-01-01", 
                            "notes": "", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 64.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RGB-D Based Object Recognition", 
                            "minval": 64.5, 
                            "url": "http://homes.cs.washington.edu/~lfb/paper/iser12.pdf", 
                            "papername": "Unsupervised Feature Learning for RGB-D Based Object Recognition", 
                            "value": 64.5, 
                            "label": "RGB-D Based Object Recogn...", 
                            "algorithm_src_url": "", 
                            "date": "2012-07-01", 
                            "algorithms": [], 
                            "max_date": "2012-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2012-01-01", 
                            "notes": "Hierarchical sparse coding using Matching Pursuit and K-SVD", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 56.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep Learning of Invariant Features via Simulated Fixations in Video", 
                            "minval": 56.5, 
                            "url": "http://ai.stanford.edu/~wzou/nips_ZouZhuNgYu12.pdf", 
                            "papername": "Deep Learning of Invariant Features via Simulated Fixations in Video", 
                            "value": 56.5, 
                            "label": "Deep Learning of Invarian...", 
                            "algorithm_src_url": "", 
                            "date": "2012-12-03", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Trained also with video (unrelated to STL-10) obtained 61%", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 62.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Discriminative Learning of Sum-Product Networks", 
                            "minval": 62.3, 
                            "url": "http://homes.cs.washington.edu/~rcg/papers/dspn.pdf", 
                            "papername": "Discriminative Learning of Sum-Product Networks", 
                            "value": 62.3, 
                            "label": "Discriminative Learning o...", 
                            "algorithm_src_url": "", 
                            "date": "2012-12-03", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 58.28, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Pooling-Invariant", 
                            "minval": 58.28, 
                            "url": "https://arxiv.org/abs/1302.5056v1", 
                            "papername": "Pooling-Invariant Image Feature Learning ", 
                            "value": 58.28, 
                            "label": "Pooling-Invariant", 
                            "algorithm_src_url": "", 
                            "date": "2013-01-15", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "1600 codes, learnt using 2x PDL", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 70.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Multi-Task Bayesian Optimization", 
                            "minval": 70.1, 
                            "url": "http://hips.seas.harvard.edu/files/swersky-multi-nips-2013.pdf", 
                            "papername": "Multi-Task Bayesian Optimization", 
                            "value": 70.1, 
                            "label": "Multi-Task Bayesian Optim...", 
                            "algorithm_src_url": "", 
                            "date": "2013-07-01", 
                            "algorithms": [], 
                            "max_date": "2013-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2013-01-01", 
                            "notes": "Also uses CIFAR-10 training data", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 61.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "No more meta-parameter tuning in unsupervised sparse feature learning", 
                            "minval": 61.0, 
                            "url": "https://arxiv.org/abs/1402.5766", 
                            "papername": "No more meta-parameter tuning in unsupervised sparse feature learning", 
                            "value": 61.0, 
                            "label": "No more meta-parameter tu...", 
                            "algorithm_src_url": "", 
                            "date": "2014-02-24", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 67.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nonnegativity Constraints ", 
                            "minval": 67.9, 
                            "url": "http://jmlr.org/proceedings/papers/v32/line14.pdf", 
                            "papername": "Stable and Efficient Representation Learning with Nonnegativity Constraints ", 
                            "value": 67.9, 
                            "label": "Nonnegativity Constraints ", 
                            "algorithm_src_url": "", 
                            "date": "2014-06-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "3-layers + multi-dict. 5 \u00b1 0.5 with 3-layers only. 6 \u00b1 0.6 with 1-layers only.", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 68.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DFF Committees", 
                            "minval": 68.0, 
                            "url": "https://arxiv.org/abs/1406.5947", 
                            "papername": "Committees of deep feedforward networks trained with few data", 
                            "value": 68.0, 
                            "label": "DFF Committees", 
                            "algorithm_src_url": "", 
                            "date": "2014-06-23", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 62.32, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "CKN", 
                            "minval": 62.32, 
                            "url": "https://arxiv.org/abs/1406.3332", 
                            "papername": "Convolutional Kernel Networks", 
                            "value": 62.32, 
                            "label": "CKN", 
                            "algorithm_src_url": "", 
                            "date": "2014-08-28", 
                            "algorithms": [], 
                            "max_date": "2014-11-14", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-06-12", 
                            "notes": "No data augmentation.", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 72.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Discriminative Unsupervised Feature Learning with Convolutional Neural Networks", 
                            "minval": 72.8, 
                            "url": "http://papers.nips.cc/paper/5548-discriminative-unsupervised-feature-learning-with-convolutional-neural-networks.pdf", 
                            "papername": "Discriminative Unsupervised Feature Learning with Convolutional Neural Networks", 
                            "value": 72.8, 
                            "label": "Discriminative Unsupervis...", 
                            "algorithm_src_url": "", 
                            "date": "2014-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "Unsupervised feature learning + linear SVM", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 70.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "An Analysis of Unsupervised Pre-training in Light of Recent Advances", 
                            "minval": 70.2, 
                            "url": "https://arxiv.org/abs/1412.6597", 
                            "papername": "An Analysis of Unsupervised Pre-training in Light of Recent Advances", 
                            "value": 70.2, 
                            "label": "An Analysis of Unsupervis...", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-13", 
                            "algorithms": [], 
                            "max_date": "2015-04-10", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-12-20", 
                            "notes": "Unsupervised pre-training, with supervised fine-tuning. Uses dropout and data-augmentation.", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 68.23, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C-SVDDNet", 
                            "minval": 68.23, 
                            "url": "https://arxiv.org/abs/1412.7259", 
                            "papername": "C-SVDDNet: An Effective Single-Layer Network for Unsupervised Feature Learning", 
                            "value": 68.23, 
                            "label": "C-SVDDNet", 
                            "algorithm_src_url": "", 
                            "date": "2015-03-11", 
                            "algorithms": [], 
                            "max_date": "2015-05-29", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2014-12-23", 
                            "notes": "", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 73.15, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep Representation Learning with Target Coding", 
                            "minval": 73.15, 
                            "url": "http://personal.ie.cuhk.edu.hk/~ccloy/files/aaai_2015_target_coding.pdf", 
                            "papername": "Deep Representation Learning with Target Coding", 
                            "value": 73.15, 
                            "label": "Deep Representation Learn...", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-01", 
                            "algorithms": [], 
                            "max_date": "2015-12-31", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-01-01", 
                            "notes": "", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 74.33, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SWWAE", 
                            "minval": 74.33, 
                            "url": "https://arxiv.org/abs/1506.02351", 
                            "papername": "Stacked What-Where Auto-encoders", 
                            "value": 74.33, 
                            "label": "SWWAE", 
                            "algorithm_src_url": "", 
                            "date": "2015-10-11", 
                            "algorithms": [], 
                            "max_date": "2016-02-14", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-06-08", 
                            "notes": "", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 74.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Convolutional Clustering", 
                            "minval": 74.1, 
                            "url": "https://arxiv.org/abs/1511.06241", 
                            "papername": "Convolutional Clustering for Unsupervised Learning", 
                            "value": 74.1, 
                            "label": "Convolutional Clustering", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-02", 
                            "algorithms": [], 
                            "max_date": "2016-02-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-19", 
                            "notes": "3 layers + multi dict. With 2 layers, reaches 71.4%", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 78.59, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "CC-GAN\u00b2", 
                            "minval": 76.99000000000001, 
                            "url": "https://arxiv.org/abs/1611.06430v1", 
                            "papername": "Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks", 
                            "value": 77.79, 
                            "label": "CC-GAN\u00b2", 
                            "algorithm_src_url": "", 
                            "date": "2016-11-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(STL-10 Image Recognition)                            ?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/awty.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": null
                }, 
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/awty.py#L24", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Leeds Sport Poses", 
                    "parent": "Problem(Image classification)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }
            ], 
            "solved": false, 
            "attributes": [
                "vision", 
                "agi"
            ]
        }, 
        {
            "superproblems": [
                "Solve vaguely or under-constrained technical problems"
            ], 
            "name": "Read a scientific or technical paper, and comprehend its contents", 
            "url": null, 
            "subproblems": [
                "Extract major numerical results or progress claims from a STEM paper"
            ], 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "language", 
                "world-modelling", 
                "super"
            ]
        }, 
        {
            "superproblems": [], 
            "name": "Conduct arbitrary sustained, probing conversation", 
            "url": null, 
            "subproblems": [
                "Turing test for casual conversation", 
                "Language comprehension and question-answering"
            ], 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "agi", 
                "language", 
                "world-modelling", 
                "communication"
            ]
        }, 
        {
            "superproblems": [], 
            "name": "Vision", 
            "url": null, 
            "subproblems": [
                "Image classification", 
                "Recognise events in videos"
            ], 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "agi", 
                "vision", 
                "world-modelling"
            ]
        }, 
        {
            "superproblems": [], 
            "name": "Building systems that solve a wide range of diverse problems, rather than just specific ones", 
            "url": null, 
            "subproblems": [
                "Transfer learning: apply relevant knowledge from a prior setting to a new slightly different one"
            ], 
            "metrics": [
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-31-847f9831eedb>#L2", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Solve all other solved problems in this document, with a single system", 
                    "parent": "Problem(Building systems that solve a wide range of diverse problems, rather than just specific ones)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }
            ], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [], 
            "name": "Modify arbitrary ML systems in order to be able to provide comprehensible human explanations of their decisions", 
            "url": null, 
            "subproblems": [
                "Provide mathematical or technical explanations of decisions from classifiers"
            ], 
            "metrics": [], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [
                "Abstract strategy games"
            ], 
            "name": "Learning the rules of complex strategy games from examples", 
            "url": null, 
            "subproblems": [], 
            "metrics": [
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/strategy_games.py#L74", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "learning chess", 
                    "parent": "Problem(Learning the rules of complex strategy games from examples)", 
                    "url": null, 
                    "notes": "\n  Chess software contains hard-coded policy constraints for valid play; this metric is whether RL\n  or other agents can correctly build those policy constraints from examples or oracles", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }, 
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/strategy_games.py#L78", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "learning go", 
                    "parent": "Problem(Learning the rules of complex strategy games from examples)", 
                    "url": null, 
                    "notes": "\n  Go software contains policy constraints for valid play and evaluating the number of\n  liberties for groups. This metric is whether RL or other agents can correctly build those \n  policy constraints from examples or oracles", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }
            ], 
            "solved": false, 
            "attributes": [
                "agi", 
                "abstract-games"
            ]
        }, 
        {
            "superproblems": [], 
            "name": "Know how to build general AI agents that will behave as expected", 
            "url": null, 
            "subproblems": [
                "Resistance to adversarial examples", 
                "Scalable supervision of a learning system", 
                "Safe exploration", 
                "Avoiding reward hacking", 
                "Avoiding undesirable side effects", 
                "Function correctly in novel environments (robustness to distributional change)", 
                "Know how to prevent an autonomous AI agent from reproducing itself an unbounded number of times"
            ], 
            "metrics": [], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [], 
            "name": "Build systems which can recognise and avoid biases decision making", 
            "url": null, 
            "subproblems": [], 
            "notes": "\nLegally institutionalised protected categories represent only the most extreme and socially recognised\nforms of biased decisionmaking. Attentive human decision makers are sometime capable of recognising\nand avoiding many more subtle biases. This problem tracks AI systems' ability to do likewise.\n", 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "safety"
            ]
        }, 
        {
            "superproblems": [
                "Know how to build general AI agents that will behave as expected"
            ], 
            "name": "Function correctly in novel environments (robustness to distributional change)", 
            "url": "https://arxiv.org/abs/1606.06565", 
            "subproblems": [], 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "safety", 
                "agi"
            ]
        }, 
        {
            "superproblems": [], 
            "name": "Detect security-related bugs in codebases", 
            "url": null, 
            "subproblems": [], 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "safety", 
                "security", 
                "unsafe"
            ]
        }, 
        {
            "superproblems": [
                "Play real-time computer & video games"
            ], 
            "name": "Simple video games", 
            "url": null, 
            "subproblems": [], 
            "metrics": [
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Alien", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SARSA(\u03bb)", 
                            "minval": 1.2, 
                            "url": "https://arxiv.org/abs/1312.5602", 
                            "papername": "Playing Atari with Deep Reinforcement Learning", 
                            "value": 1.2, 
                            "label": "SARSA(\u03bb)", 
                            "algorithm_src_url": "https://arxiv.org/abs/1207.4708v1", 
                            "date": "2013-12-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "The Arcade Learning Environment: An Evaluation Platform for General Agents", 
                            "min_date": "2012-07-19", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4162.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 1976.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 3069.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 813.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 813.5, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 813.5, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 634.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 634.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 634.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1620.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 1620.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1620.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3747.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 3747.7, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 3747.7, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1486.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 1486.5, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 1486.5, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4461.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 4461.4, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 4461.4, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 823.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 823.7, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 823.7, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1033.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 1033.4, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1033.4, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1334.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 1334.7, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 1334.7, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4203.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 4203.8, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 4203.8, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3941.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 3941.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 3941.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 182.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 182.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 182.1, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 518.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 518.4, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 518.4, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 945.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 945.3, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 945.3, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 994.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 994.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 994.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3166.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 3166.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 3166.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Alien)                                    not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 6875
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Amidar", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SARSA(\u03bb)", 
                            "minval": 5.2, 
                            "url": "https://arxiv.org/abs/1312.5602", 
                            "papername": "Playing Atari with Deep Reinforcement Learning", 
                            "value": 5.2, 
                            "label": "SARSA(\u03bb)", 
                            "algorithm_src_url": "https://arxiv.org/abs/1207.4708v1", 
                            "date": "2013-12-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "The Arcade Learning Environment: An Evaluation Platform for General Agents", 
                            "min_date": "2012-07-19", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3763.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": -2284.5, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 739.5, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 189.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 189.2, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 189.2, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 178.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 178.4, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 178.4, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 978.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 978.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 978.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1793.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 1793.3, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1793.3, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 172.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 172.7, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 172.7, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2354.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 2354.5, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 2354.5, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 169.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 169.1, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 169.1, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 238.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 238.4, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 238.4, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 129.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 129.1, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 129.1, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1838.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 1838.9, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 1838.9, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2296.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 2296.8, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 2296.8, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 173.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 173.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 173.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 263.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 263.9, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 263.9, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 283.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 283.9, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 283.9, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 112.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 112.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 112.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1735.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 1735.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 1735.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 1676
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Assault", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SARSA(\u03bb)", 
                            "minval": 6.0, 
                            "url": "https://arxiv.org/abs/1312.5602", 
                            "papername": "Playing Atari with Deep Reinforcement Learning", 
                            "value": 6.0, 
                            "label": "SARSA(\u03bb)", 
                            "algorithm_src_url": "https://arxiv.org/abs/1207.4708v1", 
                            "date": "2013-12-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "The Arcade Learning Environment: An Evaluation Platform for General Agents", 
                            "min_date": "2012-07-19", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4134.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 2584.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 3359.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1195.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 1195.8, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 1195.8, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3489.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 3489.3, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 3489.3, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4280.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 4280.4, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 4280.4, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5393.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 5393.2, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 5393.2, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3994.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 3994.8, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 3994.8, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4621.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 4621.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 4621.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6060.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 6060.8, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 6060.8, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10950.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 10950.6, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 10950.6, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6548.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 6548.9, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 6548.9, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7672.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 7672.1, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 7672.1, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11477.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 11477.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 11477.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3746.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 3746.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 3746.1, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5474.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 5474.9, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 5474.9, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 14497.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 14497.9, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 14497.9, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1673.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 1673.9, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 1673.9, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7203.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 7203.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 7203.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 1496
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Asterix", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 168.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SARSA(\u03bb)", 
                            "minval": 168.0, 
                            "url": "https://arxiv.org/abs/1312.5602", 
                            "papername": "Playing Atari with Deep Reinforcement Learning", 
                            "value": 168.0, 
                            "label": "SARSA(\u03bb)", 
                            "algorithm_src_url": "https://arxiv.org/abs/1207.4708v1", 
                            "date": "2013-12-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "The Arcade Learning Environment: An Evaluation Platform for General Agents", 
                            "min_date": "2012-07-19", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7756.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 4268.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 6012.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3324.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 3324.7, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 3324.7, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3170.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 3170.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 3170.5, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4359.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 4359.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 4359.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 17356.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 17356.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 17356.5, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 15840.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 15840.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 15840.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 28188.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 28188.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 28188.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 16837.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 16837.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 16837.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 364200.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 364200.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 364200.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 22484.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 22484.5, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 22484.5, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 31527.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 31527.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 31527.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 375080.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 375080.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 375080.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6723.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 6723.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 6723.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 17244.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 17244.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 17244.5, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 22140.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 22140.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 22140.5, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1440.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 1440.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 1440.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 406211.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 406211.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 406211.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 8503
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Asteroids", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 31.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SARSA(\u03bb)", 
                            "minval": 31.0, 
                            "url": "https://arxiv.org/abs/1312.5602", 
                            "papername": "Playing Atari with Deep Reinforcement Learning", 
                            "value": 31.0, 
                            "label": "SARSA(\u03bb)", 
                            "algorithm_src_url": "https://arxiv.org/abs/1207.4708v1", 
                            "date": "2013-12-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "The Arcade Learning Environment: An Evaluation Platform for General Agents", 
                            "min_date": "2012-07-19", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2171.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 1087.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 1629.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 933.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 933.6, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 933.6, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 734.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 734.7, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 734.7, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1364.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 1364.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1364.5, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1458.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 1458.7, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1458.7, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2035.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 2035.4, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 2035.4, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2837.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 2837.7, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 2837.7, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1021.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 1021.9, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1021.9, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1193.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 1193.2, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1193.2, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1745.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 1745.1, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 1745.1, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2654.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 2654.3, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 2654.3, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1192.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 1192.7, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 1192.7, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3009.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 3009.4, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 3009.4, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4474.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 4474.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 4474.5, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5093.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 5093.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 5093.1, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1562.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 1562.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 1562.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1516.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 1516.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 1516.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 13157
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Atlantis", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 52.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SARSA(\u03bb)", 
                            "minval": 52.0, 
                            "url": "https://arxiv.org/abs/1312.5602", 
                            "papername": "Playing Atari with Deep Reinforcement Learning", 
                            "value": 52.0, 
                            "label": "SARSA(\u03bb)", 
                            "algorithm_src_url": "https://arxiv.org/abs/1207.4708v1", 
                            "date": "2013-12-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "The Arcade Learning Environment: An Evaluation Platform for General Agents", 
                            "min_date": "2012-07-19", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 103241.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 68041.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 85641.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 629166.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 629166.5, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 629166.5, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 106056.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 106056.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 106056.0, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 279987.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 279987.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 279987.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 292491.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 292491.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 292491.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 382572.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 382572.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 382572.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 445360.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 445360.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 445360.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 319688.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 319688.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 319688.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 423252.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 423252.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 423252.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 330647.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 330647.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 330647.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 357324.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 357324.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 357324.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 395762.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 395762.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 395762.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 772392.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 772392.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 772392.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 875822.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 875822.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 875822.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 911091.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 911091.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 911091.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1267410.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 1267410.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 1267410.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 841075.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 841075.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 841075.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 29028
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Bank Heist", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SARSA(\u03bb)", 
                            "minval": 4.0, 
                            "url": "https://arxiv.org/abs/1312.5602", 
                            "papername": "Playing Atari with Deep Reinforcement Learning", 
                            "value": 4.0, 
                            "label": "SARSA(\u03bb)", 
                            "algorithm_src_url": "https://arxiv.org/abs/1207.4708v1", 
                            "date": "2013-12-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "The Arcade Learning Environment: An Evaluation Platform for General Agents", 
                            "min_date": "2012-07-19", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1079.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": -220.3, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 429.7, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 399.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 399.4, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 399.4, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 312.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 312.7, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 312.7, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 455.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 455.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 455.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1030.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 1030.6, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1030.6, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1129.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 1129.3, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 1129.3, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1611.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 1611.9, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 1611.9, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 886.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 886.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 886.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1004.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 1004.6, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1004.6, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 876.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 876.6, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 876.6, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1054.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 1054.6, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 1054.6, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1503.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 1503.1, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 1503.1, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 932.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 932.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 932.8, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 946.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 946.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 946.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 970.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 970.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 970.1, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 225.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 225.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 225.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 976.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 976.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 976.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 734.4
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Battle Zone", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 34025.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 18575.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 26300.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 19938.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 19938.0, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 19938.0, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 23750.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 23750.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 23750.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 29900.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 29900.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 29900.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 31700.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 31700.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 31700.0, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 31320.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 31320.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 31320.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 37150.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 37150.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 37150.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 24740.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 24740.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 24740.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 30650.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 30650.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 30650.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 25520.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 25520.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 25520.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 31530.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 31530.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 31530.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 35520.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 35520.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 35520.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11340.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 11340.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 11340.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12950.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 12950.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 12950.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20760.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 20760.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 20760.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 16600.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 16600.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 16600.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 28742.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 28742.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 28742.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 37800
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Beam Rider", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5184, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN best", 
                            "minval": 5184, 
                            "url": "https://arxiv.org/abs/1312.5602", 
                            "papername": "Playing Atari with Deep Reinforcement Learning", 
                            "value": 5184, 
                            "label": "DQN best", 
                            "algorithm_src_url": "", 
                            "date": "2013-12-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8465.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 5227.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 6846.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3822.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 3822.1, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 3822.1, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8627.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 8627.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 8627.5, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 9743.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 9743.2, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 9743.2, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 13772.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 13772.8, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 13772.8, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12164.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 12164.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 12164.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 14591.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 14591.3, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 14591.3, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 17417.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 17417.2, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 17417.2, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 37412.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 37412.2, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 37412.2, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 23384.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 23384.2, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 23384.2, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 31181.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 31181.3, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 31181.3, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 30276.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 30276.5, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 30276.5, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 13235.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 13235.9, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 13235.9, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 22707.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 22707.9, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 22707.9, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 24622.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 24622.2, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 24622.2, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 744.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 744.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 744.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 14074.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 14074.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 14074.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://arxiv.org/pdf/1312.5602.pdf", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 7456
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2039", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Berzerk", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 493.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 493.4, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 493.4, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 585.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 585.6, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 585.6, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1225.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 1225.4, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1225.4, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 910.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 910.6, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 910.6, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1472.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 1472.6, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 1472.6, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1011.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 1011.1, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1011.1, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2178.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 2178.6, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 2178.6, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 865.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 865.9, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 865.9, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1305.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 1305.6, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 1305.6, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3409.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 3409.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 3409.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 817.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 817.9, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 817.9, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 862.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 862.2, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 862.2, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1433.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 1433.4, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 1433.4, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 686.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 686.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 686.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1645.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 1645.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 1645.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://arxiv.org/abs/1511.06581v1", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 2630.4
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Bowling", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 130.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": -45.6, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 42.4, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 54.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 54.0, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 54.0, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 50.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 50.4, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 50.4, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 56.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 56.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 56.5, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 68.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 68.1, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 68.1, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 65.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 65.5, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 65.5, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 65.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 65.7, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 65.7, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 50.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 50.4, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 50.4, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 69.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 69.6, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 69.6, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 47.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 47.9, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 47.9, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 52.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 52.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 52.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 46.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 46.7, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 46.7, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 35.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 35.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 35.1, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 36.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 36.2, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 36.2, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 41.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 41.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 41.8, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 30.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 30.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 30.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 81.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 81.8, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 81.8, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 154.8
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Boxing", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 79.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 63.8, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 71.8, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 74.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 74.2, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 74.2, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 70.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 70.3, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 70.3, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 88.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 88.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 88.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 91.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 91.6, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 91.6, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 77.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 77.3, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 77.3, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 99.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 99.4, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 99.4, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 73.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 73.5, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 73.5, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 79.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 79.2, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 79.2, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 72.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 72.3, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 72.3, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 95.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 95.6, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 95.6, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 98.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 98.9, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 98.9, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 33.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 33.7, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 33.7, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 37.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 37.3, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 37.3, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 59.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 59.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 59.8, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 49.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 49.8, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 49.8, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 97.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 97.8, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 97.8, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 4.3
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Breakout", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 225, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN best", 
                            "minval": 225, 
                            "url": "https://arxiv.org/abs/1312.5602", 
                            "papername": "Playing Atari with Deep Reinforcement Learning", 
                            "value": 225, 
                            "label": "DQN best", 
                            "algorithm_src_url": "", 
                            "date": "2013-12-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 427.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 375.2, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 401.2, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 313.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 313.0, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 313.0, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 354.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 354.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 354.5, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 385.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 385.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 385.5, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 418.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 418.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 418.5, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 345.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 345.3, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 345.3, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 411.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 411.6, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 411.6, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 354.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 354.6, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 354.6, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 368.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 368.9, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 368.9, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 343.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 343.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 343.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 373.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 373.9, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 373.9, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 366.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 366.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 366.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 551.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 551.6, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 551.6, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 681.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 681.9, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 681.9, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 766.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 766.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 766.8, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 9.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 9.5, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 9.5, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 748.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 748.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 748.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://pdfs.semanticscholar.org/340f/48901f72278f6bf78a04ee5b01df208cc508.pdf", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 31.8
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Centipede", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 13546.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 3072.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 8309.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6296.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 6296.9, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 6296.9, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3973.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 3973.9, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 3973.9, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4657.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 4657.7, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 4657.7, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5409.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 5409.4, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 5409.4, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4881.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 4881.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 4881.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7561.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 7561.4, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 7561.4, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3853.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 3853.5, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 3853.5, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5570.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 5570.2, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 5570.2, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3489.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 3489.1, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 3489.1, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4463.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 4463.2, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 4463.2, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7687.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 7687.5, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 7687.5, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1997.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 1997.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 1997.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3306.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 3306.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 3306.5, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3755.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 3755.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 3755.8, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7783.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 7783.9, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 7783.9, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 9646.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 9646.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 9646.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Centipede)                                not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 11963
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Chopper Command", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 9603.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 3771.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 6687.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3191.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 3191.8, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 3191.8, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5017.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 5017.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 5017.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5809.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 5809.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 5809.0, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6126.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 6126.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 6126.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3784.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 3784.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 3784.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11215.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 11215.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 11215.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3495.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 3495.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 3495.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8058.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 8058.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 8058.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4635.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 4635.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 4635.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8600.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 8600.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 8600.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 13185.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 13185.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 13185.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4669.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 4669.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 4669.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7021.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 7021.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 7021.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10150.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 10150.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 10150.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3710.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 3710.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 3710.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 15600.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 15600.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 15600.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 9882
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Crazy Climber", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 136900.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 91306.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 114103.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 65451.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 65451.0, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 65451.0, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 98128.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 98128.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 98128.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 110763.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 110763.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 110763.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 117282.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 117282.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 117282.0, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 124566.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 124566.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 124566.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 143570.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 143570.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 143570.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 113782.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 113782.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 113782.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 127853.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 127853.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 127853.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 127512.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 127512.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 127512.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 141161.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 141161.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 141161.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 162224.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 162224.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 162224.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 101624.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 101624.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 101624.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 112646.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 112646.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 112646.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 138518.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 138518.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 138518.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 26430.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 26430.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 26430.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 179877.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 179877.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 179877.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 35411
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Demon Attack", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12117.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 7305.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 9711.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 14880.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 14880.1, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 14880.1, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12149.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 12149.4, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 12149.4, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12550.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 12550.7, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 12550.7, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 58044.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 58044.2, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 58044.2, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 56322.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 56322.8, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 56322.8, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 60813.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 60813.3, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 60813.3, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 69803.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 69803.4, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 69803.4, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 73371.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 73371.3, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 73371.3, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 61277.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 61277.5, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 61277.5, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 71846.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 71846.4, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 71846.4, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 72878.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 72878.6, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 72878.6, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 84997.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 84997.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 84997.5, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 113308.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 113308.4, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 113308.4, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 115201.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 115201.9, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 115201.9, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 0.2, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 0.2, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 130955.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 130955.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 130955.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 3401
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Double Dunk", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": -16.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": -20.1, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": -18.1, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -11.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": -11.3, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": -11.3, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -6.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": -6.6, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -6.6, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -6.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": -6.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -6.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -5.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": -5.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -5.5, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -0.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": -0.8, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": -0.8, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 0.1, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 0.1, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -10.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": -10.7, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -10.7, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -0.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": -0.3, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -0.3, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 16.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 16.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 16.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 18.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 18.5, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 18.5, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -12.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": -12.5, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": -12.5, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -0.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": -0.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -0.1, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 0.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 0.1, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 0.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 0.1, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 95.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 95.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 95.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 2.5, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 2.5, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": -15.5
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Enduro", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 661, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN best", 
                            "minval": 661, 
                            "url": "https://arxiv.org/abs/1312.5602", 
                            "papername": "Playing Atari with Deep Reinforcement Learning", 
                            "value": 661, 
                            "label": "DQN best", 
                            "algorithm_src_url": "", 
                            "date": "2013-12-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 325.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 277.8, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 301.8, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 71.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 71.0, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 71.0, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 626.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 626.7, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 626.7, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 729.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 729.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 729.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1211.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 1211.8, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1211.8, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2077.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 2077.4, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 2077.4, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2258.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 2258.2, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 2258.2, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1216.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 1216.6, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1216.6, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2223.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 2223.9, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 2223.9, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1831.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 1831.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 1831.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2093.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 2093.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 2093.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2306.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 2306.4, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 2306.4, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -82.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": -82.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -82.5, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -82.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": -82.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -82.5, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -82.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": -82.2, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -82.2, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -49.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": -49.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": -49.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3454.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 3454.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 3454.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://pdfs.semanticscholar.org/340f/48901f72278f6bf78a04ee5b01df208cc508.pdf", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 309.6
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Fishing Derby", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 18.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": -19.8, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": -0.8, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 4.6, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 4.6, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -4.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": -4.9, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -4.9, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -1.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": -1.6, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -1.6, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 15.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 15.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 15.5, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -4.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": -4.1, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": -4.1, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 46.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 46.4, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 46.4, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 3.2, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 3.2, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 17.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 17.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 17.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 9.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 9.8, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 9.8, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 39.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 39.5, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 39.5, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 41.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 41.3, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 41.3, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 13.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 13.6, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 13.6, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 18.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 18.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 18.8, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 22.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 22.6, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 22.6, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 31.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 31.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 31.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 8.9, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 8.9, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 5.5
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Freeway", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 30.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 30.3, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 30.3, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 10.2, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 10.2, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 26.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 26.9, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 26.9, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 30.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 30.8, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 30.8, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 33.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 33.3, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 33.3, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 0.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 0.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 0.2, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 0.2, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 28.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 28.2, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 28.2, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 28.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 28.8, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 28.8, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 28.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 28.9, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 28.9, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 33.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 33.7, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 33.7, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 33.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 33.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 33.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 0.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 0.1, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 0.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 0.1, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 0.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 0.1, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 370.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 370.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 370.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 33.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 33.9, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 33.9, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 29.6
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Frostbite", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 578.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 78.30000000000001, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 328.3, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 426.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 426.6, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 426.6, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 496.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 496.1, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 496.1, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 797.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 797.4, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 797.4, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1683.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 1683.3, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1683.3, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2332.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 2332.4, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 2332.4, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4672.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 4672.8, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 4672.8, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1448.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 1448.1, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1448.1, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4038.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 4038.4, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 4038.4, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3510.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 3510.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 3510.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4380.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 4380.1, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 4380.1, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7413.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 7413.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 7413.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 180.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 180.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 180.1, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 190.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 190.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 190.5, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 197.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 197.6, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 197.6, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 582.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 582.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 582.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3965.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 3965.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 3965.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 4355
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Gopher", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11799.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 5241.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 8520.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4373.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 4373.0, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 4373.0, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8190.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 8190.4, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 8190.4, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8777.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 8777.4, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 8777.4, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 14840.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 14840.8, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 14840.8, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 15718.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 15718.4, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 15718.4, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20051.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 20051.4, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 20051.4, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 15253.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 15253.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 15253.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 105148.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 105148.4, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 105148.4, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 32487.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 32487.2, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 32487.2, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 34858.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 34858.8, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 34858.8, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 104368.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 104368.2, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 104368.2, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8442.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 8442.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 8442.8, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10022.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 10022.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 10022.8, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 17106.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 17106.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 17106.8, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 805.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 805.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 805.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 33641.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 33641.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 33641.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 2321
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Gravitar", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 529.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 83.69999999999999, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 306.7, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 538.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 538.4, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 538.4, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 298.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 298.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 298.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 412.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 412.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 412.0, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 473.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 473.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 473.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 297.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 297.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 297.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 588.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 588.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 588.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 167.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 167.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 167.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 200.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 200.5, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 200.5, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 269.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 269.5, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 269.5, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 548.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 548.5, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 548.5, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 238.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 238.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 238.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 269.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 269.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 269.5, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 303.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 303.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 303.5, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 320.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 320.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 320.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -4.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": -4.1, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": -4.1, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 440.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 440.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 440.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 2672
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 HERO", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20108.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 19792.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 19950.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8963.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 8963.4, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 8963.4, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 14992.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 14992.9, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 14992.9, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20130.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 20130.2, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 20130.2, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20437.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 20437.8, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 20437.8, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 15207.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 15207.9, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 15207.9, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20818.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 20818.2, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 20818.2, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 14892.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 14892.5, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 14892.5, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 15459.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 15459.2, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 15459.2, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20889.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 20889.9, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 20889.9, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 23037.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 23037.7, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 23037.7, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 21036.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 21036.5, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 21036.5, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 28765.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 28765.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 28765.8, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 28889.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 28889.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 28889.5, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 32464.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 32464.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 32464.1, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11200.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 11200.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 11200.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 38874.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 38874.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 38874.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 25763
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Ice Hockey", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.3999999999999999, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": -3.6, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": -1.6, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -1.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": -1.7, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": -1.7, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -2.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": -2.7, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -2.7, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -1.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": -1.9, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -1.9, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -1.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": -1.6, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -1.6, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -1.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": -1.3, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": -1.3, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 0.5, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 0.5, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -2.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": -2.5, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -2.5, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 0.5, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 0.5, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -0.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": -0.2, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": -0.2, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 1.3, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 1.3, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -0.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": -0.4, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": -0.4, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -4.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": -4.7, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -4.7, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -2.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": -2.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -2.8, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -1.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": -1.7, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -1.7, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8647.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 8647.2, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 8647.2, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -3.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": -3.5, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": -3.5, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 0.9
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 James Bond", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 751.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 401.70000000000005, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 576.7, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 444.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 444.0, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 444.0, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 697.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 697.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 697.5, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 768.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 768.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 768.5, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1358.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 1358.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1358.0, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 835.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 835.5, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 835.5, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1312.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 1312.5, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 1312.5, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 573.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 573.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 573.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 585.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 585.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 585.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3961.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 3961.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 3961.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5148.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 5148.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 5148.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 812.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 812.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 812.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 351.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 351.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 351.5, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 541.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 541.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 541.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 613.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 613.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 613.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 0.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 0.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1909.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 1909.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 1909.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 406.7
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Kangaroo", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 9699.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 3781.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 6740.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1431.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 1431.0, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 1431.0, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4496.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 4496.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 4496.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7259.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 7259.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 7259.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12992.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 12992.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 12992.0, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10334.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 10334.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 10334.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 14854.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 14854.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 14854.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 861.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 861.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 861.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11204.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 11204.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 11204.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12185.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 12185.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 12185.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 16200.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 16200.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 16200.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1792.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 1792.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 1792.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 94.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 94.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 94.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 106.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 106.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 106.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 125.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 125.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 125.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4503.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 4503.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 4503.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12853.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 12853.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 12853.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 3035
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Krull", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4838.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 2772.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 3805.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6363.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 6363.1, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 6363.1, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6206.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 6206.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 6206.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7920.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 7920.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 7920.5, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8422.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 8422.3, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 8422.3, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8051.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 8051.6, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 8051.6, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11451.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 11451.9, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 11451.9, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6796.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 6796.1, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 6796.1, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7658.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 7658.6, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 7658.6, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6872.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 6872.8, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 6872.8, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 9728.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 9728.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 9728.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10374.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 10374.4, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 10374.4, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5560.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 5560.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 5560.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5911.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 5911.4, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 5911.4, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8066.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 8066.6, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 8066.6, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4041.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 4041.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 4041.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 9735.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 9735.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 9735.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 2395
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Kung-Fu Master", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 29225.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 17315.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 23270.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20620.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 20620.0, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 20620.0, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20882.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 20882.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 20882.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 26059.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 26059.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 26059.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 29710.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 29710.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 29710.0, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 24288.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 24288.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 24288.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 34294.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 34294.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 34294.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 30207.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 30207.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 30207.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 37484.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 37484.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 37484.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 31676.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 31676.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 31676.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 39581.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 39581.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 39581.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 48375.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 48375.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 48375.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3046.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 3046.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 3046.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 28819.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 28819.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 28819.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 40835.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 40835.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 40835.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 0.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 0.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 48192.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 48192.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 48192.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 22736
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Montezuma's Revenge", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 0.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 0.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 84.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 84.0, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 84.0, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 0.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 0.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 0.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 0.0, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 47.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 47.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 47.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 0.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 0.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 22.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 22.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 22.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 24.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 24.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 24.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 42.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 42.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 42.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 0.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 0.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 51.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 51.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 51.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 0.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 0.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 41.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 41.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 41.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 53.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 53.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 53.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 67.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 67.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 67.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 21.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 21.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 21.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 0.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 0.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 4367
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Ms. Pacman", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2836.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 1786.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 2311.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1263.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 1263.0, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 1263.0, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 594.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 594.4, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 594.4, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 653.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 653.7, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 653.7, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 850.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 850.7, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 850.7, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 15693
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Name This Game", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7804.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 6710.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 7257.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 9238.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 9238.5, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 9238.5, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6738.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 6738.8, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 6738.8, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8207.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 8207.8, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 8207.8, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10616.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 10616.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 10616.0, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11185.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 11185.1, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 11185.1, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11971.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 11971.1, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 11971.1, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8960.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 8960.3, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 8960.3, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 13637.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 13637.9, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 13637.9, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10497.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 10497.6, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 10497.6, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12270.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 12270.5, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 12270.5, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 15572.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 15572.5, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 15572.5, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5614.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 5614.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 5614.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10476.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 10476.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 10476.1, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12093.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 12093.7, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 12093.7, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 147.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 147.5, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 147.5, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12542.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 12542.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 12542.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 4076
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Pong", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 21, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN best", 
                            "minval": 21, 
                            "url": "https://arxiv.org/abs/1312.5602", 
                            "papername": "Playing Atari with Deep Reinforcement Learning", 
                            "value": 21, 
                            "label": "DQN best", 
                            "algorithm_src_url": "", 
                            "date": "2013-12-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 19.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 17.9, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 18.9, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 16.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 16.7, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 16.7, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 18.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 18.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 18.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 19.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 19.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 19.5, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 20.9, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 20.9, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 18.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 18.8, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 18.8, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 21.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 21.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 21.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 18.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 18.4, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 18.4, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 19.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 19.1, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 19.1, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 18.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 18.9, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 18.9, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 20.6, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 20.6, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 20.9, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 20.9, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 5.6, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 5.6, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 10.7, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 10.7, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 11.4, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 11.4, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 11.9, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 11.9, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 20.9, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 20.9, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://pdfs.semanticscholar.org/340f/48901f72278f6bf78a04ee5b01df208cc508.pdf", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 9.3
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Private Eye", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7261.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": -3685.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 1788.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2598.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 2598.6, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 2598.6, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 129.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 129.7, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 129.7, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 146.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 146.7, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 146.7, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 207.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 207.9, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 207.9, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 103.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 103.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 103.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 292.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 292.6, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 292.6, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -575.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": -575.5, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -575.5, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1277.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 1277.6, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1277.6, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 200.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 200.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 200.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 670.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 670.7, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 670.7, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 206.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 206.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 206.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 194.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 194.4, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 194.4, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 206.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 206.9, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 206.9, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 421.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 421.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 421.1, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1390.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 1390.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 1390.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 15095.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 15095.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 15095.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 69571
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Q*Bert", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4500, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN best", 
                            "minval": 4500, 
                            "url": "https://arxiv.org/abs/1312.5602", 
                            "papername": "Playing Atari with Deep Reinforcement Learning", 
                            "value": 4500, 
                            "label": "DQN best", 
                            "algorithm_src_url": "", 
                            "date": "2013-12-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 13890.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 7302.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 10596.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7089.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 7089.8, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 7089.8, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 9271.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 9271.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 9271.5, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 13117.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 13117.3, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 13117.3, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 15088.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 15088.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 15088.5, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 14175.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 14175.8, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 14175.8, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 19220.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 19220.3, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 19220.3, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11020.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 11020.8, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 11020.8, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 14063.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 14063.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 14063.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 9944.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 9944.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 9944.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 16256.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 16256.5, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 16256.5, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 18760.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 18760.3, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 18760.3, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 13752.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 13752.3, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 13752.3, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 15148.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 15148.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 15148.8, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 21307.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 21307.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 21307.5, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -15442.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": -15442.5, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": -15442.5, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 23784.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 23784.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 23784.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://pdfs.semanticscholar.org/340f/48901f72278f6bf78a04ee5b01df208cc508.pdf", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 13455
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 River Raid", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 9365.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 7267.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 8316.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5310.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 5310.3, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 5310.3, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4748.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 4748.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 4748.5, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7377.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 7377.6, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 7377.6, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 14884.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 14884.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 14884.5, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 16569.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 16569.4, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 16569.4, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 21162.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 21162.6, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 21162.6, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10838.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 10838.4, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 10838.4, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 16496.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 16496.8, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 16496.8, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11807.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 11807.2, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 11807.2, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 14522.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 14522.3, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 14522.3, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20607.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 20607.6, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 20607.6, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6591.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 6591.9, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 6591.9, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10001.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 10001.2, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 10001.2, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12201.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 12201.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 12201.8, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2090.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 2090.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 2090.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 17322.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 17322.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 17322.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 13513
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Road Runner", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 22525.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 13989.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 18257.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 43079.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 43079.8, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 43079.8, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 35215.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 35215.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 35215.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 39544.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 39544.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 39544.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 44127.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 44127.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 44127.0, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 58549.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 58549.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 58549.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 69524.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 69524.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 69524.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 43156.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 43156.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 43156.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 54630.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 54630.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 54630.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 52264.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 52264.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 52264.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 57608.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 57608.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 57608.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 62151.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 62151.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 62151.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 31769.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 31769.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 31769.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 34216.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 34216.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 34216.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 73949.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 73949.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 73949.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 678.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 678.5, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 678.5, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 55839.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 55839.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 55839.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 7845
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Robotank", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 55.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 47.6, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 51.6, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 61.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 61.8, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 61.8, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 58.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 58.7, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 58.7, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 63.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 63.9, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 63.9, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 65.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 65.1, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 65.1, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 62.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 62.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 62.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 65.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 65.3, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 65.3, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 24.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 24.7, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 24.7, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 59.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 59.1, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 59.1, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 56.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 56.2, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 56.2, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 62.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 62.6, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 62.6, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 27.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 27.5, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 27.5, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 2.3, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 2.3, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 2.6, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 2.6, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 32.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 32.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 32.8, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1470.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 1470.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 1470.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 52.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 52.3, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 52.3, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 11.9
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Seaquest", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1740, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN best", 
                            "minval": 1740, 
                            "url": "https://arxiv.org/abs/1312.5602", 
                            "papername": "Playing Atari with Deep Reinforcement Learning", 
                            "value": 1740, 
                            "label": "DQN best", 
                            "algorithm_src_url": "", 
                            "date": "2013-12-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6596.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 3976.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 5286.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10145.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 10145.9, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 10145.9, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4216.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 4216.7, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 4216.7, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5860.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 5860.6, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 5860.6, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 16452.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 16452.7, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 16452.7, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 37361.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 37361.6, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 37361.6, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 50254.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 50254.2, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 50254.2, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1431.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 1431.2, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1431.2, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 14498.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 14498.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 14498.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 25463.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 25463.7, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 25463.7, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 26357.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 26357.8, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 26357.8, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 931.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 931.6, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 931.6, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1326.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 1326.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 1326.1, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2300.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 2300.2, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 2300.2, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2355.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 2355.4, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 2355.4, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -4.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": -4.5, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": -4.5, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 266434.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 266434.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 266434.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://pdfs.semanticscholar.org/340f/48901f72278f6bf78a04ee5b01df208cc508.pdf", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 20182
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Space Invaders", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1075, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN best", 
                            "minval": 1075, 
                            "url": "https://arxiv.org/abs/1312.5602", 
                            "papername": "Playing Atari with Deep Reinforcement Learning", 
                            "value": 1075, 
                            "label": "DQN best", 
                            "algorithm_src_url": "", 
                            "date": "2013-12-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2869.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 1083.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 1976.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1183.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 1183.3, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 1183.3, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1293.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 1293.8, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1293.8, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1692.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 1692.3, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1692.3, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2525.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 2525.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 2525.5, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5993.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 5993.1, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 5993.1, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6427.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 6427.3, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 6427.3, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2628.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 2628.7, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 2628.7, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8978.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 8978.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 8978.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2865.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 2865.8, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 2865.8, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3912.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 3912.1, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 3912.1, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 15311.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 15311.5, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 15311.5, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2214.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 2214.7, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 2214.7, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 15730.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 15730.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 15730.5, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 23846.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 23846.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 23846.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 67974.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 67974.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 67974.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5747.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 5747.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 5747.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://pdfs.semanticscholar.org/340f/48901f72278f6bf78a04ee5b01df208cc508.pdf", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 1652
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Star Gunner", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 61149.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 54845.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 57997.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 14919.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 14919.2, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 14919.2, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 52970.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 52970.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 52970.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 54282.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 54282.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 54282.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 60142.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 60142.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 60142.0, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 89238.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 89238.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 89238.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 90804.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 90804.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 90804.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 58365.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 58365.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 58365.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 127073.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 127073.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 127073.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 61582.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 61582.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 61582.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 63302.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 63302.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 63302.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 125117.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 125117.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 125117.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 64393.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 64393.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 64393.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 138218.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 138218.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 138218.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 164766.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 164766.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 164766.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 760.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 760.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 760.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 49095.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 49095.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 49095.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 10250
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Tennis", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": -1.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": -3.5, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": -2.5, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -0.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": -0.7, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": -0.7, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -22.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": -22.8, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -22.8, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 11.1, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 11.1, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 12.2, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 12.2, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 4.4, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 4.4, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 5.1, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 5.1, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -13.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": -13.2, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -13.2, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -7.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": -7.8, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -7.8, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -5.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": -5.3, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": -5.3, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 0.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 0.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 0.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 0.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -10.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": -10.2, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -10.2, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -6.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": -6.4, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -6.4, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -6.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": -6.3, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -6.3, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3480.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 3480.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 3480.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 23.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 23.1, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 23.1, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": -8.9
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Time Pilot", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7547.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 4347.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 5947.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8267.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 8267.8, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 8267.8, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4786.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 4786.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 4786.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4870.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 4870.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 4870.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8339.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 8339.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 8339.0, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6601.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 6601.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 6601.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11666.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 11666.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 11666.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4871.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 4871.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 4871.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6608.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 6608.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 6608.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5963.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 5963.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 5963.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 9197.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 9197.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 9197.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7553.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 7553.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 7553.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5825.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 5825.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 5825.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12679.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 12679.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 12679.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 27202.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 27202.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 27202.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 16401.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 16401.7, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 16401.7, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8329.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 8329.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 8329.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 5925
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Tutankham", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 227.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 145.7, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 186.7, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 118.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 118.5, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 118.5, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 45.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 45.6, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 45.6, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 68.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 68.1, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 68.1, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 218.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 218.4, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 218.4, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 48.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 48.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 48.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 211.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 211.4, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 211.4, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 92.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 92.2, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 92.2, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 108.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 108.6, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 108.6, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 56.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 56.9, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 56.9, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 204.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 204.6, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 204.6, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 245.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 245.9, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 245.9, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 26.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 26.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 26.1, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 144.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 144.2, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 144.2, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 156.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 156.3, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 156.3, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6380.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 6380.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 6380.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 280.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 280.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 280.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 167.6
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Up and Down", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11618.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 5294.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 8456.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8747.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 8747.7, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 8747.7, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8038.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 8038.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 8038.5, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 9989.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 9989.9, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 9989.9, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 22972.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 22972.2, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 22972.2, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 24759.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 24759.2, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 24759.2, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 44939.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 44939.6, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 44939.6, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 19086.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 19086.9, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 19086.9, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 22681.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 22681.3, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 22681.3, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12157.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 12157.4, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 12157.4, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 16154.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 16154.1, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 16154.1, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 33879.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 33879.1, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 33879.1, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 54525.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 54525.4, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 54525.4, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 74705.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 74705.7, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 74705.7, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 105728.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 105728.7, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 105728.7, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 15612.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 15612.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 15612.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 9082
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Venture", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 618.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 142.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 380.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 523.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 523.4, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 523.4, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 98.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 98.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 98.0, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 136.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 136.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 136.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 163.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 163.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 163.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 200.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 200.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 200.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 497.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 497.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 497.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 21.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 21.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 21.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 29.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 29.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 29.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 54.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 54.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 54.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 94.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 94.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 94.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 48.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 48.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 48.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 19.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 19.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 19.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 23.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 23.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 23.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 25.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 25.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 25.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1520.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 1520.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 1520.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 1188
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Video Pinball", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 58971.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 26397.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 42684.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 112093.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 112093.4, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 112093.4, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 154414.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 154414.1, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 154414.1, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 196760.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 196760.4, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 196760.4, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 309941.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 309941.9, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 309941.9, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 98209.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 98209.5, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 98209.5, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 110976.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 110976.2, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 110976.2, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 367823.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 367823.7, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 367823.7, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 447408.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 447408.6, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 447408.6, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 282007.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 282007.3, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 282007.3, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 295972.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 295972.8, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 295972.8, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 479197.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 479197.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 479197.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 185852.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 185852.6, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 185852.6, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 331628.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 331628.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 331628.1, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 470310.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 470310.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 470310.5, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 949604.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 949604.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 949604.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 17298
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Wizard of Wor", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5412.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 1374.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 3393.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10431.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 10431.0, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 10431.0, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1609.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 1609.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1609.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2704.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 2704.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 2704.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7492.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 7492.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 7492.0, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7054.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 7054.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 7054.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7855.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 7855.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 7855.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6201.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 6201.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 6201.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10471.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 10471.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 10471.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4802.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 4802.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 4802.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5727.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 5727.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 5727.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12352.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 12352.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 12352.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5278.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 5278.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 5278.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 17244.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 17244.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 17244.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 18082.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 18082.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 18082.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 9300.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 9300.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 9300.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 4757
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2044", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Zaxxon", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6212.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Nature DQN", 
                            "minval": 3742.0, 
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "papername": "Human-level control through deep reinforcement learning", 
                            "value": 4977.0, 
                            "label": "Nature DQN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6159.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gorila", 
                            "minval": 6159.4, 
                            "url": "https://arxiv.org/abs/1507.04296", 
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning", 
                            "value": 6159.4, 
                            "label": "Gorila", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-15", 
                            "algorithms": [], 
                            "max_date": "2015-07-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-15", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4412.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 4412.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 4412.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5363.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 5363.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 5363.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10163.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 10163.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 10163.0, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10164.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 10164.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 10164.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12944.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 12944.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 12944.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8593.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 8593.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 8593.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11320.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 11320.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 11320.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 9474.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 9474.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 9474.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10469.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 10469.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 10469.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 13886.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 13886.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 13886.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2659.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 2659.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 2659.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 23519.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 23519.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 23519.0, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 24622.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 24622.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 24622.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 10513.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 10513.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 10513.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 9173
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2039", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Defender", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 15917.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 15917.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 15917.5, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 23633.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 23633.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 23633.0, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 35338.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 35338.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 35338.5, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 33996.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 33996.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 33996.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 42214.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 42214.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 42214.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 27510.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 27510.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 27510.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 34415.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 34415.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 34415.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 23666.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 23666.5, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 23666.5, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 31286.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 31286.5, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 31286.5, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 41324.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 41324.5, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 41324.5, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 36242.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 36242.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 36242.5, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 56533.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 56533.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 56533.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 233021.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 233021.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 233021.5, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1166.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 1166.5, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 1166.5, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 47092.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 47092.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 47092.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://arxiv.org/abs/1509.06461", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 18688.9
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L1838", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Ms. Pac-Man", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1092.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 1092.3, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1092.3, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pac-Man)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2711.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 2711.4, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 2711.4, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pac-Man)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3085.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 3085.6, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 3085.6, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pac-Man)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2250.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 2250.6, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 2250.6, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pac-Man)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6283.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 6283.5, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 6283.5, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pac-Man)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1007.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 1007.8, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1007.8, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pac-Man)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1241.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 1241.3, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1241.3, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pac-Man)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1865.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 1865.9, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 1865.9, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pac-Man)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6518.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 6518.7, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 6518.7, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pac-Man)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3327.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 3327.3, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 3327.3, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pac-Man)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 100.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 100.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 100.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pac-Man)                              not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3415.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 3415.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 3415.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Ms. Pac-Man)                              not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://arxiv.org/abs/1509.06461", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 15375.0
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2039", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Phoenix", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7484.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 7484.8, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 7484.8, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8485.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 8485.2, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 8485.2, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12252.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 12252.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 12252.5, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 20410.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 20410.5, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 20410.5, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 23092.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 23092.2, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 23092.2, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 12366.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 12366.5, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 12366.5, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 63597.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 63597.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 63597.0, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 16903.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 16903.6, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 16903.6, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 18992.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 18992.7, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 18992.7, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 70324.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 70324.3, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 70324.3, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 28181.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 28181.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 28181.8, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 52894.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 52894.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 52894.1, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 74786.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 74786.7, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 74786.7, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5009.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 5009.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 5009.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 17490.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 17490.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 17490.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://arxiv.org/abs/1509.06461", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 7242.6
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L1838", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Pitfall!", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": -286.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": -286.1, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -286.1, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pitfall!)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -113.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": -113.2, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -113.2, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pitfall!)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -29.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": -29.9, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -29.9, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pitfall!)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -46.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": -46.9, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": -46.9, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pitfall!)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 0.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 0.0, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pitfall!)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -243.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": -243.6, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -243.6, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pitfall!)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -186.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": -186.7, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -186.7, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pitfall!)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -427.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": -427.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": -427.0, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pitfall!)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -356.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": -356.5, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": -356.5, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pitfall!)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 0.0, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 0.0, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pitfall!)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 16590.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 16590.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 16590.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pitfall!)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 0.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 0.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 0.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pitfall!)                                 SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://arxiv.org/abs/1509.06461", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 6463.7
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2039", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Skiing", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": -13062.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": -13062.3, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -13062.3, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Skiing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -12142.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": -12142.1, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -12142.1, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Skiing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -9021.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": -9021.8, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -9021.8, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Skiing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -11928.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": -11928.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": -11928.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Skiing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -8857.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": -8857.4, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": -8857.4, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Skiing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -18955.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": -18955.8, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -18955.8, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Skiing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -11490.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": -11490.4, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -11490.4, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Skiing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -10169.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": -10169.1, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": -10169.1, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Skiing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -9996.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": -9996.9, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": -9996.9, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Skiing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -19949.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": -19949.9, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": -19949.9, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Skiing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -14863.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": -14863.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -14863.8, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Skiing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -13700.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": -13700.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -13700.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Skiing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -10911.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": -10911.1, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -10911.1, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Skiing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4970.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 4970.0, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 4970.0, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Skiing)                                   SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -13901.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": -13901.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": -13901.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Skiing)                                   SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://arxiv.org/abs/1509.06461", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": -3686.6
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2039", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Solaris", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1295.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 1295.4, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1295.4, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3067.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 3067.8, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 3067.8, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3482.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 3482.8, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 3482.8, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1768.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 1768.4, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 1768.4, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2250.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 2250.8, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 2250.8, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 280.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 280.6, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 280.6, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 810.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 810.0, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 810.0, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2272.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 2272.8, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 2272.8, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4309.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 4309.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 4309.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 133.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 133.4, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 133.4, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1884.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 1884.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 1884.8, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1936.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 1936.4, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 1936.4, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1956.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 1956.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 1956.0, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 130.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 130.3, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 130.3, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8342.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 8342.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 8342.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://arxiv.org/abs/1509.06461", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 12326.7
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2039", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Surround", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": -6.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": -6.0, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -6.0, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -5.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": -5.6, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -5.6, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -2.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": -2.9, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -2.9, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 4.0, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 4.0, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 4.4, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 4.4, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -0.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": -0.2, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": -0.2, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 1.9, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 1.9, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 5.9, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 5.9, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 8.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 8.9, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 8.9, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 1.2, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 1.2, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -9.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": -9.7, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -9.7, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -9.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": -9.6, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -9.6, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -8.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": -8.3, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -8.3, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 22834.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "ES FF (1 hour) noop", 
                            "minval": 22834.8, 
                            "url": "https://arxiv.org/abs/1703.03864v1", 
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", 
                            "value": 22834.8, 
                            "label": "ES FF (1 hour) noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-10", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 6.8, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 6.8, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://arxiv.org/abs/1509.06461", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 6.5
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2039", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Yars Revenge", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4577.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN hs", 
                            "minval": 4577.5, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 4577.5, 
                            "label": "DQN hs", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11712.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) noop", 
                            "minval": 11712.6, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 11712.6, 
                            "label": "DDQN (tuned) noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Deep Reinforcement Learning with Double Q-learning", 
                            "min_date": "2015-12-08", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 18098.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DQN noop", 
                            "minval": 18098.9, 
                            "url": "https://arxiv.org/abs/1509.06461v1", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 18098.9, 
                            "label": "DQN noop", 
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf", 
                            "date": "2015-09-22", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Human-level control through deep reinforcement learning", 
                            "min_date": "2015-02-26", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 25976.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel hs", 
                            "minval": 25976.5, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 25976.5, 
                            "label": "Duel hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 49622.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Duel noop", 
                            "minval": 49622.1, 
                            "url": "https://arxiv.org/abs/1511.06581v1", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 49622.1, 
                            "label": "Duel noop", 
                            "algorithm_src_url": "", 
                            "date": "2015-11-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 6270.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "DDQN (tuned) hs", 
                            "minval": 6270.6, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 6270.6, 
                            "label": "DDQN (tuned) hs", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 58145.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel hs", 
                            "minval": 58145.9, 
                            "url": "https://arxiv.org/abs/1509.06461v3", 
                            "papername": "Deep Reinforcement Learning with Double Q-learning", 
                            "value": 58145.9, 
                            "label": "Prior+Duel hs", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2015-12-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 4687.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior hs", 
                            "minval": 4687.4, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 4687.4, 
                            "label": "Prior hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 11357.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior noop", 
                            "minval": 11357.0, 
                            "url": "https://arxiv.org/abs/1511.05952", 
                            "papername": "Prioritized Experience Replay", 
                            "value": 11357.0, 
                            "label": "Prior noop", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-06", 
                            "algorithms": [], 
                            "max_date": "2016-02-25", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 69618.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Prior+Duel noop", 
                            "minval": 69618.1, 
                            "url": "https://arxiv.org/abs/1511.06581v3", 
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning", 
                            "value": 69618.1, 
                            "label": "Prior+Duel noop", 
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952", 
                            "date": "2016-04-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Prioritized Experience Replay", 
                            "min_date": "2015-11-18", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 5615.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": 5615.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 5615.5, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7157.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": 7157.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 7157.5, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 7270.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": 7270.8, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": 7270.8, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 35050.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "C51 noop", 
                            "minval": 35050.0, 
                            "url": "https://arxiv.org/abs/1707.06887v1", 
                            "papername": "A Distributional Perspective on Reinforcement Learning", 
                            "value": 35050.0, 
                            "label": "C51 noop", 
                            "algorithm_src_url": "", 
                            "date": "2017-07-21", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": "https://arxiv.org/abs/1509.06461", 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": 54576.9
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/scrapers/atari.py#L2039", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Atari 2600 Pit Fall", 
                    "parent": "Problem(Simple video games)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": -135.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C LSTM hs", 
                            "minval": -135.7, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -135.7, 
                            "label": "A3C LSTM hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pit Fall)                                 ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -123.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF (1 day) hs", 
                            "minval": -123.0, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -123.0, 
                            "label": "A3C FF (1 day) hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pit Fall)                                 ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": -78.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "A3C FF hs", 
                            "minval": -78.5, 
                            "url": "https://arxiv.org/abs/1602.01783", 
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning", 
                            "value": -78.5, 
                            "label": "A3C FF hs", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-10", 
                            "algorithms": [], 
                            "max_date": "2016-06-16", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-02-04", 
                            "notes": "", 
                            "metric": "Metric(Atari 2600 Pit Fall)                                 ?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "scrapers/atari.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }
            ], 
            "solved": false, 
            "attributes": [
                "world-modelling", 
                "realtime-games", 
                "agi"
            ]
        }, 
        {
            "superproblems": [
                "Abstract strategy games"
            ], 
            "name": "Playing abstract games with extensive hints", 
            "url": null, 
            "subproblems": [], 
            "notes": "\n  Complex abstract strategy games have been solved to super-human levels\n  by computer systems with extensive rule-hinting and heuristics,\n  in some cases combined with machine learning techniques.\n", 
            "metrics": [
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/strategy_games.py#L59", 
                    "scale": "ELO rating", 
                    "target_label": "Best human play", 
                    "name": "Computer Chess", 
                    "parent": "Problem(Playing abstract games with extensive hints)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1631, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Novag Super Constellation 6502 4 MHz", 
                            "minval": 1631, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 1631, 
                            "label": "Novag Super Constellation...", 
                            "algorithm_src_url": "", 
                            "date": "1984-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1827, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Mephisto Amsterdam 68000 12 MHz", 
                            "minval": 1827, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 1827, 
                            "label": "Mephisto Amsterdam 68000 ...", 
                            "algorithm_src_url": "", 
                            "date": "1985-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1827, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Mephisto Amsterdam 68000 12 MHz", 
                            "minval": 1827, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 1827, 
                            "label": "Mephisto Amsterdam 68000 ...", 
                            "algorithm_src_url": "", 
                            "date": "1986-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1923, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Mephisto Dallas 68020 14 MHz", 
                            "minval": 1923, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 1923, 
                            "label": "Mephisto Dallas 68020 14 ...", 
                            "algorithm_src_url": "", 
                            "date": "1987-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1993, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Mephisto MM 4 Turbo Kit 6502 16 MHz", 
                            "minval": 1993, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 1993, 
                            "label": "Mephisto MM 4 Turbo Kit 6...", 
                            "algorithm_src_url": "", 
                            "date": "1988-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2027, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Mephisto Portorose 68020 12 MHz", 
                            "minval": 2027, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2027, 
                            "label": "Mephisto Portorose 68020 ...", 
                            "algorithm_src_url": "", 
                            "date": "1989-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2138, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Mephisto Portorose 68030 36 MHz", 
                            "minval": 2138, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2138, 
                            "label": "Mephisto Portorose 68030 ...", 
                            "algorithm_src_url": "", 
                            "date": "1990-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2127, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Mephisto Vancouver 68030 36 MHz", 
                            "minval": 2127, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2127, 
                            "label": "Mephisto Vancouver 68030 ...", 
                            "algorithm_src_url": "", 
                            "date": "1991-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2174, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Chess Machine Schroder 3.0 ARM2 30 MHz", 
                            "minval": 2174, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2174, 
                            "label": "Chess Machine Schroder 3....", 
                            "algorithm_src_url": "", 
                            "date": "1992-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2235, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Mephisto Genius 2.0 486/50-66 MHz", 
                            "minval": 2235, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2235, 
                            "label": "Mephisto Genius 2.0 486/5...", 
                            "algorithm_src_url": "", 
                            "date": "1993-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2306, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MChess Pro 5.0 Pentium 90 MHz", 
                            "minval": 2306, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2306, 
                            "label": "MChess Pro 5.0 Pentium 90...", 
                            "algorithm_src_url": "", 
                            "date": "1995-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2337, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Rebel 8.0 Pentium 90 MHz", 
                            "minval": 2337, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2337, 
                            "label": "Rebel 8.0 Pentium 90 MHz", 
                            "algorithm_src_url": "", 
                            "date": "1996-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2750, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep Blue", 
                            "minval": 2700, 
                            "url": "https://www.quora.com/What-was-Deep-Blues-Elo-rating", 
                            "papername": "What was Deep Blue's Elo rating? - Quora", 
                            "value": 2725, 
                            "label": "Deep Blue", 
                            "algorithm_src_url": "", 
                            "date": "1997-05-11", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2418, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "HIARCS 6.0 49MB P200 MMX", 
                            "minval": 2418, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2418, 
                            "label": "HIARCS 6.0 49MB P200 MMX", 
                            "algorithm_src_url": "", 
                            "date": "1997-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2460, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Fritz 5.0 PB29% 67MB P200 MMX", 
                            "minval": 2460, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2460, 
                            "label": "Fritz 5.0 PB29% 67MB P200...", 
                            "algorithm_src_url": "", 
                            "date": "1998-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2594, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Chess Tiger 12.0 DOS 128MB K6-2 450 MHz", 
                            "minval": 2594, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2594, 
                            "label": "Chess Tiger 12.0 DOS 128M...", 
                            "algorithm_src_url": "", 
                            "date": "1999-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2607, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Fritz 6.0 128MB K6-2 450 MHz", 
                            "minval": 2607, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2607, 
                            "label": "Fritz 6.0 128MB K6-2 450 ...", 
                            "algorithm_src_url": "", 
                            "date": "2000-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2709, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Chess Tiger 14.0 CB 256MB Athlon 1200", 
                            "minval": 2709, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2709, 
                            "label": "Chess Tiger 14.0 CB 256MB...", 
                            "algorithm_src_url": "", 
                            "date": "2001-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2759, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep Fritz 7.0 256MB Athlon 1200 MHz", 
                            "minval": 2759, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2759, 
                            "label": "Deep Fritz 7.0 256MB Athl...", 
                            "algorithm_src_url": "", 
                            "date": "2002-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2791, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Shredder 7.04 UCI 256MB Athlon 1200 MHz", 
                            "minval": 2791, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2791, 
                            "label": "Shredder 7.04 UCI 256MB A...", 
                            "algorithm_src_url": "", 
                            "date": "2003-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2800, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Shredder 8.0 CB 256MB Athlon 1200 MHz", 
                            "minval": 2800, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2800, 
                            "label": "Shredder 8.0 CB 256MB Ath...", 
                            "algorithm_src_url": "", 
                            "date": "2004-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2808, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Shredder 9.0 UCI 256MB Athlon 1200 MHz", 
                            "minval": 2808, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2808, 
                            "label": "Shredder 9.0 UCI 256MB At...", 
                            "algorithm_src_url": "", 
                            "date": "2005-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3020, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Rybka 1.1 64bit", 
                            "minval": 2970, 
                            "url": "https://web.archive.org/web/20060531091049/http://www.computerchess.org.uk/ccrl/4040/rating_list_all.html", 
                            "papername": "CCRL 40/40 - Complete list", 
                            "value": 2995, 
                            "label": "Rybka 1.1 64bit", 
                            "algorithm_src_url": "", 
                            "date": "2006-05-27", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2902, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Rybka 1.2 256MB Athlon 1200 MHz", 
                            "minval": 2902, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2902, 
                            "label": "Rybka 1.2 256MB Athlon 12...", 
                            "algorithm_src_url": "", 
                            "date": "2006-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 2935, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Rybka 2.3.1 Arena 256MB Athlon 1200 MHz", 
                            "minval": 2935, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 2935, 
                            "label": "Rybka 2.3.1 Arena 256MB A...", 
                            "algorithm_src_url": "", 
                            "date": "2007-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3238, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep Rybka 3 2GB Q6600 2.4 GHz", 
                            "minval": 3238, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 3238, 
                            "label": "Deep Rybka 3 2GB Q6600 2....", 
                            "algorithm_src_url": "", 
                            "date": "2008-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3232, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep Rybka 3 2GB Q6600 2.4 GHz", 
                            "minval": 3232, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 3232, 
                            "label": "Deep Rybka 3 2GB Q6600 2....", 
                            "algorithm_src_url": "", 
                            "date": "2009-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3291, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Rybka 4 64bit", 
                            "minval": 3247, 
                            "url": "https://web.archive.org/web/20100923131123/http://www.computerchess.org.uk/ccrl/4040/rating_list_all.html", 
                            "papername": "CCRL 40/40 - Complete list", 
                            "value": 3269, 
                            "label": "Rybka 4 64bit", 
                            "algorithm_src_url": "", 
                            "date": "2010-08-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3227, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep Rybka 3 2GB Q6600 2.4 GHz", 
                            "minval": 3227, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 3227, 
                            "label": "Deep Rybka 3 2GB Q6600 2....", 
                            "algorithm_src_url": "", 
                            "date": "2010-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3216, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep Rybka 4 2GB Q6600 2.4 GHz", 
                            "minval": 3216, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 3216, 
                            "label": "Deep Rybka 4 2GB Q6600 2....", 
                            "algorithm_src_url": "", 
                            "date": "2011-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3221, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep Rybka 4 x64 2GB Q6600 2.4 GHz", 
                            "minval": 3221, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 3221, 
                            "label": "Deep Rybka 4 x64 2GB Q660...", 
                            "algorithm_src_url": "", 
                            "date": "2012-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3264, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Houdini 3 64bit", 
                            "minval": 3232, 
                            "url": "https://web.archive.org/web/20130415000000*/http://www.computerchess.org.uk/ccrl/4040/rating_list_all.html", 
                            "papername": "Wayback Machine", 
                            "value": 3248, 
                            "label": "Houdini 3 64bit", 
                            "algorithm_src_url": "", 
                            "date": "2013-07-20", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3241, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Komodo 5.1 MP x64 2GB Q6600 2.4 GHz", 
                            "minval": 3241, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 3241, 
                            "label": "Komodo 5.1 MP x64 2GB Q66...", 
                            "algorithm_src_url": "", 
                            "date": "2013-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3295, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Komodo 7.0 MP x64 2GB Q6600 2.4 GHz", 
                            "minval": 3295, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 3295, 
                            "label": "Komodo 7.0 MP x64 2GB Q66...", 
                            "algorithm_src_url": "", 
                            "date": "2014-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3356, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Komodo 9", 
                            "minval": 3308, 
                            "url": "https://web.archive.org/web/20150708104805/http://www.computerchess.org.uk/ccrl/4040/rating_list_all.html", 
                            "papername": "CCRL 40/40 - Complete list", 
                            "value": 3332, 
                            "label": "Komodo 9", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-04", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3334, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Stockfish 6 MP x64 2GB Q6600 2.4 GHz", 
                            "minval": 3334, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 3334, 
                            "label": "Stockfish 6 MP x64 2GB Q6...", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3366, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Komodo 9.1 MP x64 2GB Q6600 2.4 GHz", 
                            "minval": 3366, 
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders", 
                            "papername": "Swedish Chess Computer Association - Wikipedia", 
                            "value": 3366, 
                            "label": "Komodo 9.1 MP x64 2GB Q66...", 
                            "algorithm_src_url": "", 
                            "date": "2016-12-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 3443, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Stockfish", 
                            "minval": 3343, 
                            "url": "https://web.archive.org/web/20170227044521/http://www.computerchess.org.uk/ccrl/4040/", 
                            "papername": "CCRL 40/40 - Index", 
                            "value": 3393, 
                            "label": "Stockfish", 
                            "algorithm_src_url": "", 
                            "date": "2017-02-27", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Computer Chess)                                      SOLVED", 
                            "opensource": false
                        }
                    ], 
                    "solved": true, 
                    "data_path": "data/strategy_games.py", 
                    "target_source": "https://en.wikipedia.org/w/index.php?title=Comparison_of_top_chess_players_throughout_history&oldid=777500496#Elo_system", 
                    "changeable": false, 
                    "axis_label": "ELO rating", 
                    "target": 2882
                }, 
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/strategy_games.py#L16", 
                    "scale": "ELO rating", 
                    "target_label": "Best human play", 
                    "name": "Computer Go", 
                    "parent": "Problem(Playing abstract games with extensive hints)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [], 
                    "solved": true, 
                    "data_path": null, 
                    "target_source": "https://www.goratings.org/en/history/", 
                    "changeable": false, 
                    "axis_label": "ELO rating", 
                    "target": 3632
                }
            ], 
            "solved": true, 
            "attributes": [
                "abstract-games"
            ]
        }, 
        {
            "superproblems": [], 
            "name": "Accurate modelling of human language.", 
            "url": null, 
            "subproblems": [], 
            "metrics": [
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L24", 
                    "scale": "Perplexity", 
                    "target_label": null, 
                    "name": "Penn Treebank (Perplexity when parsing English sentences)", 
                    "parent": "Problem(Accurate modelling of human language.)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 125.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "KN5+cache baseline", 
                            "minval": 125.7, 
                            "url": "http://www.fit.vutbr.cz/~imikolov/rnnlm/google.pdf", 
                            "papername": null, 
                            "value": 125.7, 
                            "label": "KN5+cache baseline", 
                            "algorithm_src_url": "", 
                            "date": "2012-04-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 78.8, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "KN5+RNNME ensemble", 
                            "minval": 78.8, 
                            "url": "http://www.fit.vutbr.cz/~imikolov/rnnlm/google.pdf", 
                            "papername": null, 
                            "value": 78.8, 
                            "label": "KN5+RNNME ensemble", 
                            "algorithm_src_url": "", 
                            "date": "2012-04-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 124.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RNNLM", 
                            "minval": 124.7, 
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2012/07/rnn_ctxt_TR.sav_.pdf", 
                            "papername": null, 
                            "value": 124.7, 
                            "label": "RNNLM", 
                            "algorithm_src_url": "", 
                            "date": "2012-07-27", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 113.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RNN-LDA LM", 
                            "minval": 113.7, 
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2012/07/rnn_ctxt_TR.sav_.pdf", 
                            "papername": null, 
                            "value": 113.7, 
                            "label": "RNN-LDA LM", 
                            "algorithm_src_url": "", 
                            "date": "2012-07-27", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 92.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RNN-LDA LM+KN5+cache", 
                            "minval": 92.0, 
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2012/07/rnn_ctxt_TR.sav_.pdf", 
                            "papername": null, 
                            "value": 92.0, 
                            "label": "RNN-LDA LM+KN5+cache", 
                            "algorithm_src_url": "", 
                            "date": "2012-07-27", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 80.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RNN-LDA ensemble", 
                            "minval": 80.1, 
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2012/07/rnn_ctxt_TR.sav_.pdf", 
                            "papername": null, 
                            "value": 80.1, 
                            "label": "RNN-LDA ensemble", 
                            "algorithm_src_url": "", 
                            "date": "2012-07-27", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 74.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RNN-LDA+all", 
                            "minval": 74.1, 
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2012/07/rnn_ctxt_TR.sav_.pdf", 
                            "papername": null, 
                            "value": 74.1, 
                            "label": "RNN-LDA+all", 
                            "algorithm_src_url": "", 
                            "date": "2012-07-27", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 107.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Deep RNN", 
                            "minval": 107.5, 
                            "url": "https://arxiv.org/abs/1312.6026", 
                            "papername": "How to Construct Deep Recurrent Neural Networks", 
                            "value": 107.5, 
                            "label": "Deep RNN", 
                            "algorithm_src_url": "", 
                            "date": "2013-12-20", 
                            "algorithms": [], 
                            "max_date": "2014-04-24", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2013-12-20", 
                            "notes": "", 
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 68.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RNN Dropout Regularization", 
                            "minval": 68.7, 
                            "url": "https://arxiv.org/abs/1409.2329v1", 
                            "papername": "Recurrent Neural Network Regularization", 
                            "value": 68.7, 
                            "label": "RNN Dropout Regularization", 
                            "algorithm_src_url": "", 
                            "date": "2014-09-08", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 70.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Pointer Sentinel-LSTM", 
                            "minval": 70.9, 
                            "url": "https://arxiv.org/abs/1609.07843v1", 
                            "papername": "Pointer Sentinel Mixture Models", 
                            "value": 70.9, 
                            "label": "Pointer Sentinel-LSTM", 
                            "algorithm_src_url": "", 
                            "date": "2016-09-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 73.4, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Variational LSTM", 
                            "minval": 73.4, 
                            "url": "https://arxiv.org/abs/1512.05287v5", 
                            "papername": "A Theoretically Grounded Application of Dropout in Recurrent Neural Networks", 
                            "value": 73.4, 
                            "label": "Variational LSTM", 
                            "algorithm_src_url": "", 
                            "date": "2016-10-05", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 68.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RHN", 
                            "minval": 68.5, 
                            "url": "https://arxiv.org/abs/1607.03474v3", 
                            "papername": "Recurrent Highway Networks", 
                            "value": 68.5, 
                            "label": "RHN", 
                            "algorithm_src_url": "", 
                            "date": "2016-10-27", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 66, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RHN+WT", 
                            "minval": 66, 
                            "url": "https://arxiv.org/abs/1607.03474v3", 
                            "papername": "Recurrent Highway Networks", 
                            "value": 66, 
                            "label": "RHN+WT", 
                            "algorithm_src_url": "", 
                            "date": "2016-10-27", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 71.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Variational RHN", 
                            "minval": 71.3, 
                            "url": "https://arxiv.org/abs/1607.03474", 
                            "papername": "Recurrent Highway Networks", 
                            "value": 71.3, 
                            "label": "Variational RHN", 
                            "algorithm_src_url": "", 
                            "date": "2017-01-06", 
                            "algorithms": [], 
                            "max_date": "2017-07-04", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-07-12", 
                            "notes": "", 
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/language.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Perplexity", 
                    "target": null
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L39", 
                    "scale": "Model Entropy", 
                    "target_label": null, 
                    "name": "Hutter Prize (bits per character to encode English text)", 
                    "parent": "Problem(Accurate modelling of human language.)", 
                    "url": null, 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RNN", 
                            "minval": 1.6, 
                            "url": "http://www.cs.utoronto.ca/~ilya/pubs/2011/LANG-RNN.pdf", 
                            "papername": null, 
                            "value": 1.6, 
                            "label": "RNN", 
                            "algorithm_src_url": "", 
                            "date": "2011-06-28", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.67, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "RNN, LSTM", 
                            "minval": 1.67, 
                            "url": "https://arxiv.org/abs/1308.0850", 
                            "papername": "Generating Sequences With Recurrent Neural Networks", 
                            "value": 1.67, 
                            "label": "RNN, LSTM", 
                            "algorithm_src_url": "", 
                            "date": "2013-08-04", 
                            "algorithms": [], 
                            "max_date": "2014-06-05", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2013-08-04", 
                            "notes": "", 
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.58, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Gated Feedback RNN", 
                            "minval": 1.58, 
                            "url": "https://arxiv.org/abs/1502.02367", 
                            "papername": "Gated Feedback Recurrent Neural Networks", 
                            "value": 1.58, 
                            "label": "Gated Feedback RNN", 
                            "algorithm_src_url": "", 
                            "date": "2015-02-15", 
                            "algorithms": [], 
                            "max_date": "2015-06-17", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-02-09", 
                            "notes": "", 
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.47, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Grid LSTM", 
                            "minval": 1.47, 
                            "url": "https://arxiv.org/abs/1507.01526", 
                            "papername": "Grid Long Short-Term Memory", 
                            "value": 1.47, 
                            "label": "Grid LSTM", 
                            "algorithm_src_url": "", 
                            "date": "2015-07-06", 
                            "algorithms": [], 
                            "max_date": "2016-01-07", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-07-06", 
                            "notes": "", 
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.32, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Recurrent Highway Networks", 
                            "minval": 1.32, 
                            "url": "https://arxiv.org/abs/1607.03474", 
                            "papername": "Recurrent Highway Networks", 
                            "value": 1.32, 
                            "label": "Recurrent Highway Networks", 
                            "algorithm_src_url": "", 
                            "date": "2016-07-12", 
                            "algorithms": [], 
                            "max_date": "2017-07-04", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-07-12", 
                            "notes": "", 
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.32, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": " Hierarchical Multiscale RNN", 
                            "minval": 1.32, 
                            "url": "https://arxiv.org/abs/1609.01704", 
                            "papername": "Hierarchical Multiscale Recurrent Neural Networks", 
                            "value": 1.32, 
                            "label": " Hierarchical Multiscale ...", 
                            "algorithm_src_url": "", 
                            "date": "2016-09-06", 
                            "algorithms": [], 
                            "max_date": "2017-03-09", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-09-06", 
                            "notes": "", 
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.39, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Hypernetworks", 
                            "minval": 1.39, 
                            "url": "https://arxiv.org/abs/1609.09106", 
                            "papername": "HyperNetworks", 
                            "value": 1.39, 
                            "label": "Hypernetworks", 
                            "algorithm_src_url": "", 
                            "date": "2016-09-27", 
                            "algorithms": [], 
                            "max_date": "2016-12-01", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-09-27", 
                            "notes": "", 
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.37, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Surprisal-Driven Feedback RNN", 
                            "minval": 1.37, 
                            "url": "https://arxiv.org/abs/1608.06027", 
                            "papername": "Surprisal-Driven Feedback in Recurrent Networks", 
                            "value": 1.37, 
                            "label": "Surprisal-Driven Feedback...", 
                            "algorithm_src_url": "", 
                            "date": "2016-10-19", 
                            "algorithms": [], 
                            "max_date": "2016-10-19", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-08-22", 
                            "notes": "", 
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 1.313, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Surprisal-Driven Zoneout", 
                            "minval": 1.313, 
                            "url": "https://pdfs.semanticscholar.org/e9bc/83f9ff502bec9cffb750468f76fdfcf5dd05.pdf", 
                            "papername": null, 
                            "value": 1.313, 
                            "label": "Surprisal-Driven Zoneout", 
                            "algorithm_src_url": "", 
                            "date": "2016-10-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/language.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Model Entropy", 
                    "target": 1.3
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/language.py#L47", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "LAMBADA prediction of words in discourse", 
                    "parent": "Problem(Accurate modelling of human language.)", 
                    "url": "https://arxiv.org/abs/1606.06031", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 21.7, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Stanford Reader", 
                            "minval": 21.7, 
                            "url": "https://arxiv.org/abs/1610.08431v3", 
                            "papername": "Broad Context Language Modeling as Reading Comprehension", 
                            "value": 21.7, 
                            "label": "Stanford Reader", 
                            "algorithm_src_url": "https://arxiv.org/abs/1606.02858", 
                            "date": "2017-02-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task", 
                            "min_date": "2016-06-09", 
                            "notes": "", 
                            "metric": "Metric(LAMBADA prediction of words in discourse)            not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 32.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "Modified Stanford", 
                            "minval": 32.1, 
                            "url": "https://arxiv.org/abs/1610.08431v3", 
                            "papername": "Broad Context Language Modeling as Reading Comprehension", 
                            "value": 32.1, 
                            "label": "Modified Stanford", 
                            "algorithm_src_url": "https://arxiv.org/abs/1606.02858", 
                            "date": "2017-02-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task", 
                            "min_date": "2016-06-09", 
                            "notes": "", 
                            "metric": "Metric(LAMBADA prediction of words in discourse)            not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 44.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "AS + feat.", 
                            "minval": 44.5, 
                            "url": "https://arxiv.org/abs/1610.08431v3", 
                            "papername": "Broad Context Language Modeling as Reading Comprehension", 
                            "value": 44.5, 
                            "label": "AS + feat.", 
                            "algorithm_src_url": "https://arxiv.org/abs/1603.01547", 
                            "date": "2017-02-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Text Understanding with the Attention Sum Reader Network", 
                            "min_date": "2016-03-04", 
                            "notes": "", 
                            "metric": "Metric(LAMBADA prediction of words in discourse)            not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 49.0, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "GA + feat.", 
                            "minval": 49.0, 
                            "url": "https://arxiv.org/abs/1610.08431v3", 
                            "papername": "Broad Context Language Modeling as Reading Comprehension", 
                            "value": 49.0, 
                            "label": "GA + feat.", 
                            "algorithm_src_url": "https://arxiv.org/abs/1606.01549v2", 
                            "date": "2017-02-16", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": "Gated-Attention Readers for Text Comprehension", 
                            "min_date": "2016-12-01", 
                            "notes": "", 
                            "metric": "Metric(LAMBADA prediction of words in discourse)            not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 51.6, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MAGE (48)", 
                            "minval": 51.6, 
                            "url": "https://arxiv.org/abs/1703.02620v1", 
                            "papername": "Linguistic Knowledge as Memory for Recurrent Neural Networks", 
                            "value": 51.6, 
                            "label": "MAGE (48)", 
                            "algorithm_src_url": "", 
                            "date": "2017-03-07", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(LAMBADA prediction of words in discourse)            not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/language.py", 
                    "target_source": "https://arxiv.org/abs/1610.08431v3", 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": 86
                }
            ], 
            "solved": false, 
            "attributes": [
                "language", 
                "agi"
            ]
        }, 
        {
            "superproblems": [
                "Play real-time computer & video games"
            ], 
            "name": "Games that require inventing novel language, forms of speech, or communication", 
            "url": null, 
            "subproblems": [
                "Games that require both understanding and speaking a language"
            ], 
            "metrics": [], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [
                "Know how to build general AI agents that will behave as expected"
            ], 
            "name": "Resistance to adversarial examples", 
            "url": "https://arxiv.org/abs/1312.6199", 
            "subproblems": [], 
            "notes": "\nWe know that humans have significant resistance to adversarial examples.  Although methods like camouflage sometimes\nwork to fool us into thinking one thing is another, those\n", 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "safety", 
                "agi", 
                "security"
            ]
        }, 
        {
            "superproblems": [
                "Write computer programs from specifications"
            ], 
            "name": "Parse and implement complex conditional expressions", 
            "url": null, 
            "subproblems": [], 
            "metrics": [], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [
                "Image classification"
            ], 
            "name": "Image comprehension", 
            "url": null, 
            "subproblems": [], 
            "metrics": [
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/vision.py#L81", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "COCO Visual Question Answering (VQA) 1.0 open ended", 
                    "parent": "Problem(Image comprehension)", 
                    "url": "http://visualqa.org/", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 58.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "LSTM Q+I", 
                            "minval": 58.2, 
                            "url": "https://arxiv.org/abs/1505.00468v1", 
                            "papername": "VQA: Visual Question Answering", 
                            "value": 58.2, 
                            "label": "LSTM Q+I", 
                            "algorithm_src_url": "", 
                            "date": "2015-05-03", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 55.89, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "iBOWIMG baseline", 
                            "minval": 55.89, 
                            "url": "https://arxiv.org/abs/1512.02167", 
                            "papername": "Simple Baseline for Visual Question Answering", 
                            "value": 55.89, 
                            "label": "iBOWIMG baseline", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-15", 
                            "algorithms": [], 
                            "max_date": "2015-12-15", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-12-07", 
                            "notes": "", 
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 58.9, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SAN", 
                            "minval": 58.9, 
                            "url": "https://arxiv.org/abs/1511.02274v2", 
                            "papername": "Stacked Attention Networks for Image Question Answering", 
                            "value": 58.9, 
                            "label": "SAN", 
                            "algorithm_src_url": "", 
                            "date": "2016-01-26", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 59.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "CNN-RNN", 
                            "minval": 59.5, 
                            "url": "https://arxiv.org/abs/1603.02814v1", 
                            "papername": "Image Captioning and Visual Question Answering Based on Attributes and Their Related External Knowledge", 
                            "value": 59.5, 
                            "label": "CNN-RNN", 
                            "algorithm_src_url": "", 
                            "date": "2016-03-09", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 58.24, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "SMem-VQA", 
                            "minval": 58.24, 
                            "url": "https://arxiv.org/abs/1511.05234v2", 
                            "papername": "Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering", 
                            "value": 58.24, 
                            "label": "SMem-VQA", 
                            "algorithm_src_url": "", 
                            "date": "2016-03-19", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 59.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "FDA", 
                            "minval": 59.5, 
                            "url": "https://arxiv.org/abs/1604.01485v1", 
                            "papername": "A Focused Dynamic Attention Model for Visual Question Answering", 
                            "value": 59.5, 
                            "label": "FDA", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-06", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 62.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "HQI+ResNet", 
                            "minval": 62.1, 
                            "url": "https://arxiv.org/abs/1606.00061v1", 
                            "papername": "Hierarchical Co-Attention for Visual Question Answering", 
                            "value": 62.1, 
                            "label": "HQI+ResNet", 
                            "algorithm_src_url": "", 
                            "date": "2016-05-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 66.5, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MCB 7 att.", 
                            "minval": 66.5, 
                            "url": "https://arxiv.org/abs/1606.01847v1", 
                            "papername": "Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding", 
                            "value": 66.5, 
                            "label": "MCB 7 att.", 
                            "algorithm_src_url": "", 
                            "date": "2016-06-06", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "https://github.com/akirafukui/vqa-mcb", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 63.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "joint-loss", 
                            "minval": 63.2, 
                            "url": "https://arxiv.org/abs/1606.03647", 
                            "papername": "Training Recurrent Answering Units with Joint Loss Minimization for VQA", 
                            "value": 63.2, 
                            "label": "joint-loss", 
                            "algorithm_src_url": "", 
                            "date": "2016-08-06", 
                            "algorithms": [], 
                            "max_date": "2016-09-30", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-06-12", 
                            "notes": "", 
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/vision.py", 
                    "target_source": "https://arxiv.org/abs/1505.00468", 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": 84.122371649179
                }, 
                {
                    "graphed": true, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/vision.py#L82", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "COCO Visual Question Answering (VQA) 1.0 multiple choice", 
                    "parent": "Problem(Image comprehension)", 
                    "url": "http://visualqa.org/", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 63.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "LSTM Q+I", 
                            "minval": 63.1, 
                            "url": "https://arxiv.org/abs/1505.00468v1", 
                            "papername": "VQA: Visual Question Answering", 
                            "value": 63.1, 
                            "label": "LSTM Q+I", 
                            "algorithm_src_url": "", 
                            "date": "2015-05-03", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 multiple choice)?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 61.97, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "iBOWIMG baseline", 
                            "minval": 61.97, 
                            "url": "https://arxiv.org/abs/1512.02167", 
                            "papername": "Simple Baseline for Visual Question Answering", 
                            "value": 61.97, 
                            "label": "iBOWIMG baseline", 
                            "algorithm_src_url": "", 
                            "date": "2015-12-15", 
                            "algorithms": [], 
                            "max_date": "2015-12-15", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2015-12-07", 
                            "notes": "", 
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 multiple choice)?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 64.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "FDA", 
                            "minval": 64.2, 
                            "url": "https://arxiv.org/abs/1604.01485v1", 
                            "papername": "A Focused Dynamic Attention Model for Visual Question Answering", 
                            "value": 64.2, 
                            "label": "FDA", 
                            "algorithm_src_url": "", 
                            "date": "2016-04-06", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 multiple choice)?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 66.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "HQI+ResNet", 
                            "minval": 66.1, 
                            "url": "https://arxiv.org/abs/1606.00061v1", 
                            "papername": "Hierarchical Co-Attention for Visual Question Answering", 
                            "value": 66.1, 
                            "label": "HQI+ResNet", 
                            "algorithm_src_url": "", 
                            "date": "2016-05-31", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 multiple choice)?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 70.1, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MCB 7 att.", 
                            "minval": 70.1, 
                            "url": "https://arxiv.org/abs/1606.01847v1", 
                            "papername": "Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding", 
                            "value": 70.1, 
                            "label": "MCB 7 att.", 
                            "algorithm_src_url": "", 
                            "date": "2016-06-06", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "https://github.com/akirafukui/vqa-mcb", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 multiple choice)?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 67.3, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "joint-loss", 
                            "minval": 67.3, 
                            "url": "https://arxiv.org/abs/1606.03647", 
                            "papername": "Training Recurrent Answering Units with Joint Loss Minimization for VQA", 
                            "value": 67.3, 
                            "label": "joint-loss", 
                            "algorithm_src_url": "", 
                            "date": "2016-08-06", 
                            "algorithms": [], 
                            "max_date": "2016-09-30", 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": "2016-06-12", 
                            "notes": "", 
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 multiple choice)?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/vision.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": null
                }, 
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/vision.py#L49", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Toronto COCO-QA", 
                    "parent": "Problem(Image comprehension)", 
                    "url": "http://www.cs.toronto.edu/~mren/imageqa/data/cocoqa/", 
                    "notes": "", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }, 
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/vision.py#L50", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "DAQUAR", 
                    "parent": "Problem(Image comprehension)", 
                    "url": "https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/vision-and-language/visual-turing-challenge/", 
                    "notes": "", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": "https://arxiv.org/abs/1505.02074", 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": 60.27
                }, 
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/vision.py#L86", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "Visual Genome (pairs)", 
                    "parent": "Problem(Image comprehension)", 
                    "url": "http://visualgenome.org", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 28.52, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "CMN", 
                            "minval": 28.52, 
                            "url": "https://arxiv.org/abs/1611.09978v1", 
                            "papername": "Modeling Relationships in Referential Expressions with Compositional Modular Networks", 
                            "value": 28.52, 
                            "label": "CMN", 
                            "algorithm_src_url": "", 
                            "date": "2016-11-30", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Visual Genome (pairs))                               ?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/vision.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Top-1 precision", 
                    "target": null
                }, 
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/vision.py#L87", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "Visual Genome (subjects)", 
                    "parent": "Problem(Image comprehension)", 
                    "url": "http://visualgenome.org", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 44.24, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "CMN", 
                            "minval": 44.24, 
                            "url": "https://arxiv.org/abs/1611.09978v1", 
                            "papername": "Modeling Relationships in Referential Expressions with Compositional Modular Networks", 
                            "value": 44.24, 
                            "label": "CMN", 
                            "algorithm_src_url": "", 
                            "date": "2016-11-30", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Visual Genome (subjects))                            ?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/vision.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Top-1 precision", 
                    "target": null
                }, 
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/vision.py#L85", 
                    "scale": "Percentage correct", 
                    "target_label": null, 
                    "name": "Visual7W", 
                    "parent": "Problem(Image comprehension)", 
                    "url": "https://arxiv.org/abs/1511.03416", 
                    "notes": "", 
                    "measures": [
                        {
                            "not_directly_comparable": false, 
                            "maxval": 62.2, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "MCB+Att.", 
                            "minval": 62.2, 
                            "url": "https://arxiv.org/abs/1606.01847v1", 
                            "papername": "Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding", 
                            "value": 62.2, 
                            "label": "MCB+Att.", 
                            "algorithm_src_url": "", 
                            "date": "2016-06-06", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Visual7W)                                            ?", 
                            "opensource": false
                        }, 
                        {
                            "not_directly_comparable": false, 
                            "maxval": 72.53, 
                            "long_label": false, 
                            "withdrawn": false, 
                            "name": "CMN", 
                            "minval": 72.53, 
                            "url": "https://arxiv.org/abs/1611.09978v1", 
                            "papername": "Modeling Relationships in Referential Expressions with Compositional Modular Networks", 
                            "value": 72.53, 
                            "label": "CMN", 
                            "algorithm_src_url": "", 
                            "date": "2016-11-30", 
                            "algorithms": [], 
                            "max_date": null, 
                            "replicated_url": "", 
                            "src_name": null, 
                            "min_date": null, 
                            "notes": "", 
                            "metric": "Metric(Visual7W)                                            ?", 
                            "opensource": false
                        }
                    ], 
                    "solved": false, 
                    "data_path": "data/vision.py", 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Percentage correct", 
                    "target": null
                }, 
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/vision.py#L55", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "FM-IQA", 
                    "parent": "Problem(Image comprehension)", 
                    "url": "http://idl.baidu.com/FM-IQA.html", 
                    "notes": "", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }, 
                {
                    "graphed": false, 
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/data/vision.py#L56", 
                    "scale": "Score", 
                    "target_label": null, 
                    "name": "Visual Madlibs", 
                    "parent": "Problem(Image comprehension)", 
                    "url": "http://tamaraberg.com/visualmadlibs/", 
                    "notes": "", 
                    "measures": [], 
                    "solved": false, 
                    "data_path": null, 
                    "target_source": null, 
                    "changeable": false, 
                    "axis_label": "Score", 
                    "target": null
                }
            ], 
            "solved": false, 
            "attributes": [
                "agi", 
                "vision", 
                "language", 
                "world-modelling"
            ]
        }, 
        {
            "superproblems": [], 
            "name": "Be able to generate complex scene e.g. a baboon receiving their degree at convocatoin.", 
            "url": null, 
            "subproblems": [
                "Drawing pictures"
            ], 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "vision", 
                "world-modelling", 
                "agi"
            ]
        }, 
        {
            "superproblems": [
                "Given an arbitrary technical problem, solve it as well as a typical professional in that field"
            ], 
            "name": "Solve vaguely or under-constrained technical problems", 
            "url": null, 
            "subproblems": [
                "Read a scientific or technical paper, and comprehend its contents", 
                "Write computer programs from specifications"
            ], 
            "metrics": [], 
            "solved": false, 
            "attributes": []
        }, 
        {
            "superproblems": [
                "Know how to build general AI agents that will behave as expected"
            ], 
            "name": "Avoiding undesirable side effects", 
            "url": "https://arxiv.org/abs/1606.06565", 
            "subproblems": [], 
            "metrics": [], 
            "solved": false, 
            "attributes": [
                "safety"
            ], 
            "nodes": "\nMany important constraints on good behaviour will not be explicitly\nencoded in goal specification, either because they are too hard to capture\nor simply because there are so many of them and they are hard to enumerate\n"
        }
    ]
}