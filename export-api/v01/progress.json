{
    "problems": [
        {
            "name": "Play real-time computer & video games",
            "superproblems": "<map object at 0x7f5a5cab50f0>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a5cab52e8>",
            "url": null,
            "solved": false,
            "attributes": [
                "world-modelling",
                "realtime-games",
                "agi",
                "language"
            ]
        },
        {
            "name": "Simple video games",
            "superproblems": "<map object at 0x7f5a5cab5cc0>",
            "metrics": [
                {
                    "notes": "",
                    "target": 6875,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Atari 2600 Alien",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 103.2,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 103.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 103.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 939.2,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 939.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 939.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 3069.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 4162.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 1976.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 1093.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 813.5,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 813.5,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 813.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 634.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 634.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 634.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1620.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 1620.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 1620.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 1486.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 1486.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 1486.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 3747.7,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 3747.7,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 3747.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 4461.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 4461.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 4461.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 823.7,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 823.7,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 823.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1033.4,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 1033.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 1033.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 1334.7,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 1334.7,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 1334.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 4203.8,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 4203.8,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 4203.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 3213.5,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 3213.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 3213.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 3941.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 3941.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 3941.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 182.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 182.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 182.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 518.4,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 518.4,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 518.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 945.3,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 945.3,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 945.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 994.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 994.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 994.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 3166.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 3166.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Alien)                                    not solved",
                            "minval": 3166.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 1676,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Amidar",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 183.6,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 183.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 183.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 103.4,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 103.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 103.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 739.5,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 3763.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": -2284.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 3024.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 189.2,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 189.2,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 189.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 178.4,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 178.4,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 178.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 978.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 978.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 978.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 172.7,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 172.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 172.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 1793.3,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 1793.3,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 1793.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 2354.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 2354.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 2354.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 169.1,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 169.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 169.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 238.4,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 238.4,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 238.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 129.1,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 129.1,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 129.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 1838.9,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 1838.9,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 1838.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 782.5,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 782.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 782.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 2296.8,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 2296.8,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 2296.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 173.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 173.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 173.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 263.9,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 263.9,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 263.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 283.9,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 283.9,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 283.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 112.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 112.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 112.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 1735.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 1735.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Amidar)                                   SOLVED",
                            "minval": 1735.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 1496,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Assault",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 537.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 537.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 537.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 628.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 628.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 628.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 3359.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 4134.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 2584.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 775.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 1195.8,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 1195.8,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 1195.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 3489.3,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 3489.3,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 3489.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 4280.4,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 4280.4,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 4280.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 3994.8,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 3994.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 3994.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 4621.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 4621.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 4621.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 5393.2,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 5393.2,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 5393.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 6060.8,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 6060.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 6060.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 10950.6,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 10950.6,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 10950.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 6548.9,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 6548.9,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 6548.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 7672.1,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 7672.1,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 7672.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 9011.6,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 9011.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 9011.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 11477.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 11477.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 11477.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 3746.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 3746.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 3746.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 5474.9,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 5474.9,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 5474.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 14497.9,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 14497.9,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 14497.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 1673.9,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 1673.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 1673.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 7203.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 7203.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Assault)                                  SOLVED",
                            "minval": 7203.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 8503,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Asterix",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 1332.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 1332.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 1332.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 987.3,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 987.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 987.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 6012.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 7756.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 4268.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 1744.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 3324.7,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 3324.7,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 3324.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 3170.5,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 3170.5,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 3170.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 4359.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 4359.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 4359.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 15840.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 15840.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 15840.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 17356.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 17356.5,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 17356.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 28188.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 28188.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 28188.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 16837.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 16837.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 16837.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 364200.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 364200.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 364200.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 22484.5,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 22484.5,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 22484.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 31527.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 31527.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 31527.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 18919.5,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 18919.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 18919.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 375080.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 375080.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 375080.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 6723.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 6723.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 6723.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 17244.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 17244.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 17244.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 22140.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 22140.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 22140.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 1440.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 1440.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 1440.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 406211.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 406211.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asterix)                                  SOLVED",
                            "minval": 406211.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 13157,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Atari 2600 Asteroids",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 89.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 89.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 89.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 907.3,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 907.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 907.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 1629.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 2171.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 1087.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 542.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 933.6,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 933.6,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 933.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1364.5,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 1364.5,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 1364.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1458.7,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 1458.7,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 1458.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 734.7,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 734.7,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 734.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 2035.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 2035.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 2035.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 2837.7,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 2837.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 2837.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1021.9,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 1021.9,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 1021.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1193.2,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 1193.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 1193.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 1745.1,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 1745.1,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 1745.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 2654.3,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 2654.3,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 2654.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 2869.3,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 2869.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 2869.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 1192.7,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 1192.7,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 1192.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 3009.4,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 3009.4,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 3009.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 4474.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 4474.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 4474.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 5093.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 5093.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 5093.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 1562.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 1562.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 1562.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 1516.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 1516.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Asteroids)                                not solved",
                            "minval": 1516.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 29028,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Atlantis",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 852.9,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 852.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 852.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 62687.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 62687.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 62687.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 85641.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 103241.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 68041.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 17600.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 629166.5,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 629166.5,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 629166.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 279987.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 279987.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 279987.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 292491.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 292491.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 292491.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 106056.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 106056.0,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 106056.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 382572.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 382572.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 382572.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 445360.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 445360.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 445360.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 319688.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 319688.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 319688.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 423252.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 423252.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 423252.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 330647.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 330647.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 330647.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 357324.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 357324.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 357324.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 340076.0,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 340076.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 340076.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 395762.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 395762.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 395762.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 772392.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 772392.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 772392.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 875822.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 875822.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 875822.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 911091.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 911091.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 911091.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 1267410.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 1267410.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 1267410.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 841075.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 841075.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Atlantis)                                 SOLVED",
                            "minval": 841075.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 734.4,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Bank Heist",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 67.4,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 67.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 67.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 190.8,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 190.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 190.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 429.7,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 1079.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": -220.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 650.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 399.4,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 399.4,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 399.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 312.7,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 312.7,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 312.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 455.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 455.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 455.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 1030.6,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 1030.6,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 1030.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 1129.3,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 1129.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 1129.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 1611.9,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 1611.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 1611.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 886.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 886.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 886.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1004.6,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 1004.6,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 1004.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 876.6,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 876.6,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 876.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 1054.6,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 1054.6,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 1054.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 1103.3,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 1103.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 1103.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 1503.1,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 1503.1,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 1503.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 932.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 932.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 932.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 946.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 946.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 946.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 970.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 970.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 970.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 225.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 225.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 225.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 976.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 976.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bank Heist)                               SOLVED",
                            "minval": 976.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 37800,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Atari 2600 Battle Zone",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 16.2,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 16.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 16.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 15820.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 15820.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 15820.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 26300.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 34025.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 18575.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 7725.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 19938.0,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 19938.0,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 19938.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 23750.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 23750.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 23750.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 29900.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 29900.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 29900.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 31320.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 31320.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 31320.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 31700.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 31700.0,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 31700.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 37150.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 37150.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 37150.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 24740.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 24740.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 24740.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 30650.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 30650.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 30650.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 25520.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 25520.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 25520.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 31530.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 31530.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 31530.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 8220.0,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 8220.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 8220.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 35520.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 35520.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 35520.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 11340.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 11340.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 11340.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 12950.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 12950.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 12950.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 20760.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 20760.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 20760.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 16600.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 16600.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 16600.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 28742.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 28742.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Battle Zone)                              not solved",
                            "minval": 28742.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 7456,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Beam Rider",
                    "target_source": "https://arxiv.org/pdf/1312.5602.pdf",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 1743.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 1743.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 1743.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 929.4,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 929.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 929.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-12-19",
                            "papername": "Playing Atari with Deep Reinforcement Learning",
                            "value": 5184,
                            "url": "https://arxiv.org/abs/1312.5602",
                            "min_date": null,
                            "maxval": 5184,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 5184,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN best",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN best"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 6846.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 8465.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 5227.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 1619.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 3822.1,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 3822.1,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 3822.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 8627.5,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 8627.5,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 8627.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 9743.2,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 9743.2,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 9743.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 12164.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 12164.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 12164.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 13772.8,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 13772.8,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 13772.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 14591.3,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 14591.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 14591.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 17417.2,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 17417.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 17417.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 37412.2,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 37412.2,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 37412.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 23384.2,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 23384.2,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 23384.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 31181.3,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 31181.3,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 31181.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 8299.4,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 8299.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 8299.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 30276.5,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 30276.5,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 30276.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 13235.9,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 13235.9,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 13235.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 22707.9,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 22707.9,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 22707.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 24622.2,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 24622.2,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 24622.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 744.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 744.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 744.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 14074.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 14074.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Beam Rider)                               SOLVED",
                            "minval": 14074.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 2630.4,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2347",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Berzerk",
                    "target_source": "https://arxiv.org/abs/1511.06581v1",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 493.4,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 493.4,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED",
                            "minval": 493.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 585.6,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 585.6,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED",
                            "minval": 585.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 910.6,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 910.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED",
                            "minval": 910.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 1225.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 1225.4,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED",
                            "minval": 1225.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 1472.6,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 1472.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED",
                            "minval": 1472.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1011.1,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 1011.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED",
                            "minval": 1011.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 2178.6,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 2178.6,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED",
                            "minval": 2178.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 865.9,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 865.9,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED",
                            "minval": 865.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 1305.6,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 1305.6,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED",
                            "minval": 1305.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 1199.6,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 1199.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED",
                            "minval": 1199.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 3409.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 3409.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED",
                            "minval": 3409.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 817.9,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 817.9,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED",
                            "minval": 817.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 862.2,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 862.2,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED",
                            "minval": 862.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 1433.4,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 1433.4,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED",
                            "minval": 1433.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 686.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 686.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED",
                            "minval": 686.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 1645.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 1645.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Berzerk)                                  SOLVED",
                            "minval": 1645.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 154.8,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Atari 2600 Bowling",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 36.4,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 36.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 36.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 43.9,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 43.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 43.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 42.4,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 130.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": -45.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 88.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 54.0,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 54.0,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 54.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 50.4,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 50.4,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 50.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 56.5,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 56.5,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 56.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 65.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 65.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 65.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 65.7,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 65.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 65.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 68.1,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 68.1,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 68.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 50.4,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 50.4,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 50.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 69.6,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 69.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 69.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 47.9,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 47.9,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 47.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 52.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 52.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 52.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 102.1,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 102.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 102.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 46.7,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 46.7,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 46.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 35.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 35.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 35.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 36.2,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 36.2,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 36.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 41.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 41.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 41.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 30.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 30.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 30.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 81.8,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 81.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Bowling)                                  not solved",
                            "minval": 81.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 4.3,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Boxing",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 9.8,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 9.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 9.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 44.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 44.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 44.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 71.8,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 79.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 63.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 8.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 74.2,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 74.2,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 74.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 70.3,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 70.3,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 70.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 88.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 88.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 88.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 77.3,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 77.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 77.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 91.6,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 91.6,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 91.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 99.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 99.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 99.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 73.5,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 73.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 73.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 79.2,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 79.2,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 79.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 72.3,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 72.3,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 72.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 95.6,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 95.6,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 95.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 99.3,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 99.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 99.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 98.9,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 98.9,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 98.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 33.7,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 33.7,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 33.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 37.3,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 37.3,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 37.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 59.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 59.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 59.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 49.8,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 49.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 49.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 97.8,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 97.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Boxing)                                   SOLVED",
                            "minval": 97.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 31.8,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Breakout",
                    "target_source": "https://pdfs.semanticscholar.org/340f/48901f72278f6bf78a04ee5b01df208cc508.pdf",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 6.1,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 6.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 6.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 5.2,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 5.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 5.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-12-19",
                            "papername": "Playing Atari with Deep Reinforcement Learning",
                            "value": 225,
                            "url": "https://arxiv.org/abs/1312.5602",
                            "min_date": null,
                            "maxval": 225,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 225,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN best",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN best"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 401.2,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 427.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 375.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 26.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 313.0,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 313.0,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 313.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 354.5,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 354.5,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 354.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 385.5,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 385.5,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 385.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 345.3,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 345.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 345.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 411.6,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 411.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 411.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 418.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 418.5,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 418.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 354.6,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 354.6,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 354.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 368.9,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 368.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 368.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 343.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 343.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 343.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 373.9,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 373.9,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 373.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 344.1,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 344.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 344.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 366.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 366.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 366.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 551.6,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 551.6,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 551.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 681.9,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 681.9,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 681.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 766.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 766.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 766.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 9.5,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 9.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 9.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 748.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 748.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Breakout)                                 SOLVED",
                            "minval": 748.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 11963,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Centipede",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 4647.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 4647.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 4647.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 8803.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 8803.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 8803.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 8309.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 13546.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 3072.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 5237.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 6296.9,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 6296.9,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 6296.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 3973.9,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 3973.9,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 3973.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 4657.7,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 4657.7,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 4657.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 4881.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 4881.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 4881.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 5409.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 5409.4,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 5409.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 7561.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 7561.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 7561.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 3853.5,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 3853.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 3853.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 5570.2,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 5570.2,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 5570.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 3489.1,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 3489.1,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 3489.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 4463.2,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 4463.2,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 4463.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 49065.8,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 49065.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 49065.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 7687.5,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 7687.5,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 7687.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 1997.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 1997.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 1997.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 3306.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 3306.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 3306.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 3755.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 3755.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 3755.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 7783.9,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 7783.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 7783.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 9646.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 9646.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Centipede)                                SOLVED",
                            "minval": 9646.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 9882,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Chopper Command",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 16.9,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 16.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 16.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 1582.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 1582.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 1582.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 6687.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 9603.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 3771.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 2916.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 3191.8,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 3191.8,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 3191.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 5017.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 5017.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 5017.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 6126.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 6126.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 6126.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 3784.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 3784.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 3784.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 5809.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 5809.0,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 5809.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 11215.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 11215.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 11215.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 3495.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 3495.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 3495.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 8058.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 8058.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 8058.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 4635.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 4635.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 4635.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 8600.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 8600.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 8600.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 775.0,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 775.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 775.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 13185.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 13185.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 13185.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 4669.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 4669.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 4669.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 7021.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 7021.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 7021.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 10150.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 10150.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 10150.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 3710.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 3710.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 3710.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 15600.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 15600.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Chopper Command)                          SOLVED",
                            "minval": 15600.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 35411,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Crazy Climber",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 149.8,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 149.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 149.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 23411.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 23411.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 23411.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 114103.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 136900.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 91306.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 22797.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 65451.0,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 65451.0,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 65451.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 98128.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 98128.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 98128.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 110763.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 110763.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 110763.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 117282.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 117282.0,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 117282.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 124566.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 124566.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 124566.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 143570.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 143570.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 143570.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 113782.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 113782.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 113782.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 127853.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 127853.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 127853.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 127512.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 127512.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 127512.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 141161.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 141161.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 141161.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 119679.0,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 119679.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 119679.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 162224.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 162224.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 162224.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 101624.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 101624.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 101624.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 112646.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 112646.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 112646.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 138518.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 138518.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 138518.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 26430.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 26430.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 26430.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 179877.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 179877.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Crazy Climber)                            SOLVED",
                            "minval": 179877.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 3401,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Demon Attack",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 0.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 0.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 520.5,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 520.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 520.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 9711.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 12117.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 7305.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 2406.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 14880.1,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 14880.1,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 14880.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 12149.4,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 12149.4,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 12149.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 12550.7,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 12550.7,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 12550.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 56322.8,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 56322.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 56322.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 58044.2,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 58044.2,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 58044.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 60813.3,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 60813.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 60813.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 69803.4,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 69803.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 69803.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 73371.3,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 73371.3,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 73371.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 61277.5,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 61277.5,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 61277.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 71846.4,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 71846.4,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 71846.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 63644.9,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 63644.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 63644.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 72878.6,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 72878.6,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 72878.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 84997.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 84997.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 84997.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 113308.4,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 113308.4,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 113308.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 115201.9,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 115201.9,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 115201.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 1166.5,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 1166.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 1166.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 130955.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 130955.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Demon Attack)                             SOLVED",
                            "minval": 130955.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": -15.5,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Double Dunk",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": -16.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": -16.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": -16.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": -13.1,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": -13.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": -13.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": -18.1,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": -16.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": -20.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 2.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": -11.3,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": -11.3,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": -11.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -6.6,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": -6.6,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": -6.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -6.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": -6.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": -6.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": -5.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": -5.5,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": -5.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": -0.8,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": -0.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": -0.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 0.1,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 0.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": 0.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -10.7,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": -10.7,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": -10.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -0.3,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": -0.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": -0.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 16.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 16.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": 16.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 18.5,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 18.5,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": 18.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": -11.5,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": -11.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": -11.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": -12.5,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": -12.5,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": -12.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -0.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -0.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": -0.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 0.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 0.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": 0.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 0.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 0.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": 0.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 0.2,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 0.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": 0.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 2.5,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 2.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Double Dunk)                              SOLVED",
                            "minval": 2.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 309.6,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Enduro",
                    "target_source": "https://pdfs.semanticscholar.org/340f/48901f72278f6bf78a04ee5b01df208cc508.pdf",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 159.4,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 159.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 159.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 129.1,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 129.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 129.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-12-19",
                            "papername": "Playing Atari with Deep Reinforcement Learning",
                            "value": 661,
                            "url": "https://arxiv.org/abs/1312.5602",
                            "min_date": null,
                            "maxval": 661,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 661,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN best",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN best"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 301.8,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 325.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 277.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 24.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 71.0,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 71.0,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 71.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 626.7,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 626.7,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 626.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 729.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 729.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 729.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 1211.8,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 1211.8,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 1211.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 2077.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 2077.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 2077.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 2258.2,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 2258.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 2258.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1216.6,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 1216.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 1216.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 2223.9,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 2223.9,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 2223.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 1831.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 1831.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 1831.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 2093.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 2093.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 2093.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 2002.1,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 2002.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 2002.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 2306.4,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 2306.4,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 2306.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -82.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -82.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": -82.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -82.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -82.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": -82.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -82.2,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -82.2,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": -82.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 95.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 95.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 95.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 3454.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 3454.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Enduro)                                   SOLVED",
                            "minval": 3454.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 5.5,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Fishing Derby",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": -85.1,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": -85.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": -85.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": -89.5,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": -89.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": -89.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": -0.8,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 18.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": -19.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 19.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 4.6,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 4.6,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": 4.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -4.9,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": -4.9,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": -4.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -1.6,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": -1.6,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": -1.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": -4.1,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": -4.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": -4.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 15.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 15.5,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": 15.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 46.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 46.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": 46.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 3.2,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 3.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": 3.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 17.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 17.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": 17.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 9.8,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 9.8,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": 9.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 39.5,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 39.5,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": 39.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 45.1,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 45.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": 45.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 41.3,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 41.3,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": 41.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 13.6,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 13.6,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": 13.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 18.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 18.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": 18.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 22.6,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 22.6,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": 22.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": -49.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": -49.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": -49.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 8.9,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 8.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Fishing Derby)                            SOLVED",
                            "minval": 8.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 29.6,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Freeway",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 19.7,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 19.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 19.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 19.1,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 19.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 19.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 30.3,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 30.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 30.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 10.2,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 10.2,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 10.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 26.9,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 26.9,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 26.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 30.8,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 30.8,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 30.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 0.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 0.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 0.2,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 0.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 0.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 33.3,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 33.3,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 33.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 28.2,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 28.2,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 28.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 28.8,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 28.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 28.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 28.9,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 28.9,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 28.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 33.7,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 33.7,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 33.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 33.4,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 33.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 33.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 33.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 33.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 33.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 0.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 0.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 0.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 0.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 0.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 0.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 0.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 0.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 0.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 31.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 31.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 31.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 33.9,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 33.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Freeway)                                  SOLVED",
                            "minval": 33.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 4355,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Frostbite",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 180.9,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 180.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 180.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 216.9,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 216.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 216.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 328.3,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 578.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 78.30000000000001,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 250.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 426.6,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 426.6,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 426.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 496.1,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 496.1,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 496.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 797.4,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 797.4,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 797.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 1683.3,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 1683.3,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 1683.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 2332.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 2332.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 2332.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 4672.8,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 4672.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 4672.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1448.1,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 1448.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 1448.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 4038.4,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 4038.4,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 4038.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 3510.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 3510.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 3510.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 4380.1,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 4380.1,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 4380.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 3469.6,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 3469.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 3469.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 7413.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 7413.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 7413.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 180.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 180.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 180.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 190.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 190.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 190.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 197.6,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 197.6,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 197.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 370.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 370.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 370.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 3965.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 3965.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Frostbite)                                SOLVED",
                            "minval": 3965.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 2321,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Gopher",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 2368.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 2368.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 2368.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 1288.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 1288.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 1288.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 8520.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 11799.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 5241.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 3279.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 4373.0,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 4373.0,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 4373.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 8190.4,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 8190.4,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 8190.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 8777.4,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 8777.4,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 8777.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 14840.8,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 14840.8,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 14840.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 15718.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 15718.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 15718.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 20051.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 20051.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 20051.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 15253.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 15253.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 15253.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 105148.4,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 105148.4,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 105148.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 32487.2,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 32487.2,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 32487.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 34858.8,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 34858.8,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 34858.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 56218.2,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 56218.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 56218.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 104368.2,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 104368.2,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 104368.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 8442.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 8442.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 8442.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 10022.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 10022.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 10022.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 17106.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 17106.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 17106.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 582.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 582.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 582.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 33641.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 33641.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gopher)                                   SOLVED",
                            "minval": 33641.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 2672,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Atari 2600 Gravitar",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 429.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 429.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 429.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 387.7,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 387.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 387.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 306.7,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 529.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 83.69999999999999,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 223.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 538.4,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 538.4,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 538.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 298.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 298.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 298.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 473.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 473.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 473.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 297.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 297.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 297.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 412.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 412.0,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 412.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 588.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 588.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 588.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 167.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 167.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 167.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 200.5,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 200.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 200.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 269.5,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 269.5,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 269.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 548.5,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 548.5,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 548.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 483.5,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 483.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 483.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 238.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 238.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 238.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 269.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 269.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 269.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 303.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 303.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 303.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 320.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 320.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 320.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 805.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 805.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 805.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 440.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 440.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Gravitar)                                 not solved",
                            "minval": 440.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 25763,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 HERO",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 7295.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 7295.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 7295.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 6459.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 6459.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 6459.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 19950.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 20108.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 19792.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 158.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 8963.4,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 8963.4,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 8963.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 14992.9,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 14992.9,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 14992.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 20437.8,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 20437.8,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 20437.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 15207.9,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 15207.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 15207.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 20130.2,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 20130.2,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 20130.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 20818.2,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 20818.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 20818.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 14892.5,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 14892.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 14892.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 15459.2,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 15459.2,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 15459.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 20889.9,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 20889.9,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 20889.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 23037.7,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 23037.7,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 23037.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 14225.2,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 14225.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 14225.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 21036.5,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 21036.5,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 21036.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 28765.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 28765.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 28765.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 28889.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 28889.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 28889.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 32464.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 32464.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 32464.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 38874.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 38874.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 HERO)                                     SOLVED",
                            "minval": 38874.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 0.9,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Ice Hockey",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": -3.2,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": -3.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -3.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": -9.5,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": -9.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -9.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": -1.6,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 0.3999999999999999,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -3.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 2.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": -1.7,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": -1.7,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -1.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -1.9,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": -1.9,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -1.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -1.6,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": -1.6,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -1.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": -2.7,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": -2.7,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -2.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": -1.3,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": -1.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -1.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 0.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 0.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": 0.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -2.5,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": -2.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -2.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 0.5,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 0.5,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": 0.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": -0.2,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": -0.2,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -0.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 1.3,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 1.3,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": 1.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": -4.1,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": -4.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -4.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": -0.4,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": -0.4,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -0.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -4.7,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -4.7,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -4.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -2.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -2.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -2.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -1.7,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -1.7,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -1.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": -4.1,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": -4.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -4.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": -3.5,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": -3.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ice Hockey)                               SOLVED",
                            "minval": -3.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 406.7,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 James Bond",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 354.1,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 354.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 354.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 202.8,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 202.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 202.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 576.7,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 751.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 401.70000000000005,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 175.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 444.0,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 444.0,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 444.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 697.5,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 697.5,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 697.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 768.5,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 768.5,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 768.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 835.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 835.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 835.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 1312.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 1312.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 1312.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 1358.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 1358.0,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 1358.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 573.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 573.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 573.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 585.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 585.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 585.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 3961.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 3961.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 3961.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 5148.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 5148.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 5148.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 507.5,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 507.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 507.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 812.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 812.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 812.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 351.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 351.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 351.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 541.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 541.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 541.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 613.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 613.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 613.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 1909.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 1909.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 James Bond)                               SOLVED",
                            "minval": 1909.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 3035,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Kangaroo",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 8.8,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 8.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 8.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 1622.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 1622.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 1622.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 6740.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 9699.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 3781.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 2959.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 1431.0,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 1431.0,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 1431.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 4496.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 4496.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 4496.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 7259.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 7259.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 7259.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 10334.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 10334.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 10334.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 12992.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 12992.0,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 12992.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 14854.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 14854.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 14854.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 861.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 861.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 861.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 11204.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 11204.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 11204.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 12185.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 12185.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 12185.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 16200.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 16200.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 16200.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 13150.0,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 13150.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 13150.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 1792.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 1792.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 1792.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 94.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 94.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 94.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 106.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 106.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 106.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 125.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 125.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 125.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 11200.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 11200.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 11200.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 12853.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 12853.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kangaroo)                                 SOLVED",
                            "minval": 12853.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 2395,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Krull",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 3341.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 3341.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 3341.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 3372.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 3372.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 3372.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 3805.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 4838.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 2772.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 1033.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 6363.1,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 6363.1,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 6363.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 6206.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 6206.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 6206.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 8422.3,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 8422.3,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 8422.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 7920.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 7920.5,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 7920.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 8051.6,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 8051.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 8051.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 11451.9,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 11451.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 11451.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 6796.1,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 6796.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 6796.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 7658.6,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 7658.6,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 7658.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 6872.8,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 6872.8,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 6872.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 9728.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 9728.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 9728.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 9745.1,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 9745.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 9745.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 10374.4,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 10374.4,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 10374.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 5560.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 5560.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 5560.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 5911.4,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 5911.4,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 5911.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 8066.6,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 8066.6,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 8066.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 8647.2,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 8647.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 8647.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 9735.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 9735.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Krull)                                    SOLVED",
                            "minval": 9735.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 22736,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Kung-Fu Master",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 29151.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 29151.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 29151.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 19544.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 19544.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 19544.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 23270.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 29225.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 17315.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 5955.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 20620.0,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 20620.0,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 20620.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 20882.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 20882.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 20882.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 26059.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 26059.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 26059.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 24288.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 24288.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 24288.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 29710.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 29710.0,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 29710.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 34294.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 34294.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 34294.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 30207.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 30207.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 30207.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 37484.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 37484.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 37484.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 31676.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 31676.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 31676.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 39581.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 39581.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 39581.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 34393.0,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 34393.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 34393.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 48375.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 48375.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 48375.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 3046.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 3046.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 3046.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 28819.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 28819.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 28819.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 40835.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 40835.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 40835.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 48192.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 48192.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Kung-Fu Master)                           SOLVED",
                            "minval": 48192.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 4367,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Atari 2600 Montezuma's Revenge",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 259.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 259.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 259.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 10.7,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 10.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 10.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 0.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 0.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 84.0,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 84.0,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 84.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 0.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 0.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 47.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 47.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 47.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 0.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 0.0,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 0.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 0.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 22.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 22.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 22.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 24.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 24.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 24.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 42.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 42.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 42.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 0.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 0.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 51.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 51.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 51.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 0.0,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 0.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 0.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 0.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 41.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 41.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 41.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 53.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 53.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 53.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 67.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 67.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 67.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 0.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 0.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 0.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 0.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Montezuma's Revenge)                      not solved",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 15693,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Atari 2600 Ms. Pacman",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 1227.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 1227.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 1227.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 1692.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 1692.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 1692.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 2311.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 2836.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 1786.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 525.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 1263.0,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 1263.0,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 1263.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1092.3,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 1092.3,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 1092.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 3085.6,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 3085.6,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 3085.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 2250.6,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 2250.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 2250.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 2711.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 2711.4,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 2711.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 6283.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 6283.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 6283.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1007.8,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 1007.8,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 1007.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1241.3,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 1241.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 1241.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 1865.9,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 1865.9,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 1865.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 6518.7,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 6518.7,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 6518.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 4963.8,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 4963.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 4963.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 3327.3,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 3327.3,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 3327.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 594.4,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 594.4,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 594.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 653.7,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 653.7,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 653.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 850.7,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 850.7,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 850.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 3415.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 3415.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Ms. Pacman)                               not solved",
                            "minval": 3415.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 4076,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Name This Game",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 2247.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 2247.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 2247.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 2500.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 2500.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 2500.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 7257.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 7804.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 6710.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 547.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 9238.5,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 9238.5,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 9238.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 6738.8,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 6738.8,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 6738.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 8207.8,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 8207.8,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 8207.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 10616.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 10616.0,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 10616.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 11185.1,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 11185.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 11185.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 11971.1,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 11971.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 11971.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 8960.3,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 8960.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 8960.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 13637.9,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 13637.9,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 13637.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 10497.6,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 10497.6,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 10497.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 12270.5,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 12270.5,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 12270.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 15851.2,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 15851.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 15851.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 15572.5,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 15572.5,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 15572.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 5614.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 5614.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 5614.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 10476.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 10476.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 10476.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 12093.7,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 12093.7,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 12093.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 4503.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 4503.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 4503.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 12542.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 12542.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Name This Game)                           SOLVED",
                            "minval": 12542.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 9.3,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Pong",
                    "target_source": "https://pdfs.semanticscholar.org/340f/48901f72278f6bf78a04ee5b01df208cc508.pdf",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": -17.4,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": -17.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": -17.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": -19.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": -19.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": -19.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-12-19",
                            "papername": "Playing Atari with Deep Reinforcement Learning",
                            "value": 21,
                            "url": "https://arxiv.org/abs/1312.5602",
                            "min_date": null,
                            "maxval": 21,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 21,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN best",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN best"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 18.9,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 19.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 17.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 1.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 16.7,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 16.7,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 16.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 18.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 18.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 18.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 19.5,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 19.5,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 19.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 18.8,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 18.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 18.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 20.9,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 20.9,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 20.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 21.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 21.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 21.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 18.4,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 18.4,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 18.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 19.1,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 19.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 19.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 18.9,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 18.9,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 18.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 20.6,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 20.6,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 20.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 20.6,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 20.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 20.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 20.9,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 20.9,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 20.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 5.6,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 5.6,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 5.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 10.7,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 10.7,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 10.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 11.4,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 11.4,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 11.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 21.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 21.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 21.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 20.9,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 20.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pong)                                     SOLVED",
                            "minval": 20.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 69571,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Atari 2600 Private Eye",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 86.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 86.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 86.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 684.3,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 684.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 684.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 1788.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 7261.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": -3685.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 5473.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 2598.6,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 2598.6,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 2598.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 146.7,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 146.7,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 146.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 207.9,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 207.9,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 207.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 103.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 103.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 103.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 129.7,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 129.7,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 129.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 292.6,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 292.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 292.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -575.5,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": -575.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": -575.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1277.6,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 1277.6,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 1277.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 200.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 200.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 200.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 670.7,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 670.7,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 670.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 286.7,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 286.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 286.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 206.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 206.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 206.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 194.4,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 194.4,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 194.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 206.9,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 206.9,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 206.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 421.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 421.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 421.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 100.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 100.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 100.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 15095.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 15095.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Private Eye)                              not solved",
                            "minval": 15095.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 13455,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Q*Bert",
                    "target_source": "https://pdfs.semanticscholar.org/340f/48901f72278f6bf78a04ee5b01df208cc508.pdf",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 960.3,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 960.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 960.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 613.5,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 613.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 613.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-12-19",
                            "papername": "Playing Atari with Deep Reinforcement Learning",
                            "value": 4500,
                            "url": "https://arxiv.org/abs/1312.5602",
                            "min_date": null,
                            "maxval": 4500,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 4500,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN best",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN best"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 10596.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 13890.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 7302.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 3294.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 7089.8,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 7089.8,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 7089.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 9271.5,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 9271.5,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 9271.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 13117.3,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 13117.3,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 13117.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 14175.8,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 14175.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 14175.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 15088.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 15088.5,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 15088.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 19220.3,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 19220.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 19220.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 11020.8,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 11020.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 11020.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 14063.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 14063.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 14063.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 9944.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 9944.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 9944.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 16256.5,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 16256.5,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 16256.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 5236.8,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 5236.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 5236.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 18760.3,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 18760.3,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 18760.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 13752.3,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 13752.3,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 13752.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 15148.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 15148.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 15148.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 21307.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 21307.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 21307.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 147.5,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 147.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 147.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 23784.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 23784.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Q*Bert)                                   SOLVED",
                            "minval": 23784.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 13513,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 River Raid",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 2650.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 2650.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 2650.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 1904.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 1904.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 1904.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 8316.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 9365.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 7267.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 1049.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 5310.3,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 5310.3,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 5310.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 4748.5,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 4748.5,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 4748.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 7377.6,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 7377.6,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 7377.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 14884.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 14884.5,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 14884.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 16569.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 16569.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 16569.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 21162.6,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 21162.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 21162.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 10838.4,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 10838.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 10838.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 16496.8,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 16496.8,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 16496.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 11807.2,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 11807.2,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 11807.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 14522.3,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 14522.3,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 14522.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 12530.8,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 12530.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 12530.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 20607.6,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 20607.6,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 20607.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 6591.9,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 6591.9,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 6591.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 10001.2,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 10001.2,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 10001.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 12201.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 12201.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 12201.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 5009.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 5009.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 5009.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 17322.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 17322.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 River Raid)                               SOLVED",
                            "minval": 17322.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 7845,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Road Runner",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 89.1,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 89.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 89.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 67.7,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 67.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 67.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 18257.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 22525.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 13989.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 4268.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 43079.8,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 43079.8,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 43079.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 35215.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 35215.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 35215.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 39544.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 39544.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 39544.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 44127.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 44127.0,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 44127.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 58549.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 58549.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 58549.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 69524.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 69524.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 69524.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 43156.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 43156.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 43156.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 54630.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 54630.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 54630.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 52264.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 52264.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 52264.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 57608.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 57608.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 57608.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 47770.0,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 47770.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 47770.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 62151.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 62151.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 62151.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 31769.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 31769.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 31769.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 34216.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 34216.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 34216.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 73949.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 73949.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 73949.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 16590.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 16590.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 16590.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 55839.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 55839.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Road Runner)                              SOLVED",
                            "minval": 55839.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 11.9,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Robotank",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 12.4,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 12.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 12.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 28.7,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 28.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 28.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 51.6,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 55.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 47.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 4.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 61.8,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 61.8,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 61.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 58.7,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 58.7,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 58.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 63.9,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 63.9,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 63.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 62.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 62.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 62.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 65.1,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 65.1,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 65.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 65.3,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 65.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 65.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 24.7,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 24.7,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 24.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 59.1,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 59.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 59.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 56.2,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 56.2,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 56.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 62.6,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 62.6,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 62.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 64.3,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 64.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 64.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 27.5,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 27.5,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 27.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 2.3,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 2.3,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 2.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 2.6,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 2.6,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 2.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 32.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 32.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 32.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 11.9,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 11.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 11.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 52.3,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 52.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Robotank)                                 SOLVED",
                            "minval": 52.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 20182,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Seaquest",
                    "target_source": "https://pdfs.semanticscholar.org/340f/48901f72278f6bf78a04ee5b01df208cc508.pdf",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 675.5,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 675.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 675.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 664.8,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 664.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 664.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-12-19",
                            "papername": "Playing Atari with Deep Reinforcement Learning",
                            "value": 1740,
                            "url": "https://arxiv.org/abs/1312.5602",
                            "min_date": null,
                            "maxval": 1740,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 1740,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN best",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN best"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 5286.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 6596.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 3976.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 1310.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 10145.9,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 10145.9,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 10145.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 4216.7,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 4216.7,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 4216.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 5860.6,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 5860.6,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 5860.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 16452.7,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 16452.7,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 16452.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 37361.6,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 37361.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 37361.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 50254.2,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 50254.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 50254.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1431.2,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 1431.2,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 1431.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 14498.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 14498.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 14498.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 25463.7,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 25463.7,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 25463.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 26357.8,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 26357.8,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 26357.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 10932.3,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 10932.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 10932.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 931.6,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 931.6,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 931.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 1326.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 1326.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 1326.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 2300.2,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 2300.2,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 2300.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 2355.4,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 2355.4,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 2355.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 1390.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 1390.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 1390.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 266434.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 266434.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Seaquest)                                 SOLVED",
                            "minval": 266434.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 1652,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Space Invaders",
                    "target_source": "https://pdfs.semanticscholar.org/340f/48901f72278f6bf78a04ee5b01df208cc508.pdf",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 267.9,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 267.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 267.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 250.1,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 250.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 250.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-12-19",
                            "papername": "Playing Atari with Deep Reinforcement Learning",
                            "value": 1075,
                            "url": "https://arxiv.org/abs/1312.5602",
                            "min_date": null,
                            "maxval": 1075,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 1075,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN best",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN best"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 1976.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 2869.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 1083.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 893.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 1183.3,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 1183.3,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 1183.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1293.8,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 1293.8,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 1293.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1692.3,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 1692.3,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 1692.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 2525.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 2525.5,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 2525.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 5993.1,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 5993.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 5993.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 6427.3,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 6427.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 6427.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 2628.7,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 2628.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 2628.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 8978.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 8978.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 8978.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 2865.8,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 2865.8,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 2865.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 3912.1,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 3912.1,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 3912.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 2589.7,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 2589.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 2589.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 15311.5,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 15311.5,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 15311.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 2214.7,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 2214.7,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 2214.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 15730.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 15730.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 15730.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 23846.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 23846.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 23846.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 678.5,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 678.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 678.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 5747.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 5747.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Space Invaders)                           SOLVED",
                            "minval": 5747.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 10250,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Star Gunner",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 9.4,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 9.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 9.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 1070.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 1070.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 1070.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 57997.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 61149.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 54845.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 3152.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 14919.2,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 14919.2,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 14919.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 52970.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 52970.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 52970.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 54282.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 54282.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 54282.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 60142.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 60142.0,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 60142.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 89238.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 89238.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 89238.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 90804.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 90804.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 90804.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 58365.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 58365.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 58365.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 127073.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 127073.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 127073.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 61582.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 61582.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 61582.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 63302.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 63302.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 63302.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 589.0,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 589.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 589.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 125117.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 125117.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 125117.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 64393.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 64393.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 64393.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 138218.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 138218.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 138218.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 164766.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 164766.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 164766.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 1470.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 1470.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 1470.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 49095.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 49095.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Star Gunner)                              SOLVED",
                            "minval": 49095.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": -8.9,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Tennis",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 0.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 0.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": -0.1,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": -0.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": -0.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": -2.5,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": -1.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": -3.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 1.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": -0.7,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": -0.7,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": -0.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 11.1,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 11.1,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": 11.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 12.2,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 12.2,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": 12.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": -22.8,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": -22.8,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": -22.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 4.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 4.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": 4.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 5.1,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 5.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": 5.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -13.2,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": -13.2,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": -13.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -7.8,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": -7.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": -7.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": -5.3,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": -5.3,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": -5.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 0.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 0.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 12.1,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 12.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": 12.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 0.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 0.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -10.2,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -10.2,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": -10.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -6.4,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -6.4,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": -6.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -6.3,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -6.3,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": -6.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": -4.5,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": -4.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": -4.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 23.1,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 23.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tennis)                                   SOLVED",
                            "minval": 23.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 5925,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Time Pilot",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 24.9,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 24.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 24.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 3741.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 3741.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 3741.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 5947.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 7547.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 4347.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 1600.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 8267.8,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 8267.8,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 8267.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 4786.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 4786.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 4786.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 4870.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 4870.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 4870.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 6601.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 6601.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 6601.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 8339.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 8339.0,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 8339.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 11666.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 11666.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 11666.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 4871.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 4871.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 4871.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 6608.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 6608.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 6608.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 5963.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 5963.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 5963.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 9197.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 9197.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 9197.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 4870.0,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 4870.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 4870.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 7553.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 7553.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 7553.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 5825.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 5825.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 5825.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 12679.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 12679.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 12679.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 27202.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 27202.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 27202.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 4970.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 4970.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 4970.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 8329.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 8329.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Time Pilot)                               SOLVED",
                            "minval": 8329.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 167.6,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Tutankham",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 98.2,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 98.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 98.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 114.3,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 114.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 114.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 186.7,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 227.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 145.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 41.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 118.5,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 118.5,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 118.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 45.6,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 45.6,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 45.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 68.1,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 68.1,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 68.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 48.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 48.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 48.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 211.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 211.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 211.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 218.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 218.4,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 218.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 92.2,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 92.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 92.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 108.6,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 108.6,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 108.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 56.9,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 56.9,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 56.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 204.6,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 204.6,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 204.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 183.9,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 183.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 183.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 245.9,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 245.9,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 245.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 26.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 26.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 26.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 144.2,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 144.2,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 144.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 156.3,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 156.3,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 156.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 130.3,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 130.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 130.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 280.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 280.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Tutankham)                                SOLVED",
                            "minval": 280.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 9082,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Up and Down",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 2449.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 2449.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 2449.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 3533.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 3533.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 3533.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 8456.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 11618.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 5294.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 3162.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 8747.7,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 8747.7,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 8747.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 8038.5,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 8038.5,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 8038.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 9989.9,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 9989.9,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 9989.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 22972.2,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 22972.2,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 22972.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 24759.2,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 24759.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 24759.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 44939.6,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 44939.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 44939.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 19086.9,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 19086.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 19086.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 22681.3,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 22681.3,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 22681.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 12157.4,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 12157.4,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 12157.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 16154.1,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 16154.1,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 16154.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 22474.4,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 22474.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 22474.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 33879.1,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 33879.1,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 33879.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 54525.4,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 54525.4,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 54525.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 74705.7,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 74705.7,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 74705.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 105728.7,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 105728.7,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 105728.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 67974.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 67974.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 67974.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 15612.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 15612.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Up and Down)                              SOLVED",
                            "minval": 15612.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 1188,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Venture",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 0.6,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 0.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 0.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 66.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 66.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 66.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 380.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 618.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 142.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 238.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 523.4,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 523.4,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 523.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 136.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 136.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 136.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 163.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 163.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 163.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 98.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 98.0,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 98.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 200.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 200.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 200.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 497.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 497.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 497.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 21.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 21.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 21.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 29.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 29.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 29.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 54.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 54.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 54.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 94.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 94.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 94.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 1172.0,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 1172.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 1172.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 48.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 48.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 48.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 19.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 19.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 19.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 23.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 23.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 23.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 25.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 25.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 25.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 760.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 760.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 760.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 1520.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 1520.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Venture)                                  SOLVED",
                            "minval": 1520.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 17298,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Video Pinball",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 19761.0,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 19761.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 19761.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 16871.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 16871.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 16871.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 42684.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 58971.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 26397.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 16287.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 112093.4,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 112093.4,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 112093.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 154414.1,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 154414.1,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 154414.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 196760.4,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 196760.4,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 196760.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 98209.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 98209.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 98209.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 110976.2,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 110976.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 110976.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 309941.9,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 309941.9,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 309941.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 367823.7,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 367823.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 367823.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 447408.6,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 447408.6,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 447408.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 282007.3,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 282007.3,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 282007.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 295972.8,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 295972.8,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 295972.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 56287.0,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 56287.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 56287.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 479197.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 479197.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 479197.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 185852.6,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 185852.6,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 185852.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 331628.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 331628.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 331628.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 470310.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 470310.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 470310.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 22834.8,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 22834.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 22834.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 949604.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 949604.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Video Pinball)                            SOLVED",
                            "minval": 949604.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 4757,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Wizard of Wor",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 36.9,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 36.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 36.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 1981.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 1981.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 1981.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 3393.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 5412.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 1374.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 2019.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 10431.0,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 10431.0,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 10431.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1609.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 1609.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 1609.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 2704.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 2704.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 2704.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 7054.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 7054.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 7054.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 7492.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 7492.0,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 7492.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 7855.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 7855.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 7855.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 6201.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 6201.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 6201.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 10471.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 10471.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 10471.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 4802.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 4802.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 4802.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 5727.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 5727.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 5727.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 483.0,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 483.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 483.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 12352.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 12352.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 12352.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 5278.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 5278.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 5278.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 17244.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 17244.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 17244.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 18082.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 18082.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 18082.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 3480.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 3480.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 3480.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 9300.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 9300.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Wizard of Wor)                            SOLVED",
                            "minval": 9300.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 9173,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2352",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Zaxxon",
                    "target_source": "https://www.semanticscholar.org/paper/Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu/340f48901f72278f6bf78a04ee5b01df208cc508",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-14",
                            "papername": "Investigating Contingency Awareness Using Atari 2600 Games",
                            "value": 21.4,
                            "url": "https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/view/5162",
                            "min_date": null,
                            "maxval": 21.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 21.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SARSA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SARSA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-19",
                            "papername": "The Arcade Learning Environment: An Evaluation Platform for General Agents",
                            "value": 3365.0,
                            "url": "https://arxiv.org/abs/1207.4708v1",
                            "min_date": null,
                            "maxval": 3365.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 3365.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Best linear",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best linear"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-26",
                            "papername": "Human-level control through deep reinforcement learning",
                            "value": 4977.0,
                            "url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "min_date": null,
                            "maxval": 6212.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 3742.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 1235.0,
                            "name": "Nature DQN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nature DQN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-15",
                            "papername": "Massively Parallel Methods for Deep Reinforcement Learning",
                            "value": 6159.4,
                            "url": "https://arxiv.org/abs/1507.04296",
                            "min_date": "2015-07-15",
                            "maxval": 6159.4,
                            "max_date": "2015-07-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 6159.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gorila",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gorila"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 4412.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 4412.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 4412.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 5363.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 5363.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 5363.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 10163.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 10163.0,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 10163.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 10164.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 10164.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 10164.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 12944.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 12944.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 12944.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 8593.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 8593.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 8593.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 11320.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 11320.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 11320.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 9474.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 9474.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 9474.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 10469.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 10469.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 10469.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 14402.0,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 14402.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 14402.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 13886.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 13886.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 13886.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 2659.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 2659.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 2659.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 23519.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 23519.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 23519.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 24622.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 24622.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 24622.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 6380.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 6380.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 6380.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 10513.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 10513.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Zaxxon)                                   SOLVED",
                            "minval": 10513.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 2665.5,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2347",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Phoenix",
                    "target_source": "https://arxiv.org/abs/1509.06461",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 7484.8,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 7484.8,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED",
                            "minval": 7484.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 8485.2,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 8485.2,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED",
                            "minval": 8485.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 12252.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 12252.5,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED",
                            "minval": 12252.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 20410.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 20410.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED",
                            "minval": 20410.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 23092.2,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 23092.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED",
                            "minval": 23092.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 12366.5,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 12366.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED",
                            "minval": 12366.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 63597.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 63597.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED",
                            "minval": 63597.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 16903.6,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 16903.6,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED",
                            "minval": 16903.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 18992.7,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 18992.7,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED",
                            "minval": 18992.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 6202.5,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 6202.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED",
                            "minval": 6202.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 70324.3,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 70324.3,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED",
                            "minval": 70324.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 28181.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 28181.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED",
                            "minval": 28181.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 52894.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 52894.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED",
                            "minval": 52894.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 74786.7,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 74786.7,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED",
                            "minval": 74786.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 4041.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 4041.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED",
                            "minval": 4041.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 17490.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 17490.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Phoenix)                                  SOLVED",
                            "minval": 17490.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 22736.3,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2347",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Atari 2600 Pit Fall",
                    "target_source": "https://arxiv.org/abs/1509.06461",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -135.7,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -135.7,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pit Fall)                                 not solved",
                            "minval": -135.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -123.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -123.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pit Fall)                                 not solved",
                            "minval": -123.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -78.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -78.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pit Fall)                                 not solved",
                            "minval": -78.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 0.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 0.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pit Fall)                                 not solved",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 13455.0,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2347",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Atari 2600 Skiing",
                    "target_source": "https://arxiv.org/abs/1509.06461",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -13062.3,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": -13062.3,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Skiing)                                   not solved",
                            "minval": -13062.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -12142.1,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": -12142.1,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Skiing)                                   not solved",
                            "minval": -12142.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": -11928.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": -11928.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Skiing)                                   not solved",
                            "minval": -11928.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": -9021.8,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": -9021.8,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Skiing)                                   not solved",
                            "minval": -9021.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": -8857.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": -8857.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Skiing)                                   not solved",
                            "minval": -8857.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -18955.8,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": -18955.8,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Skiing)                                   not solved",
                            "minval": -18955.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -11490.4,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": -11490.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Skiing)                                   not solved",
                            "minval": -11490.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": -10169.1,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": -10169.1,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Skiing)                                   not solved",
                            "minval": -10169.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": -9996.9,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": -9996.9,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Skiing)                                   not solved",
                            "minval": -9996.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": -13585.1,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": -13585.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Skiing)                                   not solved",
                            "minval": -13585.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": -19949.9,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": -19949.9,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Skiing)                                   not solved",
                            "minval": -19949.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -14863.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -14863.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Skiing)                                   not solved",
                            "minval": -14863.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -13700.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -13700.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Skiing)                                   not solved",
                            "minval": -13700.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -10911.1,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -10911.1,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Skiing)                                   not solved",
                            "minval": -10911.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": -15442.5,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": -15442.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Skiing)                                   not solved",
                            "minval": -15442.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": -13901.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": -13901.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Skiing)                                   not solved",
                            "minval": -13901.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 17118.0,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2347",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Atari 2600 Solaris",
                    "target_source": "https://arxiv.org/abs/1509.06461",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1295.4,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 1295.4,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved",
                            "minval": 1295.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 3482.8,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 3482.8,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved",
                            "minval": 3482.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 1768.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 1768.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved",
                            "minval": 1768.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 2250.8,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 2250.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved",
                            "minval": 2250.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 3067.8,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 3067.8,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved",
                            "minval": 3067.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 280.6,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 280.6,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved",
                            "minval": 280.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 810.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 810.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved",
                            "minval": 810.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 2272.8,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 2272.8,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved",
                            "minval": 2272.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 4309.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 4309.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved",
                            "minval": 4309.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 4544.8,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 4544.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved",
                            "minval": 4544.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 133.4,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 133.4,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved",
                            "minval": 133.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 1884.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 1884.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved",
                            "minval": 1884.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 1936.4,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 1936.4,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved",
                            "minval": 1936.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 1956.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 1956.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved",
                            "minval": 1956.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 2090.0,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 2090.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved",
                            "minval": 2090.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 8342.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 8342.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Solaris)                                  not solved",
                            "minval": 8342.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 5650.0,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2347",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Yars Revenge",
                    "target_source": "https://arxiv.org/abs/1509.06461",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 4577.5,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 4577.5,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED",
                            "minval": 4577.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 18098.9,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 18098.9,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED",
                            "minval": 18098.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 11712.6,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 11712.6,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED",
                            "minval": 11712.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 25976.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 25976.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED",
                            "minval": 25976.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 49622.1,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 49622.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED",
                            "minval": 49622.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 6270.6,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 6270.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED",
                            "minval": 6270.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 58145.9,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 58145.9,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED",
                            "minval": 58145.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 4687.4,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 4687.4,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED",
                            "minval": 4687.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 11357.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 11357.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED",
                            "minval": 11357.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 21409.5,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 21409.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED",
                            "minval": 21409.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 69618.1,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 69618.1,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED",
                            "minval": 69618.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 5615.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 5615.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED",
                            "minval": 5615.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 7157.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 7157.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED",
                            "minval": 7157.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 7270.8,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 7270.8,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED",
                            "minval": 7270.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-10",
                            "papername": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning",
                            "value": 16401.7,
                            "url": "https://arxiv.org/abs/1703.03864v1",
                            "min_date": null,
                            "maxval": 16401.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED",
                            "minval": 16401.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ES FF (1 hour) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ES FF (1 hour) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 35050.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 35050.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Yars Revenge)                             SOLVED",
                            "minval": 35050.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 18688.9,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2347",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Defender",
                    "target_source": "https://arxiv.org/abs/1509.06461",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 15917.5,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 15917.5,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED",
                            "minval": 15917.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 23633.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": 23633.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED",
                            "minval": 23633.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 33996.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 33996.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED",
                            "minval": 33996.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 35338.5,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": 35338.5,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED",
                            "minval": 35338.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 42214.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 42214.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED",
                            "minval": 42214.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 27510.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 27510.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED",
                            "minval": 27510.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 34415.0,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": 34415.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED",
                            "minval": 34415.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 23666.5,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 23666.5,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED",
                            "minval": 23666.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 31286.5,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 31286.5,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED",
                            "minval": 31286.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": 11099.0,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": 11099.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED",
                            "minval": 11099.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 41324.5,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 41324.5,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED",
                            "minval": 41324.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 36242.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 36242.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED",
                            "minval": 36242.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 56533.0,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 56533.0,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED",
                            "minval": 56533.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": 233021.5,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": 233021.5,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED",
                            "minval": 233021.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 47092.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 47092.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Defender)                                 SOLVED",
                            "minval": 47092.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 6463.7,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2140",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Atari 2600 Pitfall!",
                    "target_source": "https://arxiv.org/abs/1509.06461",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -286.1,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": -286.1,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Pitfall!)                                 not solved",
                            "minval": -286.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -113.2,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": -113.2,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Pitfall!)                                 not solved",
                            "minval": -113.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": -46.9,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": -46.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pitfall!)                                 not solved",
                            "minval": -46.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": -29.9,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": -29.9,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Pitfall!)                                 not solved",
                            "minval": -29.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 0.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 0.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pitfall!)                                 not solved",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -243.6,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": -243.6,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Pitfall!)                                 not solved",
                            "minval": -243.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -186.7,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": -186.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pitfall!)                                 not solved",
                            "minval": -186.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": -427.0,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": -427.0,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pitfall!)                                 not solved",
                            "minval": -427.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": -356.5,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": -356.5,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pitfall!)                                 not solved",
                            "minval": -356.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": -2.6,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": -2.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pitfall!)                                 not solved",
                            "minval": -2.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 0.0,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 0.0,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Pitfall!)                                 not solved",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 0.0,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 0.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Pitfall!)                                 not solved",
                            "minval": 0.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 6.5,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/scrapers/atari.py#L2347",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Atari 2600 Surround",
                    "target_source": "https://arxiv.org/abs/1509.06461",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/scrapers/atari.py",
                    "parent": "Problem(Simple video games)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -6.0,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": -6.0,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED",
                            "minval": -6.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-22",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -5.6,
                            "url": "https://arxiv.org/abs/1509.06461v1",
                            "min_date": "2015-02-26",
                            "maxval": -5.6,
                            "max_date": null,
                            "src_name": "Human-level control through deep reinforcement learning",
                            "algorithm_src_url": "https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf",
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED",
                            "minval": -5.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DQN noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DQN noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": -2.9,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": "2015-12-08",
                            "maxval": -2.9,
                            "max_date": null,
                            "src_name": "Deep Reinforcement Learning with Double Q-learning",
                            "algorithm_src_url": "https://arxiv.org/abs/1509.06461v3",
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED",
                            "minval": -2.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 4.0,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 4.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED",
                            "minval": 4.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-20",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 4.4,
                            "url": "https://arxiv.org/abs/1511.06581v1",
                            "min_date": null,
                            "maxval": 4.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED",
                            "minval": 4.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": -0.2,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": "2015-11-18",
                            "maxval": -0.2,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED",
                            "minval": -0.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-08",
                            "papername": "Deep Reinforcement Learning with Double Q-learning",
                            "value": 1.9,
                            "url": "https://arxiv.org/abs/1509.06461v3",
                            "min_date": null,
                            "maxval": 1.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED",
                            "minval": 1.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN (tuned) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN (tuned) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 5.9,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 5.9,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED",
                            "minval": 5.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-06",
                            "papername": "Prioritized Experience Replay",
                            "value": 8.9,
                            "url": "https://arxiv.org/abs/1511.05952",
                            "min_date": "2015-11-18",
                            "maxval": 8.9,
                            "max_date": "2016-02-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED",
                            "minval": 8.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-02-24",
                            "papername": "Learning functions across many orders of magnitudes",
                            "value": -2.5,
                            "url": "https://arxiv.org/abs/1602.07714v1",
                            "min_date": null,
                            "maxval": -2.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED",
                            "minval": -2.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DDQN+Pop-Art noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DDQN+Pop-Art noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-05",
                            "papername": "Dueling Network Architectures for Deep Reinforcement Learning",
                            "value": 1.2,
                            "url": "https://arxiv.org/abs/1511.06581v3",
                            "min_date": "2015-11-18",
                            "maxval": 1.2,
                            "max_date": null,
                            "src_name": "Prioritized Experience Replay",
                            "algorithm_src_url": "https://arxiv.org/abs/1511.05952",
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED",
                            "minval": 1.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Prior+Duel noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Prior+Duel noop"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -9.7,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -9.7,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED",
                            "minval": -9.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -9.6,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -9.6,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED",
                            "minval": -9.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C FF (1 day) hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C FF (1 day) hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-10",
                            "papername": "Asynchronous Methods for Deep Reinforcement Learning",
                            "value": -8.3,
                            "url": "https://arxiv.org/abs/1602.01783",
                            "min_date": "2016-02-04",
                            "maxval": -8.3,
                            "max_date": "2016-06-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED",
                            "minval": -8.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "A3C LSTM hs",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "A3C LSTM hs"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-07-21",
                            "papername": "A Distributional Perspective on Reinforcement Learning",
                            "value": 6.8,
                            "url": "https://arxiv.org/abs/1707.06887v1",
                            "min_date": null,
                            "maxval": 6.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Atari 2600 Surround)                                 SOLVED",
                            "minval": 6.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "C51 noop",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C51 noop"
                        }
                    ]
                }
            ],
            "subproblems": "<map object at 0x7f5a5cab5b00>",
            "url": null,
            "solved": false,
            "attributes": [
                "world-modelling",
                "realtime-games",
                "agi"
            ]
        },
        {
            "name": "Detection of Instrumentals musical tracks",
            "superproblems": "<map object at 0x7f5a5cab5dd8>",
            "metrics": [
                {
                    "notes": "",
                    "target": 99,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/acoustics.py#L59",
                    "target_label": null,
                    "url": null,
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "Precision of Instrumentals detection reached when tested on SATIN (Bayle et al. 2017)",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/acoustics.py",
                    "parent": "Problem(Detection of Instrumentals musical tracks)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-10-17",
                            "papername": "A hierarchical approach for speech-instrumental-song classification | SpringerLink",
                            "value": 17.3,
                            "url": "https://link.springer.com/article/10.1186/2193-1801-2-526",
                            "min_date": null,
                            "maxval": 17.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Precision of Instrumentals detection reached when tested on SATIN (Bayle et al. 2017))not solved",
                            "minval": 17.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Ghosal et al.",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Ghosal et al."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-09-30",
                            "papername": "On Evaluation Validity in Music Autotagging",
                            "value": 12.5,
                            "url": "https://arxiv.org/abs/1410.0001",
                            "min_date": null,
                            "maxval": 12.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Precision of Instrumentals detection reached when tested on SATIN (Bayle et al. 2017))not solved",
                            "minval": 12.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SVMBFF",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SVMBFF"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-09-30",
                            "papername": "On Evaluation Validity in Music Autotagging",
                            "value": 29.8,
                            "url": "https://arxiv.org/abs/1410.0001",
                            "min_date": null,
                            "maxval": 29.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Precision of Instrumentals detection reached when tested on SATIN (Bayle et al. 2017))not solved",
                            "minval": 29.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "VQMM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "VQMM"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-06-23",
                            "papername": "Revisiting Autotagging Toward Faultless Instrumental Playlists Generation",
                            "value": 82.5,
                            "url": "https://arxiv.org/abs/1706.07613",
                            "min_date": null,
                            "maxval": 82.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Precision of Instrumentals detection reached when tested on SATIN (Bayle et al. 2017))not solved",
                            "minval": 82.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Bayle et al.",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Bayle et al."
                        }
                    ]
                }
            ],
            "subproblems": "<map object at 0x7f5a5cb95ba8>",
            "url": null,
            "solved": false,
            "attributes": [
                "language",
                "agi"
            ]
        },
        {
            "name": "Play an arbitrary abstract game, first learning the rules",
            "superproblems": "<map object at 0x7f5a5cb95550>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a5cb95240>",
            "url": null,
            "solved": false,
            "attributes": [
                "agi",
                "abstract-games"
            ]
        },
        {
            "notes": "This is tagged agi because most humans are able to learn ethics from their surrounding community",
            "name": "Cooperative inverse reinforcement learning of objective functions",
            "superproblems": "<map object at 0x7f5a5cb95f28>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a5cb95630>",
            "url": "https://arxiv.org/abs/1606.03137",
            "solved": false,
            "attributes": [
                "safety",
                "agi"
            ]
        },
        {
            "name": "Given an arbitrary technical problem, solve it as well as a typical professional in that field",
            "superproblems": "<map object at 0x7f5a5cb95c50>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a5cb95828>",
            "url": null,
            "solved": false,
            "attributes": [
                "language",
                "world-modelling"
            ]
        },
        {
            "name": "Know how to prevent an autonomous AI agent from reproducing itself an unbounded number of times",
            "superproblems": "<map object at 0x7f5a5cb959e8>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a5cb95898>",
            "url": null,
            "solved": false,
            "attributes": [
                "safety"
            ]
        },
        {
            "name": "Parse and implement complex conditional expressions",
            "superproblems": "<map object at 0x7f5a5cb95b70>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a5cb952e8>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "name": "Know how to build general AI agents that will behave as expected",
            "superproblems": "<map object at 0x7f5a5cb95278>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a5cb95b00>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "name": "Conduct arbitrary sustained, probing conversation",
            "superproblems": "<map object at 0x7f5a5cb95940>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a5cb95cf8>",
            "url": null,
            "solved": false,
            "attributes": [
                "agi",
                "language",
                "world-modelling",
                "communication"
            ]
        },
        {
            "name": "Be able to generate complex scene e.g. a baboon receiving their degree at convocatoin.",
            "superproblems": "<map object at 0x7f5a5cb952b0>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a5cb95ef0>",
            "url": null,
            "solved": false,
            "attributes": [
                "vision",
                "world-modelling",
                "agi"
            ]
        },
        {
            "name": "Games that require language comprehension",
            "superproblems": "<map object at 0x7f5a5cb95400>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a5cb95c18>",
            "url": null,
            "solved": false,
            "attributes": [
                "agi",
                "languge"
            ]
        },
        {
            "name": "Given examples of proofs, find correct proofs of simple mathematical theorems",
            "superproblems": "<map object at 0x7f5a5cb95a90>",
            "metrics": [
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/stem.py#L39",
                    "target_label": null,
                    "url": "https://arxiv.org/abs/1703.00426",
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "HolStep",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Given examples of proofs, find correct proofs of simple mathematical theorems)",
                    "measures": []
                }
            ],
            "subproblems": "<map object at 0x7f5a5cb954a8>",
            "url": null,
            "solved": false,
            "attributes": [
                "agi",
                "math"
            ]
        },
        {
            "name": "Drawing pictures",
            "superproblems": "<map object at 0x7f5a5cb95d30>",
            "metrics": [
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/generative.py#L31",
                    "target_label": null,
                    "url": null,
                    "scale": "Model Entropy",
                    "solved": false,
                    "axis_label": "Model entropy (bits per pixel)",
                    "name": "Generative models of CIFAR-10 images",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/generative.py",
                    "parent": "Problem(Drawing pictures)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-10-30",
                            "papername": "NICE: Non-linear Independent Components Estimation",
                            "value": 4.48,
                            "url": "https://arxiv.org/abs/1410.8516",
                            "min_date": "2014-10-30",
                            "maxval": 4.48,
                            "max_date": "2015-04-10",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Generative models of CIFAR-10 images)                ?",
                            "minval": 4.48,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "NICE",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "NICE"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-16",
                            "papername": "DRAW: A Recurrent Neural Network For Image Generation",
                            "value": 4.13,
                            "url": "https://arxiv.org/abs/1502.04623",
                            "min_date": "2015-02-16",
                            "maxval": 4.13,
                            "max_date": "2015-05-20",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Generative models of CIFAR-10 images)                ?",
                            "minval": 4.13,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DRAW",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DRAW"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-05-27",
                            "papername": "Density estimation using Real NVP",
                            "value": 3.49,
                            "url": "https://arxiv.org/abs/1605.08803",
                            "min_date": "2016-05-27",
                            "maxval": 3.49,
                            "max_date": "2017-02-27",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Generative models of CIFAR-10 images)                ?",
                            "minval": 3.49,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Real NVP",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Real NVP"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-05-27",
                            "papername": "Density estimation using Real NVP",
                            "value": 3.0,
                            "url": "https://arxiv.org/abs/1605.08803",
                            "min_date": "2016-05-27",
                            "maxval": 3.0,
                            "max_date": "2017-02-27",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Generative models of CIFAR-10 images)                ?",
                            "minval": 3.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "PixelRNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "PixelRNN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-06-15",
                            "papername": "Improved Variational Inference with Inverse Autoregressive Flow",
                            "value": 3.11,
                            "url": "https://papers.nips.cc/paper/6581-improved-variational-inference-with-inverse-autoregressive-flow",
                            "min_date": null,
                            "maxval": 3.11,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Generative models of CIFAR-10 images)                ?",
                            "minval": 3.11,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "VAE with IAF",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "VAE with IAF"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-11-04",
                            "papername": "Forum | OpenReview",
                            "value": 2.92,
                            "url": "https://openreview.net/forum?id=BJrFC6ceg",
                            "min_date": null,
                            "maxval": 2.92,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Generative models of CIFAR-10 images)                ?",
                            "minval": 2.92,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "PixelCNN++",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "https://github.com/openai/pixel-cnn",
                            "label": "PixelCNN++"
                        }
                    ]
                }
            ],
            "subproblems": "<map object at 0x7f5a5cb959b0>",
            "url": null,
            "solved": false,
            "attributes": [
                "vision",
                "agi"
            ]
        },
        {
            "notes": "Humans can usually tell when they don't know something. Present ML classifiers do not have this ability.",
            "name": "Correctly identify when an answer to a classification problem is uncertain",
            "superproblems": "<map object at 0x7f5a5cb95e48>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a5cb95f98>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "notes": "\nWe know that humans have significant resistance to adversarial examples.  Although methods like camouflage sometimes\nwork to fool us into thinking one thing is another, those\n",
            "name": "Resistance to adversarial examples",
            "superproblems": "<map object at 0x7f5a5cb95160>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a5cb95b38>",
            "url": "https://arxiv.org/abs/1312.6199",
            "solved": false,
            "attributes": [
                "safety",
                "agi",
                "security"
            ]
        },
        {
            "name": "Building systems that solve a wide range of diverse problems, rather than just specific ones",
            "superproblems": "<map object at 0x7f5a5cb95a58>",
            "metrics": [
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-33-847f9831eedb>#L2",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Solve all other solved problems in this document, with a single system",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Building systems that solve a wide range of diverse problems, rather than just specific ones)",
                    "measures": []
                }
            ],
            "subproblems": "<map object at 0x7f5a5cb95e80>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "notes": "\nSeveral standards are available for avoiding classification biases.\n\nThey include holding false-positive / false adverse prediction rates constant across protected categories (which roughly maps \nto \"equal opportunity\"), holding both false-positive and false-negative rates equal (\"demographic parity\"), and ensuring\nthat the fraction of each protected group that receives a given prediction is constant across all groups \n(roughly equivalent to \"affirmative action\").",
            "name": "Train ML classifiers in a manner that corrects for the impact of omitted-variable bias on certain groups",
            "superproblems": "<map object at 0x7f5a5cb95978>",
            "metrics": [
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-39-8599bdd9b61a>#L18",
                    "target_label": null,
                    "url": "https://arxiv.org/abs/1610.02413",
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Adjust prediction models to have constant false-positive rates",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Train ML classifiers in a manner that corrects for the impact of omitted-variable bias on certain groups)",
                    "measures": []
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-39-8599bdd9b61a>#L19",
                    "target_label": null,
                    "url": "http://www.jmlr.org/proceedings/papers/v28/zemel13.pdf",
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Adjust prediction models tos have constant false-positive and -negative rates",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Train ML classifiers in a manner that corrects for the impact of omitted-variable bias on certain groups)",
                    "measures": []
                }
            ],
            "subproblems": "<map object at 0x7f5a5cb95390>",
            "url": null,
            "solved": true,
            "attributes": []
        },
        {
            "name": "Writing software from specifications",
            "superproblems": "<map object at 0x7f5a5cb950f0>",
            "metrics": [
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/stem.py#L22",
                    "target_label": null,
                    "url": "https://github.com/deepmind/card2code",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "Card2Code",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Writing software from specifications)",
                    "measures": []
                }
            ],
            "subproblems": "<map object at 0x7f5a5cb956a0>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "notes": "\nLegally institutionalised protected categories represent only the most extreme and socially recognised\nforms of biased decisionmaking. Attentive human decision makers are sometime capable of recognising\nand avoiding many more subtle biases. This problem tracks AI systems' ability to do likewise.\n",
            "name": "Build systems which can recognise and avoid biases decision making",
            "superproblems": "<map object at 0x7f5a5cb95c88>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a5cb0d1d0>",
            "url": null,
            "solved": false,
            "attributes": [
                "safety"
            ]
        },
        {
            "name": "Turing test for casual conversation",
            "superproblems": "<map object at 0x7f5a5cb0d748>",
            "metrics": [
                {
                    "notes": "\nThe Loebner Prize is an actual enactment of the Turing Test. Importantly, judges are instructed to engage in casual, natural\nconversation rather than deliberately probing to determine if participants are \"intelligent\" (Brian Christian, The Most Human Human).\nThis makes it considerably easier than a probing Turing Test, and it is close to being solved. \n\nHowever these aren't scores for the full Loebner Turing Test; since 2014 the Loebner prize has scored its entrants by\ngiving them a corpus of conversation and scoring their answers. We use these numbers because they remove variability\nin the behaviour of the judges. Unfortunately, these questions change from year to year (and have to, since \nentrants will test with last year's data).\n",
                    "target": 100,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L86",
                    "target_label": "Completely plausible answers",
                    "url": "http://www.aisb.org.uk/events/loebner-prize",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage of answers rated plausible\n(each year is a different test)",
                    "name": "The Loebner Prize scored selection answers",
                    "target_source": null,
                    "graphed": true,
                    "changeable": true,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Turing test for casual conversation)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-11-15",
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize",
                            "value": 76.7,
                            "url": "http://www.aisb.org.uk/events/loebner-prize#contest2014",
                            "min_date": null,
                            "maxval": 76.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved",
                            "minval": 76.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "The Professor 2014",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "The Professor 2014"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-11-15",
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize",
                            "value": 80.83,
                            "url": "http://www.aisb.org.uk/events/loebner-prize#contest2014",
                            "min_date": null,
                            "maxval": 80.83,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved",
                            "minval": 80.83,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Tutor 2014",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Tutor 2014"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-11-15",
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize",
                            "value": 81.67,
                            "url": "http://www.aisb.org.uk/events/loebner-prize#contest2014",
                            "min_date": null,
                            "maxval": 81.67,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved",
                            "minval": 81.67,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Uberbot 2014",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Uberbot 2014"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-11-15",
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize",
                            "value": 88.3,
                            "url": "http://www.aisb.org.uk/events/loebner-prize#contest2014",
                            "min_date": null,
                            "maxval": 88.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved",
                            "minval": 88.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Izar 2014",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Izar 2014"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-11-15",
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize",
                            "value": 88.3,
                            "url": "http://www.aisb.org.uk/events/loebner-prize#contest2014",
                            "min_date": null,
                            "maxval": 88.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved",
                            "minval": 88.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Misuku 2014",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Misuku 2014"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-11-15",
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize",
                            "value": 89.2,
                            "url": "http://www.aisb.org.uk/events/loebner-prize#contest2014",
                            "min_date": null,
                            "maxval": 89.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved",
                            "minval": 89.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Rose 2014",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Rose 2014"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-19",
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize",
                            "value": 75,
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results15",
                            "min_date": null,
                            "maxval": 75,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved",
                            "minval": 75,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Rose 2015",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Rose 2015"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-19",
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize",
                            "value": 76.7,
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results15",
                            "min_date": null,
                            "maxval": 76.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved",
                            "minval": 76.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Izar 2015",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Izar 2015"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-19",
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize",
                            "value": 80,
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results15",
                            "min_date": null,
                            "maxval": 80,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved",
                            "minval": 80,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Lisa 2015",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Lisa 2015"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-19",
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize",
                            "value": 83.3,
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results15",
                            "min_date": null,
                            "maxval": 83.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved",
                            "minval": 83.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Mitsuku 2015",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Mitsuku 2015"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-09-17",
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize",
                            "value": 76.7,
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results16",
                            "min_date": null,
                            "maxval": 76.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved",
                            "minval": 76.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Katie 2016",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Katie 2016"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-09-17",
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize",
                            "value": 77.5,
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results16",
                            "min_date": null,
                            "maxval": 77.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved",
                            "minval": 77.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Rose 2016",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Rose 2016"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-09-17",
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize",
                            "value": 77.5,
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results16",
                            "min_date": null,
                            "maxval": 77.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved",
                            "minval": 77.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Arckon 2016",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Arckon 2016"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-09-17",
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize",
                            "value": 78.3,
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results16",
                            "min_date": null,
                            "maxval": 78.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved",
                            "minval": 78.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Tutor 2016",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Tutor 2016"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-09-17",
                            "papername": "AISB - The Society for the Study of Artificial Intelligence and Simulation of Behaviour - Loebner Prize",
                            "value": 90,
                            "url": "http://www.aisb.org.uk/events/loebner-prize#Results16",
                            "min_date": null,
                            "maxval": 90,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(The Loebner Prize scored selection answers)          not solved",
                            "minval": 90,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Mitsuku 2016",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Mitsuku 2016"
                        }
                    ]
                }
            ],
            "subproblems": "<map object at 0x7f5a5cb0db70>",
            "url": null,
            "solved": false,
            "attributes": [
                "agi",
                "language",
                "world-modelling",
                "communication"
            ]
        },
        {
            "notes": "\nPeople who care strongly about their own privacy take many measures to obfuscate their tracks through\ntechnological society, including using fictitious names, email addresses, etc in their routine dealings with\ncorporations, installing software to block or send inacurate data to online trackers. Like many other groups,\nthese people may be subject to unfairly adverse algorithmic decisionmaking. Treating them as a protected\ngroup will be more difficult, because they are in many respects harder to identify.\n",
            "name": "Fairness in machine learning towards people with a preference for privacy",
            "superproblems": "<map object at 0x7f5a5cb0deb8>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a5cb0def0>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "name": "Learning the rules of complex strategy games from examples",
            "superproblems": "<map object at 0x7f5a5cb0d048>",
            "metrics": [
                {
                    "notes": "\n  Chess software contains hard-coded policy constraints for valid play; this metric is whether RL\n  or other agents can correctly build those policy constraints from examples or oracles",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/strategy_games.py#L74",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "learning chess",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Learning the rules of complex strategy games from examples)",
                    "measures": []
                },
                {
                    "notes": "\n  Go software contains policy constraints for valid play and evaluating the number of\n  liberties for groups. This metric is whether RL or other agents can correctly build those \n  policy constraints from examples or oracles",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/strategy_games.py#L78",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "learning go",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Learning the rules of complex strategy games from examples)",
                    "measures": []
                }
            ],
            "subproblems": "<map object at 0x7f5a5cb0d0b8>",
            "url": null,
            "solved": false,
            "attributes": [
                "agi",
                "abstract-games"
            ]
        },
        {
            "name": "Write computer programs from specifications",
            "superproblems": "<map object at 0x7f5a5cb0d4e0>",
            "metrics": [
                {
                    "notes": "",
                    "target": 100,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/stem.py#L53",
                    "target_label": "Bug-free card implementation",
                    "url": "https://github.com/deepmind/card2code",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "Card2Code MTG accuracy",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/stem.py",
                    "parent": "Problem(Write computer programs from specifications)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-03-22",
                            "papername": "Latent Predictor Networks for Code Generation",
                            "value": 4.8,
                            "url": "https://arxiv.org/abs/1603.06744v1",
                            "min_date": null,
                            "maxval": 4.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Card2Code MTG accuracy)                              not solved",
                            "minval": 4.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "LPN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "LPN"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 100,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/stem.py#L58",
                    "target_label": "Bug-free card implementation",
                    "url": "https://github.com/deepmind/card2code",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "Card2Code Hearthstone accuracy",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/stem.py",
                    "parent": "Problem(Write computer programs from specifications)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-03-22",
                            "papername": "Latent Predictor Networks for Code Generation",
                            "value": 6.1,
                            "url": "https://arxiv.org/abs/1603.06744v1",
                            "min_date": null,
                            "maxval": 6.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Card2Code Hearthstone accuracy)                      not solved",
                            "minval": 6.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "LPN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "LPN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-04-06",
                            "papername": "A Syntactic Neural Model for General-Purpose Code Generation",
                            "value": 1.5,
                            "url": "https://arxiv.org/abs/1704.01696v1",
                            "min_date": "2014-09-01",
                            "maxval": 1.5,
                            "max_date": null,
                            "src_name": "Neural Machine Translation by Jointly Learning to Align and Translate",
                            "algorithm_src_url": "https://arxiv.org/abs/1409.0473v1",
                            "metric": "Metric(Card2Code Hearthstone accuracy)                      not solved",
                            "minval": 1.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "NMT",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "NMT"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-04-06",
                            "papername": "A Syntactic Neural Model for General-Purpose Code Generation",
                            "value": 13.6,
                            "url": "https://arxiv.org/abs/1704.01696v1",
                            "min_date": "2016-01-06",
                            "maxval": 13.6,
                            "max_date": null,
                            "src_name": "Language to Logical Form with Neural Attention",
                            "algorithm_src_url": "https://arxiv.org/abs/1601.01280v1",
                            "metric": "Metric(Card2Code Hearthstone accuracy)                      not solved",
                            "minval": 13.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Seq2Tree-Unk",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Seq2Tree-Unk"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-04-06",
                            "papername": "A Syntactic Neural Model for General-Purpose Code Generation",
                            "value": 16.7,
                            "url": "https://arxiv.org/abs/1704.01696v1",
                            "min_date": null,
                            "maxval": 16.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Card2Code Hearthstone accuracy)                      not solved",
                            "minval": 16.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SNM -frontier embed",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SNM -frontier embed"
                        }
                    ]
                }
            ],
            "subproblems": "<map object at 0x7f5a5cb0db00>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "name": "Games that require inventing novel language, forms of speech, or communication",
            "superproblems": "<map object at 0x7f5a5cb0d5c0>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a5cb0dc88>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "name": "Image classification",
            "superproblems": "<map object at 0x7f5a5cb0d390>",
            "metrics": [
                {
                    "notes": "\nCorrectly label images from the Imagenet dataset. As of 2016, this includes:\n - Object localization for 1000 categories.\n - Object detection for 200 fully labeled categories.\n - Object detection from video for 30 fully labeled categories.\n - Scene classification for 365 scene categories (Joint with MIT Places team) on Places2 Database http://places2.csail.mit.edu.\n - Scene parsing for 150 stuff and discrete object categories (Joint with MIT Places team).\n",
                    "target": 0.051,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/vision.py#L32",
                    "target_label": null,
                    "url": "http://image-net.org",
                    "scale": "Error rate",
                    "solved": true,
                    "axis_label": "Error rate",
                    "name": "Imagenet Image Recognition",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/vision.py",
                    "parent": "Problem(Image classification)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2010-08-31",
                            "papername": "ImageNet Large Scale Visual Recognition Competition 2010 (ILSVRC2010)",
                            "value": 0.28191,
                            "url": "http://image-net.org/challenges/LSVRC/2010/results",
                            "min_date": null,
                            "maxval": 0.28191,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Imagenet Image Recognition)                          SOLVED",
                            "minval": 0.28191,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "NEC UIUC",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "NEC UIUC"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2011-10-26",
                            "papername": "ImageNet Large Scale Visual Recognition Competition 2011 (ILSVRC2011)",
                            "value": 0.2577,
                            "url": "http://image-net.org/challenges/LSVRC/2011/results",
                            "min_date": null,
                            "maxval": 0.2577,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Imagenet Image Recognition)                          SOLVED",
                            "minval": 0.2577,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "XRCE",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "XRCE"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-10-13",
                            "papername": "ImageNet Large Scale Visual Recognition Competition 2012 (ILSVRC2012)",
                            "value": 0.16422,
                            "url": "http://image-net.org/challenges/LSVRC/2012/results.html",
                            "min_date": null,
                            "maxval": 0.16422,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Imagenet Image Recognition)                          SOLVED",
                            "minval": 0.16422,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SuperVision",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SuperVision"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-11-14",
                            "papername": "ImageNet Large Scale Visual Recognition Competition 2013 (ILSVRC2013)",
                            "value": 0.11743,
                            "url": "http://www.image-net.org/challenges/LSVRC/2013/results.php",
                            "min_date": null,
                            "maxval": 0.11743,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Imagenet Image Recognition)                          SOLVED",
                            "minval": 0.11743,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Clarifai",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Clarifai"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-08-18",
                            "papername": "ImageNet Large Scale Visual Recognition Competition 2014 (ILSVRC2014)",
                            "value": 0.07405,
                            "url": "http://image-net.org/challenges/LSVRC/2014/index",
                            "min_date": null,
                            "maxval": 0.07405,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Imagenet Image Recognition)                          SOLVED",
                            "minval": 0.07405,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "VGG",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "VGG"
                        },
                        {
                            "notes": "",
                            "withdrawn": true,
                            "date": "2015-04-10",
                            "papername": "Deep Image: Scaling up Image Recognition",
                            "value": 0.0458,
                            "url": "https://arxiv.org/abs/1501.02876",
                            "min_date": "2015-01-13",
                            "maxval": 0.0458,
                            "max_date": "2015-07-06",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Imagenet Image Recognition)                          SOLVED",
                            "minval": 0.0458,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "withdrawn",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "withdrawn"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-10",
                            "papername": "ILSVRC2015 Results",
                            "value": 0.03567,
                            "url": "http://image-net.org/challenges/LSVRC/2015/results",
                            "min_date": null,
                            "maxval": 0.03567,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Imagenet Image Recognition)                          SOLVED",
                            "minval": 0.03567,
                            "opensource": false,
                            "algorithms": [
                                "residual-networks"
                            ],
                            "uncertainty": 0,
                            "name": "MSRA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MSRA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-09-26",
                            "papername": "ILSVRC2016",
                            "value": 0.02991,
                            "url": "http://image-net.org/challenges/LSVRC/2016/results",
                            "min_date": null,
                            "maxval": 0.02991,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Imagenet Image Recognition)                          SOLVED",
                            "minval": 0.02991,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Trimps-Soushen",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Trimps-Soushen"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/awty.py#L233",
                    "target_label": null,
                    "url": "http://jamie.shotton.org/work/data.html",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "MSRC-21 image semantic labelling (per-class)",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/awty.py",
                    "parent": "Problem(Image classification)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2008-07-01",
                            "papername": "Semantic Texton Forests for Image Categorization and Segmentation",
                            "value": 67.0,
                            "url": "http://mi.eng.cam.ac.uk/~cipolla/publications/inproceedings/2008-CVPR-semantic-texton-forests.pdf",
                            "min_date": "2008-01-01",
                            "maxval": 67.0,
                            "max_date": "2008-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?",
                            "minval": 67.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "STF",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "STF"
                        },
                        {
                            "notes": "?? / 69.6 % (per-class / per-pixel) the unaries alone (no CRF on top)",
                            "withdrawn": false,
                            "date": "2009-07-01",
                            "papername": "TextonBoost for Image Understanding",
                            "value": 57.0,
                            "url": "http://research.microsoft.com/pubs/117885/ijcv07a.pdf",
                            "min_date": "2009-01-01",
                            "maxval": 57.0,
                            "max_date": "2009-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?",
                            "minval": 57.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "TextonBoost",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "TextonBoost"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2010-07-01",
                            "papername": "Auto-Context and Its Application to High-Level Vision Tasks and 3D Brain Image Segmentation",
                            "value": 69.0,
                            "url": "http://pages.ucsd.edu/~ztu/publication/pami_autocontext.pdf",
                            "min_date": "2010-01-01",
                            "maxval": 69.0,
                            "max_date": "2010-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?",
                            "minval": 69.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Auto-Context",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Auto-Context"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2010-07-01",
                            "papername": "Graph Cut based Inference with Co-occurrence Statistics",
                            "value": 77.0,
                            "url": "http://research.microsoft.com/en-us/um/people/pkohli/papers/lrkt_eccv2010.pdf",
                            "min_date": "2010-01-01",
                            "maxval": 77.0,
                            "max_date": "2010-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?",
                            "minval": 77.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "HCRF+CO",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "HCRF+CO"
                        },
                        {
                            "notes": "Several variants are examined, no single method attains the overall best results, i.e. both best per-class and per-pixel averages simultaneously. Indicated result corresponds to the method that we best on the average (per-class + per-pixel / 2). Experiment data available.",
                            "withdrawn": false,
                            "date": "2011-07-01",
                            "papername": "Are Spatial and Global Constraints Really Necessary for Segmentation?",
                            "value": 77.0,
                            "url": "http://infoscience.epfl.ch/record/169178/files/lucchi_ICCV11.pdf",
                            "min_date": "2011-01-01",
                            "maxval": 77.0,
                            "max_date": "2011-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?",
                            "minval": 77.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Are Spatial and Global Constraints Really Necessary for Segmentation?",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Are Spatial and Global Co..."
                        },
                        {
                            "notes": "Strong unary used provides 76.6% / 84.0%",
                            "withdrawn": false,
                            "date": "2011-12-17",
                            "papername": "Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials",
                            "value": 78.0,
                            "url": "http://graphics.stanford.edu/projects/densecrf/densecrf.pdf",
                            "min_date": null,
                            "maxval": 78.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?",
                            "minval": 78.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "FC CRF",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "FC CRF"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-06-16",
                            "papername": "Describing the Scene as a Whole: Joint Object Detection, Scene Classification and Semantic Segmentation",
                            "value": 79.0,
                            "url": "http://ttic.uchicago.edu/~rurtasun/publications/yao_et_al_cvpr12.pdf",
                            "min_date": null,
                            "maxval": 79.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?",
                            "minval": 79.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Describing the Scene as a Whole: Joint Object Detection, Scene Classification and Semantic Segmentation",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Describing the Scene as a..."
                        },
                        {
                            "notes": "per-class % / per-pixel %",
                            "withdrawn": false,
                            "date": "2012-07-01",
                            "papername": "Harmony Potentials - Fusing Local and Global Scale for Semantic Image Segmentation",
                            "value": 80.0,
                            "url": "http://link.springer.com/article/10.1007%2Fs11263-011-0449-8",
                            "min_date": "2012-01-01",
                            "maxval": 80.0,
                            "max_date": "2012-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?",
                            "minval": 80.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Harmony Potentials",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Harmony Potentials"
                        },
                        {
                            "notes": "8% / 63.3% raw PatchMatchGraph accuracy, 72.8% / 79.0% when using Boosted CRF. Code available.",
                            "withdrawn": false,
                            "date": "2012-10-07",
                            "papername": "PatchMatchGraph: Building a Graph of Dense Patch Correspondences for Label Transfer",
                            "value": 72.8,
                            "url": "http://users.cecs.anu.edu.au/~sgould/papers/eccv12-patchGraph.pdf",
                            "min_date": null,
                            "maxval": 72.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?",
                            "minval": 72.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "PMG",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "PMG"
                        },
                        {
                            "notes": "70 % / 73 % when using only local features (not considering global features)",
                            "withdrawn": false,
                            "date": "2012-10-07",
                            "papername": "Structured Image Segmentation using Kernelized Features",
                            "value": 76.0,
                            "url": "https://infoscience.epfl.ch/record/180188/files/top.pdf",
                            "min_date": null,
                            "maxval": 76.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?",
                            "minval": 76.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Kernelized SSVM/CRF",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Kernelized SSVM/CRF"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-10-29",
                            "papername": "Morphological Proximity Priors: Spatial Relationships for Semantic Segmentation",
                            "value": 78.2,
                            "url": "http://mediatum.ub.tum.de/doc/1175516/1175516.pdf",
                            "min_date": null,
                            "maxval": 78.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?",
                            "minval": 78.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "MPP",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MPP"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-07-01",
                            "papername": "Large-Scale Semantic Co-Labeling of Image Sets",
                            "value": 80.9,
                            "url": "http://ai2-s2-pdfs.s3.amazonaws.com/daba/eb9185990f65f807c95ff4d09057c2bf1cf0.pdf",
                            "min_date": "2014-01-01",
                            "maxval": 80.9,
                            "max_date": "2014-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-class))        ?",
                            "minval": 80.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Large FC CRF",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Large FC CRF"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/awty.py#L246",
                    "target_label": null,
                    "url": "http://jamie.shotton.org/work/data.html",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "MSRC-21 image semantic labelling (per-pixel)",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/awty.py",
                    "parent": "Problem(Image classification)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2008-07-01",
                            "papername": "Semantic Texton Forests for Image Categorization and Segmentation",
                            "value": 72.0,
                            "url": "http://mi.eng.cam.ac.uk/~cipolla/publications/inproceedings/2008-CVPR-semantic-texton-forests.pdf",
                            "min_date": "2008-01-01",
                            "maxval": 72.0,
                            "max_date": "2008-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?",
                            "minval": 72.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "STF",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "STF"
                        },
                        {
                            "notes": "?? / 69.6 % (per-class / per-pixel) the unaries alone (no CRF on top)",
                            "withdrawn": false,
                            "date": "2009-07-01",
                            "papername": "TextonBoost for Image Understanding",
                            "value": 72.0,
                            "url": "http://research.microsoft.com/pubs/117885/ijcv07a.pdf",
                            "min_date": "2009-01-01",
                            "maxval": 72.0,
                            "max_date": "2009-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?",
                            "minval": 72.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "TextonBoost",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "TextonBoost"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2010-07-01",
                            "papername": "Auto-Context and Its Application to High-Level Vision Tasks and 3D Brain Image Segmentation",
                            "value": 78.0,
                            "url": "http://pages.ucsd.edu/~ztu/publication/pami_autocontext.pdf",
                            "min_date": "2010-01-01",
                            "maxval": 78.0,
                            "max_date": "2010-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?",
                            "minval": 78.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Auto-Context",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Auto-Context"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2010-07-01",
                            "papername": "Graph Cut based Inference with Co-occurrence Statistics",
                            "value": 87.0,
                            "url": "http://research.microsoft.com/en-us/um/people/pkohli/papers/lrkt_eccv2010.pdf",
                            "min_date": "2010-01-01",
                            "maxval": 87.0,
                            "max_date": "2010-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?",
                            "minval": 87.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "HCRF+CO",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "HCRF+CO"
                        },
                        {
                            "notes": "Several variants are examined, no single method attains the overall best results, i.e. both best per-class and per-pixel averages simultaneously. Indicated result corresponds to the method that we best on the average (per-class + per-pixel / 2). Experiment data available.",
                            "withdrawn": false,
                            "date": "2011-07-01",
                            "papername": "Are Spatial and Global Constraints Really Necessary for Segmentation?",
                            "value": 85.0,
                            "url": "http://infoscience.epfl.ch/record/169178/files/lucchi_ICCV11.pdf",
                            "min_date": "2011-01-01",
                            "maxval": 85.0,
                            "max_date": "2011-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?",
                            "minval": 85.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Are Spatial and Global Constraints Really Necessary for Segmentation?",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Are Spatial and Global Co..."
                        },
                        {
                            "notes": "Strong unary used provides 76.6% / 84.0%",
                            "withdrawn": false,
                            "date": "2011-12-17",
                            "papername": "Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials",
                            "value": 86.0,
                            "url": "http://graphics.stanford.edu/projects/densecrf/densecrf.pdf",
                            "min_date": null,
                            "maxval": 86.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?",
                            "minval": 86.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "FC CRF",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "FC CRF"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-06-16",
                            "papername": "Describing the Scene as a Whole: Joint Object Detection, Scene Classification and Semantic Segmentation",
                            "value": 86.0,
                            "url": "http://ttic.uchicago.edu/~rurtasun/publications/yao_et_al_cvpr12.pdf",
                            "min_date": null,
                            "maxval": 86.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?",
                            "minval": 86.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Describing the Scene as a Whole: Joint Object Detection, Scene Classification and Semantic Segmentation",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Describing the Scene as a..."
                        },
                        {
                            "notes": "per-class % / per-pixel %",
                            "withdrawn": false,
                            "date": "2012-07-01",
                            "papername": "Harmony Potentials - Fusing Local and Global Scale for Semantic Image Segmentation",
                            "value": 83.0,
                            "url": "http://link.springer.com/article/10.1007%2Fs11263-011-0449-8",
                            "min_date": "2012-01-01",
                            "maxval": 83.0,
                            "max_date": "2012-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?",
                            "minval": 83.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Harmony Potentials",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Harmony Potentials"
                        },
                        {
                            "notes": "8% / 63.3% raw PatchMatchGraph accuracy, 72.8% / 79.0% when using Boosted CRF. Code available.",
                            "withdrawn": false,
                            "date": "2012-10-07",
                            "papername": "PatchMatchGraph: Building a Graph of Dense Patch Correspondences for Label Transfer",
                            "value": 79.0,
                            "url": "http://users.cecs.anu.edu.au/~sgould/papers/eccv12-patchGraph.pdf",
                            "min_date": null,
                            "maxval": 79.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?",
                            "minval": 79.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "PatchMatchGraph",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "PatchMatchGraph"
                        },
                        {
                            "notes": "70 % / 73 % when using only local features (not considering global features)",
                            "withdrawn": false,
                            "date": "2012-10-07",
                            "papername": "Structured Image Segmentation using Kernelized Features",
                            "value": 82.0,
                            "url": "https://infoscience.epfl.ch/record/180188/files/top.pdf",
                            "min_date": null,
                            "maxval": 82.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?",
                            "minval": 82.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Kernelized SSVM/CRF",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Kernelized SSVM/CRF"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-10-29",
                            "papername": "Morphological Proximity Priors: Spatial Relationships for Semantic Segmentation",
                            "value": 85.0,
                            "url": "http://mediatum.ub.tum.de/doc/1175516/1175516.pdf",
                            "min_date": null,
                            "maxval": 85.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?",
                            "minval": 85.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "MPP",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MPP"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-07-01",
                            "papername": "Large-Scale Semantic Co-Labeling of Image Sets",
                            "value": 86.8,
                            "url": "http://ai2-s2-pdfs.s3.amazonaws.com/daba/eb9185990f65f807c95ff4d09057c2bf1cf0.pdf",
                            "min_date": "2014-01-01",
                            "maxval": 86.8,
                            "max_date": "2014-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MSRC-21 image semantic labelling (per-pixel))        ?",
                            "minval": 86.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Large FC CRF",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Large FC CRF"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/awty.py#L114",
                    "target_label": null,
                    "url": "http://https://www.cs.toronto.edu/~kriz/cifar.html",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "CIFAR-100 Image Recognition",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/awty.py",
                    "parent": "Problem(Image classification)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-06-16",
                            "papername": "Beyond Spatial Pyramids: Receptive Field Learning for Pooled Image Features",
                            "value": 54.23,
                            "url": "http://www.eecs.berkeley.edu/~jiayq/assets/pdf/cvpr12_pooling.pdf",
                            "min_date": null,
                            "maxval": 54.23,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 54.23,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Receptive Field Learning",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Receptive Field Learning"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-01-16",
                            "papername": "Stochastic Pooling for Regularization of Deep Convolutional Neural Networks",
                            "value": 57.49,
                            "url": "https://arxiv.org/abs/1301.3557",
                            "min_date": null,
                            "maxval": 57.49,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 57.49,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Stochastic Pooling",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Stochastic Pooling"
                        },
                        {
                            "notes": "Uses convolution. Does not use dataset agumentation.",
                            "withdrawn": false,
                            "date": "2013-06-16",
                            "papername": "Maxout Networks",
                            "value": 61.43,
                            "url": "http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf",
                            "min_date": null,
                            "maxval": 61.43,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 61.43,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Maxout Networks",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Maxout Networks"
                        },
                        {
                            "notes": "No data augmentation.",
                            "withdrawn": false,
                            "date": "2013-07-01",
                            "papername": "Smooth Pooling Regions",
                            "value": 56.29,
                            "url": "http://www.d2.mpi-inf.mpg.de/content/learning-smooth-pooling-regions-visual-recognition",
                            "min_date": "2013-01-01",
                            "maxval": 56.29,
                            "max_date": "2013-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 56.29,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Smooth Pooling Regions",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Smooth Pooling Regions"
                        },
                        {
                            "notes": "The baseline Convnet + max pooling + dropout reaches 62.80% (without any tree prior).",
                            "withdrawn": false,
                            "date": "2013-07-01",
                            "papername": "Discriminative Transfer Learning with Tree-based Priors",
                            "value": 63.15,
                            "url": "http://www.cs.toronto.edu/~nitish/treebasedpriors.pdf",
                            "min_date": "2013-01-01",
                            "maxval": 63.15,
                            "max_date": "2013-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 63.15,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Tree Priors",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Tree Priors"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-04-14",
                            "papername": "Improving Deep Neural Networks with Probabilistic Maxout Units",
                            "value": 61.86,
                            "url": "http://openreview.net/document/28d9c3ab-fe88-4836-b898-403d207a037c#28d9c3ab-fe88-4836-b898-403d207a037c",
                            "min_date": null,
                            "maxval": 61.86,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 61.86,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DNN+Probabilistic Maxout",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DNN+Probabilistic Maxout"
                        },
                        {
                            "notes": "NIN + Dropout The code for NIN available at https://github.com/mavenlin/cuda-convnet",
                            "withdrawn": false,
                            "date": "2014-04-14",
                            "papername": "Network in Network",
                            "value": 64.32,
                            "url": "http://openreview.net/document/9b05a3bb-3a5e-49cb-91f7-0f482af65aea#9b05a3bb-3a5e-49cb-91f7-0f482af65aea",
                            "min_date": null,
                            "maxval": 64.32,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 64.32,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "NiN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "NiN"
                        },
                        {
                            "notes": "3-layers + multi-dict. 7 with 3-layers only. 3 with 1-layers only.",
                            "withdrawn": false,
                            "date": "2014-06-21",
                            "papername": "Stable and Efficient Representation Learning with Nonnegativity Constraints ",
                            "value": 60.8,
                            "url": "http://jmlr.org/proceedings/papers/v32/line14.pdf",
                            "min_date": null,
                            "maxval": 60.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 60.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Stable and Efficient Representation Learning with Nonnegativity Constraints ",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Stable and Efficient Repr..."
                        },
                        {
                            "notes": "Single model, without data augmentation.",
                            "withdrawn": false,
                            "date": "2014-07-01",
                            "papername": "Deeply-Supervised Nets",
                            "value": 65.43,
                            "url": "http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/",
                            "min_date": "2014-01-01",
                            "maxval": 65.43,
                            "max_date": "2014-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 65.43,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DSN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DSN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-09-22",
                            "papername": "Spatially-sparse convolutional neural networks",
                            "value": 75.7,
                            "url": "https://arxiv.org/abs/1409.6070",
                            "min_date": null,
                            "maxval": 75.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 75.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "SSCNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SSCNN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-12-08",
                            "papername": "Deep Networks with Internal Selective Attention through Feedback Connections",
                            "value": 66.22,
                            "url": "http://papers.nips.cc/paper/5276-deep-networks-with-internal-selective-attention-through-feedback-connections.pdf",
                            "min_date": null,
                            "maxval": 66.22,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 66.22,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Deep Networks with Internal Selective Attention through Feedback Connections",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep Networks with Intern..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-15",
                            "papername": "Striving for Simplicity: The All Convolutional Net",
                            "value": 66.29,
                            "url": "https://arxiv.org/abs/1412.6806",
                            "min_date": "2014-12-21",
                            "maxval": 66.29,
                            "max_date": "2015-04-13",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 66.29,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "ACN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ACN"
                        },
                        {
                            "notes": "Uses a piecewise linear activation function. 69.17% accuracy with data augmentation and 65.6% accuracy without data augmentation.",
                            "withdrawn": false,
                            "date": "2015-02-19",
                            "papername": "Learning Activation Functions to Improve Deep Neural Networks",
                            "value": 69.17,
                            "url": "https://arxiv.org/abs/1412.6830",
                            "min_date": "2014-12-21",
                            "maxval": 69.17,
                            "max_date": "2015-04-21",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 69.17,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "NiN+APL",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "NiN+APL"
                        },
                        {
                            "notes": "Uses 12 passes at test time. Reaches 68.55% when using a single pass at test time. Uses data augmentation during training.",
                            "withdrawn": false,
                            "date": "2015-02-28",
                            "papername": "Fractional Max-Pooling",
                            "value": 73.61,
                            "url": "https://arxiv.org/abs/1412.6071",
                            "min_date": "2014-12-18",
                            "maxval": 73.61,
                            "max_date": "2015-05-12",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 73.61,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Fractional MP",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Fractional MP"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-05-02",
                            "papername": "Scalable Bayesian Optimization Using Deep Neural Networks",
                            "value": 72.6,
                            "url": "https://arxiv.org/abs/1502.05700",
                            "min_date": "2015-02-19",
                            "maxval": 72.6,
                            "max_date": "2015-07-13",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 72.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Tuned CNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Tuned CNN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-06-08",
                            "papername": "Recurrent Convolutional Neural Network for Object Recognition",
                            "value": 68.25,
                            "url": "http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_004.pdf",
                            "min_date": null,
                            "maxval": 68.25,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 68.25,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "RCNN-96",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RCNN-96"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-01",
                            "papername": "Deep Representation Learning with Target Coding",
                            "value": 64.77,
                            "url": "http://personal.ie.cuhk.edu.hk/~ccloy/files/aaai_2015_target_coding.pdf",
                            "min_date": "2015-01-01",
                            "maxval": 64.77,
                            "max_date": "2015-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 64.77,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Deep Representation Learning with Target Coding",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep Representation Learn..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-01",
                            "papername": "HD-CNN: Hierarchical Deep Convolutional Neural Network for Large Scale Visual Recognition",
                            "value": 67.38,
                            "url": "https://sites.google.com/site/homepagezhichengyan/home/hdcnn",
                            "min_date": "2015-01-01",
                            "maxval": 67.38,
                            "max_date": "2015-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 67.38,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "HD-CNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "HD-CNN"
                        },
                        {
                            "notes": "With data augmentation, 65.82% without. Based on NiN architecture.",
                            "withdrawn": false,
                            "date": "2015-07-01",
                            "papername": "Multi-Loss Regularized Deep Neural Network",
                            "value": 68.53,
                            "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7258343",
                            "min_date": "2015-01-01",
                            "maxval": 68.53,
                            "max_date": "2015-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 68.53,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "MLR DNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MLR DNN"
                        },
                        {
                            "notes": "feature extraction part of convnet is trained on imagenet (external training data), classification part is trained on cifar-100",
                            "withdrawn": false,
                            "date": "2015-07-12",
                            "papername": "Deep Convolutional Neural Networks as Generic Feature Extractors",
                            "value": 67.68,
                            "url": "http://www.isip.uni-luebeck.de/fileadmin/uploads/tx_wapublications/hertel_ijcnn_2015.pdf",
                            "min_date": null,
                            "maxval": 67.68,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 67.68,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DCNN+GFE",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DCNN+GFE"
                        },
                        {
                            "notes": "Using Randomized Leaky ReLU",
                            "withdrawn": false,
                            "date": "2015-08-16",
                            "papername": "Empirical Evaluation of Rectified Activations in Convolution Network",
                            "value": 59.75,
                            "url": "https://arxiv.org/abs/1505.00853",
                            "min_date": "2015-05-05",
                            "maxval": 59.75,
                            "max_date": "2015-11-27",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 59.75,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "RReLU",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RReLU"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-17",
                            "papername": "On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units",
                            "value": 70.8,
                            "url": "https://arxiv.org/abs/1508.00330",
                            "min_date": "2015-08-03",
                            "maxval": 71.0,
                            "max_date": "2015-11-01",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 70.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.2,
                            "name": "MIM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MIM"
                        },
                        {
                            "notes": "Single model without data augmentation",
                            "withdrawn": false,
                            "date": "2015-10-05",
                            "papername": "Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree",
                            "value": 67.63,
                            "url": "https://arxiv.org/abs/1509.08985",
                            "min_date": "2015-09-30",
                            "maxval": 67.63,
                            "max_date": "2015-10-10",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 67.63,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Tree+Max-Avg pooling",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Tree+Max-Avg pooling"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-10-11",
                            "papername": "Stacked What-Where Auto-encoders",
                            "value": 69.12,
                            "url": "https://arxiv.org/abs/1506.02351",
                            "min_date": "2015-06-08",
                            "maxval": 69.12,
                            "max_date": "2016-02-14",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 69.12,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "SWWAE",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SWWAE"
                        },
                        {
                            "notes": "(k=5 maxout pieces in each maxout unit).",
                            "withdrawn": false,
                            "date": "2015-11-09",
                            "papername": "Batch-normalized Maxout Network in Network",
                            "value": 71.14,
                            "url": "https://arxiv.org/abs/1511.02583",
                            "min_date": null,
                            "maxval": 71.14,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 71.14,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "BNM NiN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "BNM NiN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-18",
                            "papername": "Competitive Multi-scale Convolution",
                            "value": 72.44,
                            "url": "https://arxiv.org/abs/1511.05635",
                            "min_date": null,
                            "maxval": 72.44,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 72.44,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "CMsC",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CMsC"
                        },
                        {
                            "notes": "Best result selected on test set. 67.61% average over multiple trained models.",
                            "withdrawn": false,
                            "date": "2015-12-07",
                            "papername": "Training Very Deep Networks",
                            "value": 67.76,
                            "url": "http://people.idsia.ch/~rupesh/very_deep_learning/",
                            "min_date": null,
                            "maxval": 67.76,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 67.76,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "VDN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "VDN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-07",
                            "papername": "Spectral Representations for Convolutional Neural Networks",
                            "value": 68.4,
                            "url": "http://papers.nips.cc/paper/5649-spectral-representations-for-convolutional-neural-networks.pdf",
                            "min_date": null,
                            "maxval": 68.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 68.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Spectral Representations for Convolutional Neural Networks",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Spectral Representations ..."
                        },
                        {
                            "notes": "Using RMSProp optimizer",
                            "withdrawn": false,
                            "date": "2016-01-04",
                            "papername": "All you need is a good init",
                            "value": 72.34,
                            "url": "https://arxiv.org/abs/1511.06422",
                            "min_date": "2015-11-19",
                            "maxval": 72.34,
                            "max_date": "2016-02-19",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 72.34,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Fitnet4-LSUV",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Fitnet4-LSUV"
                        },
                        {
                            "notes": "Without data augmentation.",
                            "withdrawn": false,
                            "date": "2016-01-07",
                            "papername": "Fast and Accurate Deep Network Learning by Exponential Linear Units",
                            "value": 75.72,
                            "url": "https://arxiv.org/abs/1511.07289",
                            "min_date": "2015-11-23",
                            "maxval": 75.72,
                            "max_date": "2016-02-22",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 75.72,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Exponential Linear Units",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Exponential Linear Units"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-05-15",
                            "papername": "Universum Prescription: Regularization using Unlabeled Data",
                            "value": 67.16,
                            "url": "https://arxiv.org/abs/1511.03719",
                            "min_date": "2015-11-11",
                            "maxval": 67.16,
                            "max_date": "2016-11-18",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 67.16,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Universum Prescription",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Universum Prescription"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-05-20",
                            "papername": "Identity Mappings in Deep Residual Networks",
                            "value": 77.28999999999999,
                            "url": "https://arxiv.org/abs/1603.05027",
                            "min_date": "2016-03-16",
                            "maxval": 77.50999999999999,
                            "max_date": "2016-07-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 77.07,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.22,
                            "name": "ResNet-1001",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ResNet-1001"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-06-06",
                            "papername": "Deep Convolutional Decision Jungle for Image Classification",
                            "value": 69.0,
                            "url": "https://arxiv.org/abs/1706.02003",
                            "min_date": null,
                            "maxval": 69.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-100 Image Recognition)                         ?",
                            "minval": 69.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "NiN+Superclass+CDJ",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "NiN+Superclass+CDJ"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 94,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/awty.py#L165",
                    "target_label": null,
                    "url": "http://https://www.cs.toronto.edu/~kriz/cifar.html",
                    "scale": "Percentage correct",
                    "solved": true,
                    "axis_label": "Percentage correct",
                    "name": "CIFAR-10 Image Recognition",
                    "target_source": "http://karpathy.github.io/2011/04/27/manually-classifying-cifar10/",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/awty.py",
                    "parent": "Problem(Image classification)",
                    "measures": [
                        {
                            "notes": "6% obtained using K-means over whitened patches, with triangle encoding and 4000 features (clusters).",
                            "withdrawn": false,
                            "date": "2011-07-01",
                            "papername": "An Analysis of Single-Layer Networks in Unsupervised Feature Learning ",
                            "value": 79.6,
                            "url": "http://www.stanford.edu/~acoates/papers/coatesleeng_aistats_2011.pdf",
                            "min_date": "2011-01-01",
                            "maxval": 79.6,
                            "max_date": "2011-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 79.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "An Analysis of Single-Layer Networks in Unsupervised Feature Learning ",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "An Analysis of Single-Lay..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2011-07-01",
                            "papername": "Object Recognition with Hierarchical Kernel Descriptors",
                            "value": 80.0,
                            "url": "http://research.cs.washington.edu/istc/lfb/paper/cvpr11.pdf",
                            "min_date": "2011-01-01",
                            "maxval": 80.0,
                            "max_date": "2011-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 80.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Hierarchical Kernel Descriptors",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Hierarchical Kernel Descr..."
                        },
                        {
                            "notes": "Supplemental material, Technical Report",
                            "withdrawn": false,
                            "date": "2012-06-16",
                            "papername": "Multi-Column Deep Neural Networks for Image Classification ",
                            "value": 88.79,
                            "url": "http://www.idsia.ch/~ciresan/data/cvpr2012.pdf",
                            "min_date": null,
                            "maxval": 88.79,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 88.79,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "MCDNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MCDNN"
                        },
                        {
                            "notes": "K= 4,000",
                            "withdrawn": false,
                            "date": "2012-06-26",
                            "papername": "Learning Invariant Representations with Local Transformations",
                            "value": 82.2,
                            "url": "http://icml.cc/2012/papers/659.pdf",
                            "min_date": null,
                            "maxval": 82.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 82.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Local Transformations",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Local Transformations"
                        },
                        {
                            "notes": "So called \"dropout\" method.",
                            "withdrawn": false,
                            "date": "2012-07-03",
                            "papername": "Improving neural networks by preventing co-adaptation of feature detectors",
                            "value": 84.4,
                            "url": "https://arxiv.org/abs/1207.0580",
                            "min_date": null,
                            "maxval": 84.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 84.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Improving neural networks by preventing co-adaptation of feature detectors",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Improving neural networks..."
                        },
                        {
                            "notes": "Code size 1600.",
                            "withdrawn": false,
                            "date": "2012-12-03",
                            "papername": "Learning with Recursive Perceptual Representations",
                            "value": 79.7,
                            "url": "http://papers.nips.cc/paper/4747-learning-with-recursive-perceptual-representations",
                            "min_date": null,
                            "maxval": 79.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 79.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Learning with Recursive Perceptual Representations",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Learning with Recursive P..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-12-03",
                            "papername": "Discriminative Learning of Sum-Product Networks",
                            "value": 83.96,
                            "url": "http://papers.nips.cc/paper/4516-discriminative-learning-of-sum-product-networks",
                            "min_date": null,
                            "maxval": 83.96,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 83.96,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Discriminative Learning of Sum-Product Networks",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Discriminative Learning o..."
                        },
                        {
                            "notes": "87% error on the unaugmented data.",
                            "withdrawn": false,
                            "date": "2012-12-03",
                            "papername": "ImageNet Classification with Deep Convolutional Neural Networks",
                            "value": 89.0,
                            "url": "http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks",
                            "min_date": null,
                            "maxval": 89.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 89.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DCNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DCNN"
                        },
                        {
                            "notes": "Reaches 85.02% without data augmentation. With data augmented with horizontal reflections and translations, 90.5% accuracy on test set is achieved.",
                            "withdrawn": false,
                            "date": "2012-12-03",
                            "papername": "Practical Bayesian Optimization of Machine Learning Algorithms ",
                            "value": 90.5,
                            "url": "http://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf",
                            "min_date": null,
                            "maxval": 90.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 90.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "GP EI",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "GP EI"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-01-16",
                            "papername": "Stochastic Pooling for Regularization of Deep Convolutional Neural Networks",
                            "value": 84.87,
                            "url": "https://arxiv.org/abs/1301.3557",
                            "min_date": null,
                            "maxval": 84.87,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 84.87,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Stochastic Pooling",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Stochastic Pooling"
                        },
                        {
                            "notes": "This result was obtained using both convolution and synthetic translations / horizontal reflections of the training data. Reaches 88.32% when using convolution, but without any synthetic transformations of the training data.",
                            "withdrawn": false,
                            "date": "2013-06-16",
                            "papername": "Maxout Networks",
                            "value": 90.65,
                            "url": "http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf",
                            "min_date": null,
                            "maxval": 90.65,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 90.65,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Maxout Networks",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Maxout Networks"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-06-16",
                            "papername": "Regularization of Neural Networks using DropConnect",
                            "value": 90.68,
                            "url": "http://cs.nyu.edu/~wanli/dropc/",
                            "min_date": null,
                            "maxval": 90.68,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 90.68,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DropConnect",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DropConnect"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-07-01",
                            "papername": "Learning Smooth Pooling Regions for Visual Recognition",
                            "value": 80.02,
                            "url": "http://www.d2.mpi-inf.mpg.de/content/learning-smooth-pooling-regions-visual-recognition",
                            "min_date": "2013-01-01",
                            "maxval": 80.02,
                            "max_date": "2013-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 80.02,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Smooth Pooling Regions",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Smooth Pooling Regions"
                        },
                        {
                            "notes": "65% without data augmentation. 61% when using data augmentation.",
                            "withdrawn": false,
                            "date": "2014-04-14",
                            "papername": "Improving Deep Neural Networks with Probabilistic Maxout Units",
                            "value": 90.61,
                            "url": "http://openreview.net/document/28d9c3ab-fe88-4836-b898-403d207a037c#28d9c3ab-fe88-4836-b898-403d207a037c",
                            "min_date": null,
                            "maxval": 90.61,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 90.61,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DNN+Probabilistic Maxout",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DNN+Probabilistic Maxout"
                        },
                        {
                            "notes": "The code for NIN available at https://github.com/mavenlin/cuda-convnet NIN + Dropout 89.6% NIN + Dropout + Data Augmentation 91.2%",
                            "withdrawn": false,
                            "date": "2014-04-14",
                            "papername": "Network In Network",
                            "value": 91.2,
                            "url": "http://openreview.net/document/9b05a3bb-3a5e-49cb-91f7-0f482af65aea#9b05a3bb-3a5e-49cb-91f7-0f482af65aea",
                            "min_date": null,
                            "maxval": 91.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 91.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "NiN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "NiN"
                        },
                        {
                            "notes": "No data augmentation. Multiple feature scales combined. 77.14% when using only a single scale.",
                            "withdrawn": false,
                            "date": "2014-06-21",
                            "papername": "PCANet: A Simple Deep Learning Baseline for Image Classification?",
                            "value": 78.67,
                            "url": "https://arxiv.org/abs/1404.3606",
                            "min_date": "2014-04-14",
                            "maxval": 78.67,
                            "max_date": "2014-08-28",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 78.67,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "PCANet",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "PCANet"
                        },
                        {
                            "notes": "Full data, 3-layers + multi-dict. 4 with 3-layers only. 0 with 1-layers only.",
                            "withdrawn": false,
                            "date": "2014-06-21",
                            "papername": "Stable and Efficient Representation Learning with Nonnegativity Constraints ",
                            "value": 82.9,
                            "url": "http://jmlr.org/proceedings/papers/v32/line14.pdf",
                            "min_date": null,
                            "maxval": 82.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 82.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Nonnegativity Constraints ",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nonnegativity Constraints "
                        },
                        {
                            "notes": "Single model, with data augmentation: 91.78%. Without data augmentation: 90.22%.",
                            "withdrawn": false,
                            "date": "2014-07-01",
                            "papername": "Deeply-Supervised Nets",
                            "value": 91.78,
                            "url": "http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/",
                            "min_date": "2014-01-01",
                            "maxval": 91.78,
                            "max_date": "2014-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 91.78,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DSN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DSN"
                        },
                        {
                            "notes": "No data augmentation.",
                            "withdrawn": false,
                            "date": "2014-08-28",
                            "papername": "Convolutional Kernel Networks",
                            "value": 82.18,
                            "url": "https://arxiv.org/abs/1406.3332",
                            "min_date": "2014-06-12",
                            "maxval": 82.18,
                            "max_date": "2014-11-14",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 82.18,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "CKN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CKN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-09-22",
                            "papername": "Spatially-sparse convolutional neural networks",
                            "value": 93.72,
                            "url": "https://arxiv.org/abs/1409.6070",
                            "min_date": null,
                            "maxval": 93.72,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 93.72,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "SSCNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SSCNN"
                        },
                        {
                            "notes": "Unsupervised feature learning + linear SVM",
                            "withdrawn": false,
                            "date": "2014-12-08",
                            "papername": "Discriminative Unsupervised Feature Learning with Convolutional Neural Networks",
                            "value": 82.0,
                            "url": "http://papers.nips.cc/paper/5548-discriminative-unsupervised-feature-learning-with-convolutional-neural-networks.pdf",
                            "min_date": null,
                            "maxval": 82.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 82.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Discriminative Unsupervised Feature Learning with Convolutional Neural Networks",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Discriminative Unsupervis..."
                        },
                        {
                            "notes": "No data augmentation",
                            "withdrawn": false,
                            "date": "2014-12-08",
                            "papername": "Deep Networks with Internal Selective Attention through Feedback Connections",
                            "value": 90.78,
                            "url": "http://papers.nips.cc/paper/5276-deep-networks-with-internal-selective-attention-through-feedback-connections.pdf",
                            "min_date": null,
                            "maxval": 90.78,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 90.78,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Deep Networks with Internal Selective Attention through Feedback Connections",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep Networks with Intern..."
                        },
                        {
                            "notes": "Unsupervised pre-training, with supervised fine-tuning. Uses dropout and data-augmentation.",
                            "withdrawn": false,
                            "date": "2015-02-13",
                            "papername": "An Analysis of Unsupervised Pre-training in Light of Recent Advances",
                            "value": 86.7,
                            "url": "https://arxiv.org/abs/1412.6597",
                            "min_date": "2014-12-20",
                            "maxval": 86.7,
                            "max_date": "2015-04-10",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 86.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "An Analysis of Unsupervised Pre-training in Light of Recent Advances",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "An Analysis of Unsupervis..."
                        },
                        {
                            "notes": "92% without data augmentation, 92.75% with small data augmentation, 95.59% when using agressive data augmentation and larger network.",
                            "withdrawn": false,
                            "date": "2015-02-15",
                            "papername": "Striving for Simplicity: The All Convolutional Net",
                            "value": 95.59,
                            "url": "https://arxiv.org/abs/1412.6806",
                            "min_date": "2014-12-21",
                            "maxval": 95.59,
                            "max_date": "2015-04-13",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 95.59,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "ACN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ACN"
                        },
                        {
                            "notes": "Uses an adaptive piecewise linear activation function. 92.49% accuracy with data augmentation and 90.41% accuracy without data augmentation.",
                            "withdrawn": false,
                            "date": "2015-02-19",
                            "papername": "Learning Activation Functions to Improve Deep Neural Networks",
                            "value": 92.49,
                            "url": "https://arxiv.org/abs/1412.6830",
                            "min_date": "2014-12-21",
                            "maxval": 92.49,
                            "max_date": "2015-04-21",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 92.49,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "NiN+APL",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "NiN+APL"
                        },
                        {
                            "notes": "Uses 100 passes at test time. Reaches 95.5% when using a single pass at test time, and 96.33% when using 12 passes.. Uses data augmentation during training.",
                            "withdrawn": false,
                            "date": "2015-02-28",
                            "papername": "Fractional Max-Pooling",
                            "value": 96.53,
                            "url": "https://arxiv.org/abs/1412.6071",
                            "min_date": "2014-12-18",
                            "maxval": 96.53,
                            "max_date": "2015-05-12",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 96.53,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Fractional MP",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Fractional MP"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-05-02",
                            "papername": "Scalable Bayesian Optimization Using Deep Neural Networks",
                            "value": 93.63,
                            "url": "https://arxiv.org/abs/1502.05700",
                            "min_date": "2015-02-19",
                            "maxval": 93.63,
                            "max_date": "2015-07-13",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 93.63,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Tuned CNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Tuned CNN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-05-13",
                            "papername": "APAC: Augmented PAttern Classification with Neural Networks",
                            "value": 89.67,
                            "url": "https://arxiv.org/abs/1505.03229",
                            "min_date": null,
                            "maxval": 89.67,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 89.67,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "APAC",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "APAC"
                        },
                        {
                            "notes": "No data augmentation",
                            "withdrawn": false,
                            "date": "2015-05-31",
                            "papername": "Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network",
                            "value": 75.86,
                            "url": "https://arxiv.org/abs/1503.04596",
                            "min_date": "2015-03-16",
                            "maxval": 75.86,
                            "max_date": "2015-08-15",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 75.86,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "FLSCNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "FLSCNN"
                        },
                        {
                            "notes": "Reaches 91.31% without data augmentation.",
                            "withdrawn": false,
                            "date": "2015-06-08",
                            "papername": "Recurrent Convolutional Neural Network for Object Recognition",
                            "value": 92.91,
                            "url": "http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_004.pdf",
                            "min_date": null,
                            "maxval": 92.91,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 92.91,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "RCNN-96",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RCNN-96"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-06-12",
                            "papername": "ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks",
                            "value": 87.65,
                            "url": "https://arxiv.org/abs/1505.00393",
                            "min_date": "2015-05-03",
                            "maxval": 87.65,
                            "max_date": "2015-07-23",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 87.65,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "ReNet",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ReNet"
                        },
                        {
                            "notes": "Based on the \"call convolutional\" architecture. which reaches 90.92% by itself.",
                            "withdrawn": false,
                            "date": "2015-07-01",
                            "papername": "Speeding up Automatic Hyperparameter Optimization of Deep Neural Networks by Extrapolation of Learning Curves",
                            "value": 91.19,
                            "url": "http://aad.informatik.uni-freiburg.de/papers/15-IJCAI-Extrapolation_of_Learning_Curves.pdf",
                            "min_date": "2015-01-01",
                            "maxval": 91.19,
                            "max_date": "2015-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 91.19,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "ELC",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ELC"
                        },
                        {
                            "notes": "With data augmentation, 90.45% without. Based on NiN architecture.",
                            "withdrawn": false,
                            "date": "2015-07-01",
                            "papername": "Multi-Loss Regularized Deep Neural Network",
                            "value": 91.88,
                            "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7258343",
                            "min_date": "2015-01-01",
                            "maxval": 91.88,
                            "max_date": "2015-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 91.88,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "MLR DNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MLR DNN"
                        },
                        {
                            "notes": "Code available at https://github.com/szagoruyko/cifar.torch",
                            "withdrawn": false,
                            "date": "2015-07-01",
                            "papername": "cifar.torch",
                            "value": 92.45,
                            "url": "http://torch.ch/blog/2015/07/30/cifar.html",
                            "min_date": "2015-01-01",
                            "maxval": 92.45,
                            "max_date": "2015-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 92.45,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "cifar.torch",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "cifar.torch"
                        },
                        {
                            "notes": "feature extraction part of convnet is trained on imagenet (external training data), classification part is trained on cifar-10",
                            "withdrawn": false,
                            "date": "2015-07-12",
                            "papername": "Deep Convolutional Neural Networks as Generic Feature Extractors",
                            "value": 89.14,
                            "url": "http://www.isip.uni-luebeck.de/fileadmin/uploads/tx_wapublications/hertel_ijcnn_2015.pdf",
                            "min_date": null,
                            "maxval": 89.14,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 89.14,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DCNN+GFE",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DCNN+GFE"
                        },
                        {
                            "notes": "Using Randomized Leaky ReLU",
                            "withdrawn": false,
                            "date": "2015-08-16",
                            "papername": "Empirical Evaluation of Rectified Activations in Convolution Network",
                            "value": 88.8,
                            "url": "https://arxiv.org/abs/1505.00853",
                            "min_date": "2015-05-05",
                            "maxval": 88.8,
                            "max_date": "2015-11-27",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 88.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "RReLU",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RReLU"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-17",
                            "papername": "On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units",
                            "value": 91.48,
                            "url": "https://arxiv.org/abs/1508.00330",
                            "min_date": "2015-08-03",
                            "maxval": 91.68,
                            "max_date": "2015-11-01",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 91.28,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.2,
                            "name": "MIM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MIM"
                        },
                        {
                            "notes": "Single model with data augmentation, 92.38% without.",
                            "withdrawn": false,
                            "date": "2015-10-05",
                            "papername": "Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree",
                            "value": 93.95,
                            "url": "https://arxiv.org/abs/1509.08985",
                            "min_date": "2015-09-30",
                            "maxval": 93.95,
                            "max_date": "2015-10-10",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 93.95,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Tree+Max-Avg pooling",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Tree+Max-Avg pooling"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-10-11",
                            "papername": "Stacked What-Where Auto-encoders",
                            "value": 92.23,
                            "url": "https://arxiv.org/abs/1506.02351",
                            "min_date": "2015-06-08",
                            "maxval": 92.23,
                            "max_date": "2016-02-14",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 92.23,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "SWWAE",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SWWAE"
                        },
                        {
                            "notes": "(k=5 maxout pieces in each maxout unit). Reaches 92.15% without data augmentation.",
                            "withdrawn": false,
                            "date": "2015-11-09",
                            "papername": "Batch-normalized Maxout Network in Network",
                            "value": 93.25,
                            "url": "https://arxiv.org/abs/1511.02583",
                            "min_date": null,
                            "maxval": 93.25,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 93.25,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "BNM NiN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "BNM NiN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-18",
                            "papername": "Competitive Multi-scale Convolution",
                            "value": 93.13,
                            "url": "https://arxiv.org/abs/1511.05635",
                            "min_date": null,
                            "maxval": 93.13,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 93.13,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "CMsC",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CMsC"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-07",
                            "papername": "Spectral Representations for Convolutional Neural Networks",
                            "value": 91.4,
                            "url": "http://papers.nips.cc/paper/5649-spectral-representations-for-convolutional-neural-networks.pdf",
                            "min_date": null,
                            "maxval": 91.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 91.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Spectral Representations for Convolutional Neural Networks",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Spectral Representations ..."
                        },
                        {
                            "notes": "These results were obtained without using any data-augmentation.",
                            "withdrawn": false,
                            "date": "2015-12-07",
                            "papername": "BinaryConnect: Training Deep Neural Networks with binary weights during propagations",
                            "value": 91.73,
                            "url": "http://papers.nips.cc/paper/5647-binaryconnect-training-deep-neural-networks-with-binary-weights-during-propagations.pdf",
                            "min_date": null,
                            "maxval": 91.73,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 91.73,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "BinaryConnect",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "BinaryConnect"
                        },
                        {
                            "notes": "Best result selected on test set. 92.31% average over multiple trained models.",
                            "withdrawn": false,
                            "date": "2015-12-07",
                            "papername": "Training Very Deep Networks",
                            "value": 92.4,
                            "url": "http://people.idsia.ch/~rupesh/very_deep_learning/",
                            "min_date": null,
                            "maxval": 92.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 92.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "VDN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "VDN"
                        },
                        {
                            "notes": "Best performance reached with 110 layers. Using 1202 layers leads to 92.07%, 56 layers lead to 93.03%.",
                            "withdrawn": false,
                            "date": "2015-12-10",
                            "papername": "Deep Residual Learning for Image Recognition",
                            "value": 93.57,
                            "url": "https://arxiv.org/abs/1512.03385",
                            "min_date": null,
                            "maxval": 93.57,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 93.57,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DRL",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DRL"
                        },
                        {
                            "notes": "Only mirroring and random shifts, no extreme data augmentation. Uses thin deep residual net with maxout activations.",
                            "withdrawn": false,
                            "date": "2016-01-04",
                            "papername": "All you need is a good init",
                            "value": 94.16,
                            "url": "https://arxiv.org/abs/1511.06422",
                            "min_date": "2015-11-19",
                            "maxval": 94.16,
                            "max_date": "2016-02-19",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 94.16,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Fitnet4-LSUV",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Fitnet4-LSUV"
                        },
                        {
                            "notes": "Without data augmentation.",
                            "withdrawn": false,
                            "date": "2016-01-07",
                            "papername": "Fast and Accurate Deep Network Learning by Exponential Linear Units",
                            "value": 93.45,
                            "url": "https://arxiv.org/abs/1511.07289",
                            "min_date": "2015-11-23",
                            "maxval": 93.45,
                            "max_date": "2016-02-22",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 93.45,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Exponential Linear Units",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Exponential Linear Units"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-05-15",
                            "papername": "Universum Prescription: Regularization using Unlabeled Data",
                            "value": 93.34,
                            "url": "https://arxiv.org/abs/1511.03719",
                            "min_date": "2015-11-11",
                            "maxval": 93.34,
                            "max_date": "2016-11-18",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 93.34,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Universum Prescription",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Universum Prescription"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-05-20",
                            "papername": "Identity Mappings in Deep Residual Networks",
                            "value": 95.38,
                            "url": "https://arxiv.org/abs/1603.05027",
                            "min_date": "2016-03-16",
                            "maxval": 95.58,
                            "max_date": "2016-07-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CIFAR-10 Image Recognition)                          SOLVED",
                            "minval": 95.17999999999999,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.2,
                            "name": "ResNet-1001",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ResNet-1001"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 2.0,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/awty.py#L82",
                    "target_label": null,
                    "url": "http://ufldl.stanford.edu/housenumbers/",
                    "scale": "Percentage error",
                    "solved": true,
                    "axis_label": "Percentage error",
                    "name": "Street View House Numbers (SVHN)",
                    "target_source": "http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/awty.py",
                    "parent": "Problem(Image classification)",
                    "measures": [
                        {
                            "notes": "ConvNet / MS / L4 / Padded",
                            "withdrawn": false,
                            "date": "2012-07-01",
                            "papername": "Convolutional neural networks applied to house numbers digit classification",
                            "value": 4.9,
                            "url": "http://yann.lecun.com/exdb/publis/pdf/sermanet-icpr-12.pdf",
                            "min_date": "2012-01-01",
                            "maxval": 4.9,
                            "max_date": "2012-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED",
                            "minval": 4.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Convolutional neural networks applied to house numbers digit classification",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Convolutional neural netw..."
                        },
                        {
                            "notes": "64-64-128 Stochastic Pooling",
                            "withdrawn": false,
                            "date": "2013-01-16",
                            "papername": "Stochastic Pooling for Regularization of Deep Convolutional Neural Networks",
                            "value": 2.8,
                            "url": "https://arxiv.org/abs/1301.3557",
                            "min_date": null,
                            "maxval": 2.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED",
                            "minval": 2.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Stochastic Pooling",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Stochastic Pooling"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-06-16",
                            "papername": "Regularization of Neural Networks using DropConnect",
                            "value": 1.94,
                            "url": "http://cs.nyu.edu/~wanli/dropc/",
                            "min_date": null,
                            "maxval": 1.94,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED",
                            "minval": 1.94,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Regularization of Neural Networks using DropConnect",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Regularization of Neural ..."
                        },
                        {
                            "notes": "This result was obtained using convolution but not any synthetic transformations of the training data.",
                            "withdrawn": false,
                            "date": "2013-06-16",
                            "papername": "Maxout Networks",
                            "value": 2.47,
                            "url": "http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf",
                            "min_date": null,
                            "maxval": 2.47,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED",
                            "minval": 2.47,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Maxout",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Maxout"
                        },
                        {
                            "notes": "For classification of individual digits with a single network, error rate is 2.16%. For classification of the entire digit sequence (first paper doing this): error rate of 3.97%.",
                            "withdrawn": false,
                            "date": "2014-04-14",
                            "papername": "Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks",
                            "value": 2.16,
                            "url": "http://openreview.net/document/0c571b22-f4b6-4d58-87e4-99d7de42a893#0c571b22-f4b6-4d58-87e4-99d7de42a893",
                            "min_date": null,
                            "maxval": 2.16,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED",
                            "minval": 2.16,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DCNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DCNN"
                        },
                        {
                            "notes": "NIN + Dropout The code for NIN available at https://github.com/mavenlin/cuda-convnet",
                            "withdrawn": false,
                            "date": "2014-04-14",
                            "papername": "Network in Network",
                            "value": 2.35,
                            "url": "http://openreview.net/document/9b05a3bb-3a5e-49cb-91f7-0f482af65aea#9b05a3bb-3a5e-49cb-91f7-0f482af65aea",
                            "min_date": null,
                            "maxval": 2.35,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED",
                            "minval": 2.35,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "NiN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "NiN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-07-01",
                            "papername": "Deeply-Supervised Nets",
                            "value": 1.92,
                            "url": "http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/",
                            "min_date": "2014-01-01",
                            "maxval": 1.92,
                            "max_date": "2014-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED",
                            "minval": 1.92,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DSN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DSN"
                        },
                        {
                            "notes": "No data augmentation",
                            "withdrawn": false,
                            "date": "2015-05-31",
                            "papername": "Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network",
                            "value": 3.96,
                            "url": "https://arxiv.org/abs/1503.04596",
                            "min_date": "2015-03-16",
                            "maxval": 3.96,
                            "max_date": "2015-08-15",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED",
                            "minval": 3.96,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "FLSCNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "FLSCNN"
                        },
                        {
                            "notes": "Without data augmentation",
                            "withdrawn": false,
                            "date": "2015-06-08",
                            "papername": "Recurrent Convolutional Neural Network for Object Recognition",
                            "value": 1.77,
                            "url": "http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_004.pdf",
                            "min_date": null,
                            "maxval": 1.77,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED",
                            "minval": 1.77,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "RCNN-96",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RCNN-96"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-06-12",
                            "papername": "ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks",
                            "value": 2.38,
                            "url": "https://arxiv.org/abs/1505.00393",
                            "min_date": "2015-05-03",
                            "maxval": 2.38,
                            "max_date": "2015-07-23",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED",
                            "minval": 2.38,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "ReNet",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ReNet"
                        },
                        {
                            "notes": "Based on NiN architecture.",
                            "withdrawn": false,
                            "date": "2015-07-01",
                            "papername": "Multi-Loss Regularized Deep Neural Network",
                            "value": 1.92,
                            "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7258343",
                            "min_date": "2015-01-01",
                            "maxval": 1.92,
                            "max_date": "2015-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED",
                            "minval": 1.92,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "MLR DNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MLR DNN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-17",
                            "papername": "On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units",
                            "value": 1.97,
                            "url": "https://arxiv.org/abs/1508.00330",
                            "min_date": "2015-08-03",
                            "maxval": 2.05,
                            "max_date": "2015-11-01",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED",
                            "minval": 1.89,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.08,
                            "name": "MIM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MIM"
                        },
                        {
                            "notes": "Single model without data augmentation",
                            "withdrawn": false,
                            "date": "2015-10-05",
                            "papername": "Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree",
                            "value": 1.69,
                            "url": "https://arxiv.org/abs/1509.08985",
                            "min_date": "2015-09-30",
                            "maxval": 1.69,
                            "max_date": "2015-10-10",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED",
                            "minval": 1.69,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Tree+Max-Avg pooling",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Tree+Max-Avg pooling"
                        },
                        {
                            "notes": "(k=5 maxout pieces in each maxout unit).",
                            "withdrawn": false,
                            "date": "2015-11-09",
                            "papername": "Batch-normalized Maxout Network in Network",
                            "value": 1.81,
                            "url": "https://arxiv.org/abs/1511.02583",
                            "min_date": null,
                            "maxval": 1.81,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED",
                            "minval": 1.81,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "BNM NiN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "BNM NiN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-18",
                            "papername": "Competitive Multi-scale Convolution",
                            "value": 1.76,
                            "url": "https://arxiv.org/abs/1511.05635",
                            "min_date": null,
                            "maxval": 1.76,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED",
                            "minval": 1.76,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "CMsC",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CMsC"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-07",
                            "papername": "BinaryConnect: Training Deep Neural Networks with binary weights during propagations",
                            "value": 2.15,
                            "url": "http://papers.nips.cc/paper/5647-binaryconnect-training-deep-neural-networks-with-binary-weights-during-propagations.pdf",
                            "min_date": null,
                            "maxval": 2.15,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Street View House Numbers (SVHN))                    SOLVED",
                            "minval": 2.15,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "BinaryConnect",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "BinaryConnect"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 0.2,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/awty.py#L217",
                    "target_label": null,
                    "url": "http://yann.lecun.com/exdb/mnist/",
                    "scale": "Percentage error",
                    "solved": true,
                    "axis_label": "Percentage error",
                    "name": "MNIST handwritten digit recognition",
                    "target_source": "http://people.idsia.ch/~juergen/superhumanpatternrecognition.html",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/awty.py",
                    "parent": "Problem(Image classification)",
                    "measures": [
                        {
                            "notes": "Virtual SVM, deg-9 poly, 2-pixel jittered (Preprocessing: deskewing)",
                            "withdrawn": false,
                            "date": "2002-07-01",
                            "papername": "Training Invariant Support Vector Machines",
                            "value": 0.56,
                            "url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.9924&rep=rep1&type=pdf",
                            "min_date": "2002-01-01",
                            "maxval": 0.56,
                            "max_date": "2002-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.56,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "ISVM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ISVM"
                        },
                        {
                            "notes": "K-NN, shape context matching (preprocessing: shape context feature extraction)",
                            "withdrawn": false,
                            "date": "2002-07-01",
                            "papername": "Shape matching and object recognition using shape contexts",
                            "value": 0.63,
                            "url": "http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=B2AAC2BC3824F19757CAC66986D5F3FF?doi=10.1.1.18.8852&rep=rep1&type=pdf",
                            "min_date": "2002-01-01",
                            "maxval": 0.63,
                            "max_date": "2002-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.63,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Shape contexts",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Shape contexts"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2003-07-01",
                            "papername": "Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis",
                            "value": 0.4,
                            "url": "http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=D1C7D701BD39935473808DA5A93426C5?doi=10.1.1.160.8494&rep=rep1&type=pdf",
                            "min_date": "2003-01-01",
                            "maxval": 0.4,
                            "max_date": "2003-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Best Practices for Convol..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2003-07-01",
                            "papername": "Handwritten Digit Recognition using Convolutional Neural Networks and Gabor Filters",
                            "value": 0.68,
                            "url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.133.6559&rep=rep1&type=pdf",
                            "min_date": "2003-01-01",
                            "maxval": 0.68,
                            "max_date": "2003-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.68,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "CNN+Gabor Filters",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CNN+Gabor Filters"
                        },
                        {
                            "notes": "The ConvNN is based on the paper \"Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis\".",
                            "withdrawn": null,
                            "date": "2003-07-01",
                            "papername": "Convolutional Neural Networks",
                            "value": 1.19,
                            "url": "",
                            "min_date": "2003-01-01",
                            "maxval": 1.19,
                            "max_date": "2003-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 1.19,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "CNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CNN"
                        },
                        {
                            "notes": "Large conv. net, unsup pretraining, uses elastic distortions",
                            "withdrawn": false,
                            "date": "2006-07-01",
                            "papername": "Efficient Learning of Sparse Representations with an Energy-Based Model",
                            "value": 0.39,
                            "url": "http://papers.nips.cc/paper/3112-efficient-learning-of-sparse-representations-with-an-energy-based-model",
                            "min_date": "2006-01-01",
                            "maxval": 0.39,
                            "max_date": "2006-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.39,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Energy-Based Sparse Represenation",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Energy-Based Sparse Repre..."
                        },
                        {
                            "notes": "",
                            "withdrawn": null,
                            "date": "2006-07-01",
                            "papername": "Reducing the dimensionality of data with neural networks",
                            "value": 1.2,
                            "url": "",
                            "min_date": "2006-01-01",
                            "maxval": 1.2,
                            "max_date": "2006-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 1.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Reducing the dimensionality of data with neural networks",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Reducing the dimensionali..."
                        },
                        {
                            "notes": "K-NN with non-linear deformation (IDM) (Preprocessing: shiftable edges)",
                            "withdrawn": false,
                            "date": "2007-07-01",
                            "papername": "Deformation Models for Image Recognition",
                            "value": 0.54,
                            "url": "http://www.keysers.net/daniel/files/Keysers--Deformation-Models--TPAMI2007.pdf",
                            "min_date": "2007-01-01",
                            "maxval": 0.54,
                            "max_date": "2007-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.54,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Deformation Models",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deformation Models"
                        },
                        {
                            "notes": "Trainable feature extractor + SVMs, uses affine distortions",
                            "withdrawn": false,
                            "date": "2007-07-01",
                            "papername": "A trainable feature extractor for handwritten digit recognition",
                            "value": 0.54,
                            "url": "http://hal.inria.fr/docs/00/05/75/61/PDF/LauerSuenBlochPR.pdf",
                            "min_date": "2007-01-01",
                            "maxval": 0.54,
                            "max_date": "2007-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.54,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Trainable feature extractor",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Trainable feature extractor"
                        },
                        {
                            "notes": "Large conv. net, unsup features, no distortions",
                            "withdrawn": false,
                            "date": "2007-07-01",
                            "papername": "Unsupervised learning of invariant feature hierarchies with applications to object recognition",
                            "value": 0.62,
                            "url": "http://yann.lecun.com/exdb/publis/pdf/ranzato-cvpr-07.pdf",
                            "min_date": "2007-01-01",
                            "maxval": 0.62,
                            "max_date": "2007-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.62,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "invariant feature hierarchies",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "invariant feature hierarc..."
                        },
                        {
                            "notes": "Unsupervised sparse features + SVM, no distortions",
                            "withdrawn": false,
                            "date": "2008-07-01",
                            "papername": "Simple Methods for High-Performance Digit Recognition Based on Sparse Coding",
                            "value": 0.59,
                            "url": "http://www.inb.uni-luebeck.de/publikationen/pdfs/LaBaMa08c.pdf",
                            "min_date": "2008-01-01",
                            "maxval": 0.59,
                            "max_date": "2008-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.59,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Sparse Coding",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Sparse Coding"
                        },
                        {
                            "notes": "",
                            "withdrawn": null,
                            "date": "2008-07-01",
                            "papername": "CS81: Learning words with Deep Belief Networks",
                            "value": 1.12,
                            "url": "",
                            "min_date": "2008-01-01",
                            "maxval": 1.12,
                            "max_date": "2008-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 1.12,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DBN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DBN"
                        },
                        {
                            "notes": "",
                            "withdrawn": null,
                            "date": "2008-07-01",
                            "papername": "Deep learning via semi-supervised embedding",
                            "value": 1.5,
                            "url": "",
                            "min_date": "2008-01-01",
                            "maxval": 1.5,
                            "max_date": "2008-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 1.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Deep learning via semi-supervised embedding",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep learning via semi-su..."
                        },
                        {
                            "notes": "Large conv. net, unsup pretraining, no distortions",
                            "withdrawn": false,
                            "date": "2009-07-01",
                            "papername": "What is the Best Multi-Stage Architecture for Object Recognition?",
                            "value": 0.53,
                            "url": "http://yann.lecun.com/exdb/publis/pdf/jarrett-iccv-09.pdf",
                            "min_date": "2009-01-01",
                            "maxval": 0.53,
                            "max_date": "2009-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.53,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "The Best Multi-Stage Architecture",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "The Best Multi-Stage Arch..."
                        },
                        {
                            "notes": "",
                            "withdrawn": null,
                            "date": "2009-07-01",
                            "papername": "Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations",
                            "value": 0.82,
                            "url": "",
                            "min_date": "2009-01-01",
                            "maxval": 0.82,
                            "max_date": "2009-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.82,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "CDBN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CDBN"
                        },
                        {
                            "notes": "",
                            "withdrawn": null,
                            "date": "2009-07-01",
                            "papername": "Large-Margin kNN Classification using a Deep Encoder Network",
                            "value": 0.94,
                            "url": "",
                            "min_date": "2009-01-01",
                            "maxval": 0.94,
                            "max_date": "2009-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.94,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Large-Margin kNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Large-Margin kNN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2009-07-01",
                            "papername": "Deep Boltzmann Machines",
                            "value": 0.95,
                            "url": "http://www.utstat.toronto.edu/~rsalakhu/papers/dbm.pdf",
                            "min_date": "2009-01-01",
                            "maxval": 0.95,
                            "max_date": "2009-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.95,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Deep Boltzmann Machines",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep Boltzmann Machines"
                        },
                        {
                            "notes": "6-layer NN 784-2500-2000-1500-1000-500-10 (on GPU), uses elastic distortions",
                            "withdrawn": false,
                            "date": "2010-03-01",
                            "papername": "Deep Big Simple Neural Nets Excel on Handwritten Digit Recognition",
                            "value": 0.35,
                            "url": "https://arxiv.org/abs/1003.0358",
                            "min_date": null,
                            "maxval": 0.35,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.35,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DBSNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DBSNN"
                        },
                        {
                            "notes": "Uses sparse coding + svm.",
                            "withdrawn": false,
                            "date": "2010-07-01",
                            "papername": "Supervised Translation-Invariant Sparse Coding",
                            "value": 0.84,
                            "url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.206.339&rep=rep1&type=pdf",
                            "min_date": "2010-01-01",
                            "maxval": 0.84,
                            "max_date": "2010-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.84,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Supervised Translation-Invariant Sparse Coding",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Supervised Translation-In..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2011-07-01",
                            "papername": "On Optimization Methods for Deep Learning",
                            "value": 0.69,
                            "url": "http://ai.stanford.edu/~quocle/LeNgiCoaLahProNg11.pdf",
                            "min_date": "2011-01-01",
                            "maxval": 0.69,
                            "max_date": "2011-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.69,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "On Optimization Methods for Deep Learning",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "On Optimization Methods f..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-06-16",
                            "papername": "Multi-column Deep Neural Networks for Image Classification ",
                            "value": 0.23,
                            "url": "http://www.idsia.ch/~ciresan/data/cvpr2012.pdf",
                            "min_date": null,
                            "maxval": 0.23,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.23,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "MCDNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MCDNN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-06-16",
                            "papername": "Beyond Spatial Pyramids: Receptive Field Learning for Pooled Image Features",
                            "value": 0.64,
                            "url": "http://www.icsi.berkeley.edu/pubs/vision/beyondspatial12.pdf",
                            "min_date": null,
                            "maxval": 0.64,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.64,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Receptive Field Learning",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Receptive Field Learning"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-02-28",
                            "papername": "Trainable COSFIRE Filters for Keypoint Detection and Pattern Recognition",
                            "value": 0.52,
                            "url": "http://www.cs.rug.nl/~george/articles/PAMI2013.pdf",
                            "min_date": null,
                            "maxval": 0.52,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.52,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "COSFIRE",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "COSFIRE"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-06-16",
                            "papername": "Regularization of Neural Networks using DropConnect",
                            "value": 0.21,
                            "url": "http://cs.nyu.edu/~wanli/dropc/",
                            "min_date": null,
                            "maxval": 0.21,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.21,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DropConnect",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DropConnect"
                        },
                        {
                            "notes": "Uses convolution. Does not use dataset augmentation.",
                            "withdrawn": false,
                            "date": "2013-06-16",
                            "papername": "Maxout Networks",
                            "value": 0.45,
                            "url": "http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf",
                            "min_date": null,
                            "maxval": 0.45,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.45,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Maxout Networks",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Maxout Networks"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-07-01",
                            "papername": "Sparse Activity and Sparse Connectivity in Supervised Learning",
                            "value": 0.75,
                            "url": "http://jmlr.org/papers/v14/thom13a.html",
                            "min_date": "2013-01-01",
                            "maxval": 0.75,
                            "max_date": "2013-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.75,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Sparse Activity and Sparse Connectivity in Supervised Learning",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Sparse Activity and Spars..."
                        },
                        {
                            "notes": "NIN + Dropout The code for NIN available at https://github.com/mavenlin/cuda-convnet",
                            "withdrawn": false,
                            "date": "2014-04-14",
                            "papername": "Network in Network",
                            "value": 0.47,
                            "url": "http://openreview.net/document/9b05a3bb-3a5e-49cb-91f7-0f482af65aea#9b05a3bb-3a5e-49cb-91f7-0f482af65aea",
                            "min_date": null,
                            "maxval": 0.47,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.47,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "NiN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "NiN"
                        },
                        {
                            "notes": "No data augmentation.",
                            "withdrawn": false,
                            "date": "2014-06-21",
                            "papername": "PCANet: A Simple Deep Learning Baseline for Image Classification?",
                            "value": 0.62,
                            "url": "https://arxiv.org/abs/1404.3606",
                            "min_date": "2014-04-14",
                            "maxval": 0.62,
                            "max_date": "2014-08-28",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.62,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "PCANet",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "PCANet"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-07-01",
                            "papername": "Deeply-Supervised Nets",
                            "value": 0.39,
                            "url": "http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/",
                            "min_date": "2014-01-01",
                            "maxval": 0.39,
                            "max_date": "2014-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.39,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DSN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DSN"
                        },
                        {
                            "notes": "StrongNet is a neural design which uses two innovations: (a) strong neurons - highly nonlinear neurons with multiple outputs and (b) mostly unsupervised architecture  backpropagation-free design with all layers except for the last one being trained in a completely unsupervised setting.",
                            "withdrawn": false,
                            "date": "2014-07-01",
                            "papername": "StrongNet: mostly unsupervised image recognition with strong neurons",
                            "value": 1.1,
                            "url": "http://www.alglib.net/articles/tr-20140813-strongnet.pdf",
                            "min_date": "2014-01-01",
                            "maxval": 1.1,
                            "max_date": "2014-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 1.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "StrongNet",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "StrongNet"
                        },
                        {
                            "notes": "No data augmentation.",
                            "withdrawn": false,
                            "date": "2014-08-28",
                            "papername": "Convolutional Kernel Networks",
                            "value": 0.39,
                            "url": "https://arxiv.org/abs/1406.3332",
                            "min_date": "2014-06-12",
                            "maxval": 0.39,
                            "max_date": "2014-11-14",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.39,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "CKN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CKN"
                        },
                        {
                            "notes": "permutation invariant network used",
                            "withdrawn": false,
                            "date": "2015-02-03",
                            "papername": "Explaining and Harnessing Adversarial Examples",
                            "value": 0.78,
                            "url": "https://arxiv.org/abs/1412.6572",
                            "min_date": "2014-12-20",
                            "maxval": 0.78,
                            "max_date": "2015-03-20",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.78,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Explaining and Harnessing Adversarial Examples",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Explaining and Harnessing..."
                        },
                        {
                            "notes": "Uses 12 passes at test time. Reaches 0.5% when using a single pass at test time.",
                            "withdrawn": false,
                            "date": "2015-02-28",
                            "papername": "Fractional Max-Pooling",
                            "value": 0.32,
                            "url": "https://arxiv.org/abs/1412.6071",
                            "min_date": "2014-12-18",
                            "maxval": 0.32,
                            "max_date": "2015-05-12",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.32,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Fractional MP",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Fractional MP"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-03-11",
                            "papername": "C-SVDDNet: An Effective Single-Layer Network for Unsupervised Feature Learning",
                            "value": 0.35,
                            "url": "https://arxiv.org/abs/1412.7259",
                            "min_date": "2014-12-23",
                            "maxval": 0.35,
                            "max_date": "2015-05-29",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.35,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "C-SVDDNet",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C-SVDDNet"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-04-05",
                            "papername": "Hybrid Orthogonal Projection and Estimation (HOPE): A New Framework to Probe and Learn Neural Networks",
                            "value": 0.4,
                            "url": "https://arxiv.org/abs/1502.00702",
                            "min_date": "2015-02-03",
                            "maxval": 0.4,
                            "max_date": "2015-06-06",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "HOPE",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "HOPE"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-05-13",
                            "papername": "APAC: Augmented PAttern Classification with Neural Networks",
                            "value": 0.23,
                            "url": "https://arxiv.org/abs/1505.03229",
                            "min_date": null,
                            "maxval": 0.23,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.23,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "APAC",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "APAC"
                        },
                        {
                            "notes": "No data augmentation",
                            "withdrawn": false,
                            "date": "2015-05-31",
                            "papername": "Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network",
                            "value": 0.37,
                            "url": "https://arxiv.org/abs/1503.04596",
                            "min_date": "2015-03-16",
                            "maxval": 0.37,
                            "max_date": "2015-08-15",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.37,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "FLSCNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "FLSCNN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-06-08",
                            "papername": "Recurrent Convolutional Neural Network for Object Recognition",
                            "value": 0.31,
                            "url": "http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_004.pdf",
                            "min_date": null,
                            "maxval": 0.31,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.31,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "RCNN-96",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RCNN-96"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-06-12",
                            "papername": "ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks",
                            "value": 0.45,
                            "url": "https://arxiv.org/abs/1505.00393",
                            "min_date": "2015-05-03",
                            "maxval": 0.45,
                            "max_date": "2015-07-23",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.45,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "ReNet",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ReNet"
                        },
                        {
                            "notes": "Based on NiN architecture.",
                            "withdrawn": false,
                            "date": "2015-07-01",
                            "papername": "Multi-Loss Regularized Deep Neural Network",
                            "value": 0.42,
                            "url": "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7258343",
                            "min_date": "2015-01-01",
                            "maxval": 0.42,
                            "max_date": "2015-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.42,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "MLR DNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MLR DNN"
                        },
                        {
                            "notes": "Uses about 10x fewer parameters than the reference model, which reaches 0.87%.",
                            "withdrawn": false,
                            "date": "2015-07-01",
                            "papername": "Deep Fried Convnets",
                            "value": 0.71,
                            "url": "http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yang_Deep_Fried_Convnets_ICCV_2015_paper.pdf",
                            "min_date": "2015-01-01",
                            "maxval": 0.71,
                            "max_date": "2015-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.71,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Deep Fried Convnets",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep Fried Convnets"
                        },
                        {
                            "notes": "feature extraction part of convnet is trained on imagenet (external training data), classification part is trained on cifar-10",
                            "withdrawn": false,
                            "date": "2015-07-12",
                            "papername": "Deep Convolutional Neural Networks as Generic Feature Extractors",
                            "value": 0.46,
                            "url": "http://www.isip.uni-luebeck.de/fileadmin/uploads/tx_wapublications/hertel_ijcnn_2015.pdf",
                            "min_date": null,
                            "maxval": 0.46,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.46,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DCNN+GFE",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DCNN+GFE"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-09-17",
                            "papername": "On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units",
                            "value": 0.35,
                            "url": "https://arxiv.org/abs/1508.00330",
                            "min_date": "2015-08-03",
                            "maxval": 0.38,
                            "max_date": "2015-11-01",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.31999999999999995,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.03,
                            "name": "MIM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MIM"
                        },
                        {
                            "notes": "Single model without data augmentation",
                            "withdrawn": false,
                            "date": "2015-10-05",
                            "papername": "Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree",
                            "value": 0.29,
                            "url": "https://arxiv.org/abs/1509.08985",
                            "min_date": "2015-09-30",
                            "maxval": 0.29,
                            "max_date": "2015-10-10",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.29,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Tree+Max-Avg pooling",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Tree+Max-Avg pooling"
                        },
                        {
                            "notes": "(k=5 maxout pieces in each maxout unit).",
                            "withdrawn": false,
                            "date": "2015-11-09",
                            "papername": "Batch-normalized Maxout Network in Network",
                            "value": 0.24,
                            "url": "https://arxiv.org/abs/1511.02583",
                            "min_date": null,
                            "maxval": 0.24,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.24,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "BNM NiN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "BNM NiN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-11-18",
                            "papername": "Competitive Multi-scale Convolution",
                            "value": 0.33,
                            "url": "https://arxiv.org/abs/1511.05635",
                            "min_date": null,
                            "maxval": 0.33,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.33,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "CMsC",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CMsC"
                        },
                        {
                            "notes": "Best result selected on test set. 0.46% average over multiple trained models.",
                            "withdrawn": false,
                            "date": "2015-12-07",
                            "papername": "Training Very Deep Networks",
                            "value": 0.45,
                            "url": "http://people.idsia.ch/~rupesh/very_deep_learning/",
                            "min_date": null,
                            "maxval": 0.45,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.45,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "VDN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "VDN"
                        },
                        {
                            "notes": "Using 50% dropout",
                            "withdrawn": false,
                            "date": "2015-12-07",
                            "papername": "BinaryConnect: Training Deep Neural Networks with binary weights during propagations",
                            "value": 1.01,
                            "url": "http://papers.nips.cc/paper/5647-binaryconnect-training-deep-neural-networks-with-binary-weights-during-propagations.pdf",
                            "min_date": null,
                            "maxval": 1.01,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 1.01,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "BinaryConnect",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "BinaryConnect"
                        },
                        {
                            "notes": "2 layers + multi dict.",
                            "withdrawn": false,
                            "date": "2016-01-02",
                            "papername": "Convolutional Clustering for Unsupervised Learning",
                            "value": 1.4,
                            "url": "https://arxiv.org/abs/1511.06241",
                            "min_date": "2015-11-19",
                            "maxval": 1.4,
                            "max_date": "2016-02-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 1.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Convolutional Clustering",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Convolutional Clustering"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-04",
                            "papername": "All you need is a good init",
                            "value": 0.38,
                            "url": "https://arxiv.org/abs/1511.06422",
                            "min_date": "2015-11-19",
                            "maxval": 0.38,
                            "max_date": "2016-02-19",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(MNIST handwritten digit recognition)                 SOLVED",
                            "minval": 0.38,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Fitnet-LSUV-SVM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Fitnet-LSUV-SVM"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/awty.py#L63",
                    "target_label": null,
                    "url": "https://cs.stanford.edu/~acoates/stl10/",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "STL-10 Image Recognition",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/awty.py",
                    "parent": "Problem(Image classification)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2011-12-17",
                            "papername": "Selecting Receptive Fields in Deep Networks ",
                            "value": 60.1,
                            "url": "http://www.stanford.edu/~acoates/papers/coatesng_nips_2011.pdf",
                            "min_date": null,
                            "maxval": 60.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 60.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Receptive Fields",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Receptive Fields"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-06-26",
                            "papername": "Learning Invariant Representations with Local Transformations",
                            "value": 58.7,
                            "url": "http://web.eecs.umich.edu/~honglak/icml12-invariantFeatureLearning.pdf",
                            "min_date": null,
                            "maxval": 58.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 58.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Invariant Representations with Local Transformations",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Invariant Representations..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-01",
                            "papername": "Deep Learning of Invariant Features via Simulated Fixations in Video",
                            "value": 61.0,
                            "url": "http://papers.nips.cc/paper/4730-deep-learning-of-invariant-features-via-simulated-fixations-in-video",
                            "min_date": "2012-01-01",
                            "maxval": 61.0,
                            "max_date": "2012-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 61.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Simulated Fixations",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Simulated Fixations"
                        },
                        {
                            "notes": "Hierarchical sparse coding using Matching Pursuit and K-SVD",
                            "withdrawn": false,
                            "date": "2012-07-01",
                            "papername": "Unsupervised Feature Learning for RGB-D Based Object Recognition",
                            "value": 64.5,
                            "url": "http://homes.cs.washington.edu/~lfb/paper/iser12.pdf",
                            "min_date": "2012-01-01",
                            "maxval": 64.5,
                            "max_date": "2012-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 64.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "RGB-D Based Object Recognition",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RGB-D Based Object Recogn..."
                        },
                        {
                            "notes": "Trained also with video (unrelated to STL-10) obtained 61%",
                            "withdrawn": false,
                            "date": "2012-12-03",
                            "papername": "Deep Learning of Invariant Features via Simulated Fixations in Video",
                            "value": 56.5,
                            "url": "http://ai.stanford.edu/~wzou/nips_ZouZhuNgYu12.pdf",
                            "min_date": null,
                            "maxval": 56.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 56.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Deep Learning of Invariant Features via Simulated Fixations in Video",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep Learning of Invarian..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-12-03",
                            "papername": "Discriminative Learning of Sum-Product Networks",
                            "value": 62.3,
                            "url": "http://homes.cs.washington.edu/~rcg/papers/dspn.pdf",
                            "min_date": null,
                            "maxval": 62.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 62.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Discriminative Learning of Sum-Product Networks",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Discriminative Learning o..."
                        },
                        {
                            "notes": "1600 codes, learnt using 2x PDL",
                            "withdrawn": false,
                            "date": "2013-01-15",
                            "papername": "Pooling-Invariant Image Feature Learning ",
                            "value": 58.28,
                            "url": "https://arxiv.org/abs/1302.5056v1",
                            "min_date": null,
                            "maxval": 58.28,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 58.28,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Pooling-Invariant",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Pooling-Invariant"
                        },
                        {
                            "notes": "Also uses CIFAR-10 training data",
                            "withdrawn": false,
                            "date": "2013-07-01",
                            "papername": "Multi-Task Bayesian Optimization",
                            "value": 70.1,
                            "url": "http://hips.seas.harvard.edu/files/swersky-multi-nips-2013.pdf",
                            "min_date": "2013-01-01",
                            "maxval": 70.1,
                            "max_date": "2013-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 70.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Multi-Task Bayesian Optimization",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Multi-Task Bayesian Optim..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-02-24",
                            "papername": "No more meta-parameter tuning in unsupervised sparse feature learning",
                            "value": 61.0,
                            "url": "https://arxiv.org/abs/1402.5766",
                            "min_date": null,
                            "maxval": 61.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 61.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "No more meta-parameter tuning in unsupervised sparse feature learning",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "No more meta-parameter tu..."
                        },
                        {
                            "notes": "3-layers + multi-dict. 5 \u00b1 0.5 with 3-layers only. 6 \u00b1 0.6 with 1-layers only.",
                            "withdrawn": false,
                            "date": "2014-06-21",
                            "papername": "Stable and Efficient Representation Learning with Nonnegativity Constraints ",
                            "value": 67.9,
                            "url": "http://jmlr.org/proceedings/papers/v32/line14.pdf",
                            "min_date": null,
                            "maxval": 67.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 67.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Nonnegativity Constraints ",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Nonnegativity Constraints "
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-06-23",
                            "papername": "Committees of deep feedforward networks trained with few data",
                            "value": 68.0,
                            "url": "https://arxiv.org/abs/1406.5947",
                            "min_date": null,
                            "maxval": 68.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 68.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "DFF Committees",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DFF Committees"
                        },
                        {
                            "notes": "No data augmentation.",
                            "withdrawn": false,
                            "date": "2014-08-28",
                            "papername": "Convolutional Kernel Networks",
                            "value": 62.32,
                            "url": "https://arxiv.org/abs/1406.3332",
                            "min_date": "2014-06-12",
                            "maxval": 62.32,
                            "max_date": "2014-11-14",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 62.32,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "CKN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CKN"
                        },
                        {
                            "notes": "Unsupervised feature learning + linear SVM",
                            "withdrawn": false,
                            "date": "2014-12-08",
                            "papername": "Discriminative Unsupervised Feature Learning with Convolutional Neural Networks",
                            "value": 72.8,
                            "url": "http://papers.nips.cc/paper/5548-discriminative-unsupervised-feature-learning-with-convolutional-neural-networks.pdf",
                            "min_date": null,
                            "maxval": 72.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 72.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Discriminative Unsupervised Feature Learning with Convolutional Neural Networks",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Discriminative Unsupervis..."
                        },
                        {
                            "notes": "Unsupervised pre-training, with supervised fine-tuning. Uses dropout and data-augmentation.",
                            "withdrawn": false,
                            "date": "2015-02-13",
                            "papername": "An Analysis of Unsupervised Pre-training in Light of Recent Advances",
                            "value": 70.2,
                            "url": "https://arxiv.org/abs/1412.6597",
                            "min_date": "2014-12-20",
                            "maxval": 70.2,
                            "max_date": "2015-04-10",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 70.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "An Analysis of Unsupervised Pre-training in Light of Recent Advances",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "An Analysis of Unsupervis..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-03-11",
                            "papername": "C-SVDDNet: An Effective Single-Layer Network for Unsupervised Feature Learning",
                            "value": 68.23,
                            "url": "https://arxiv.org/abs/1412.7259",
                            "min_date": "2014-12-23",
                            "maxval": 68.23,
                            "max_date": "2015-05-29",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 68.23,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "C-SVDDNet",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "C-SVDDNet"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-01",
                            "papername": "Deep Representation Learning with Target Coding",
                            "value": 73.15,
                            "url": "http://personal.ie.cuhk.edu.hk/~ccloy/files/aaai_2015_target_coding.pdf",
                            "min_date": "2015-01-01",
                            "maxval": 73.15,
                            "max_date": "2015-12-31",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 73.15,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Deep Representation Learning with Target Coding",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep Representation Learn..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-10-11",
                            "papername": "Stacked What-Where Auto-encoders",
                            "value": 74.33,
                            "url": "https://arxiv.org/abs/1506.02351",
                            "min_date": "2015-06-08",
                            "maxval": 74.33,
                            "max_date": "2016-02-14",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 74.33,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "SWWAE",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SWWAE"
                        },
                        {
                            "notes": "3 layers + multi dict. With 2 layers, reaches 71.4%",
                            "withdrawn": false,
                            "date": "2016-01-02",
                            "papername": "Convolutional Clustering for Unsupervised Learning",
                            "value": 74.1,
                            "url": "https://arxiv.org/abs/1511.06241",
                            "min_date": "2015-11-19",
                            "maxval": 74.1,
                            "max_date": "2016-02-16",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 74.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.0,
                            "name": "Convolutional Clustering",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Convolutional Clustering"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-11-19",
                            "papername": "Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks",
                            "value": 77.79,
                            "url": "https://arxiv.org/abs/1611.06430v1",
                            "min_date": null,
                            "maxval": 78.59,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(STL-10 Image Recognition)                            ?",
                            "minval": 76.99000000000001,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0.8,
                            "name": "CC-GAN\u00b2",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CC-GAN\u00b2"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/awty.py#L24",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Leeds Sport Poses",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Image classification)",
                    "measures": []
                }
            ],
            "subproblems": "<map object at 0x7f5a5cb0d128>",
            "url": null,
            "solved": false,
            "attributes": [
                "vision",
                "agi"
            ]
        },
        {
            "name": "Train machine learning systems on private user data, without transferring sensitive facts into the model",
            "superproblems": "<map object at 0x7f5a60798128>",
            "metrics": [
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-40-7db95217a73d>#L2",
                    "target_label": null,
                    "url": "https://arxiv.org/abs/1602.05629",
                    "scale": "Score",
                    "solved": true,
                    "axis_label": "Score",
                    "name": "Federated Learning (distributed training with thresholded updates to models)",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Train machine learning systems on private user data, without transferring sensitive facts into the model)",
                    "measures": []
                }
            ],
            "subproblems": "<map object at 0x7f5a607987b8>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "name": "Pedestrian, bicycle & obstacle detection",
            "superproblems": "<map object at 0x7f5a607984e0>",
            "metrics": [
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-37-13d9cddcfa63>#L9",
                    "target_label": null,
                    "url": "http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/",
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Caltech Pedestrians USA",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Pedestrian, bicycle & obstacle detection)",
                    "measures": []
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-37-13d9cddcfa63>#L11",
                    "target_label": null,
                    "url": "http://pascal.inrialpes.fr/data/human/",
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "INRIA persons",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Pedestrian, bicycle & obstacle detection)",
                    "measures": []
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-37-13d9cddcfa63>#L13",
                    "target_label": null,
                    "url": "http://www.vision.ee.ethz.ch/~aess/dataset/",
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "ETH Pedestrian",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Pedestrian, bicycle & obstacle detection)",
                    "measures": []
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-37-13d9cddcfa63>#L15",
                    "target_label": null,
                    "url": "http://www.d2.mpi-inf.mpg.de/tud-brussels",
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "TUD-Brussels Pedestrian",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Pedestrian, bicycle & obstacle detection)",
                    "measures": []
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master/<ipython-input-37-13d9cddcfa63>#L17",
                    "target_label": null,
                    "url": "http://www.gavrila.net/Datasets/Daimler_Pedestrian_Benchmark_D/Daimler_Mono_Ped__Detection_Be/daimler_mono_ped__detection_be.html",
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Damiler Pedestrian",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Pedestrian, bicycle & obstacle detection)",
                    "measures": []
                }
            ],
            "subproblems": "<map object at 0x7f5a607986a0>",
            "url": null,
            "solved": false,
            "attributes": [
                "safety",
                "vision"
            ]
        },
        {
            "name": "Recognise events in videos",
            "superproblems": "<map object at 0x7f5a60798588>",
            "metrics": [
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/vision.py#L36",
                    "target_label": null,
                    "url": "https://research.google.com/youtube8m/",
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "YouTube-8M video labelling",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Recognise events in videos)",
                    "measures": []
                }
            ],
            "subproblems": "<map object at 0x7f5a60798978>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "notes": "\nHumans have only partial resistance to reward hacking.\nAddiction seems to be one failure to exhibit this resistance.\nAvoiding learning something because it might make us feel bad, or even building elaborate systems of self-deception, are also sometimes\nseen in humans. So this problem is not tagged \"agi\".\n",
            "name": "Avoiding reward hacking",
            "superproblems": "<map object at 0x7f5a60798710>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a607984a8>",
            "url": "https://arxiv.org/abs/1606.06565",
            "solved": false,
            "attributes": [
                "safety"
            ]
        },
        {
            "name": "Modify arbitrary ML systems in order to be able to provide comprehensible human explanations of their decisions",
            "superproblems": "<map object at 0x7f5a60798b00>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a60798ac8>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "name": "Vision",
            "superproblems": "<map object at 0x7f5a60798518>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a60798358>",
            "url": null,
            "solved": false,
            "attributes": [
                "agi",
                "vision",
                "world-modelling"
            ]
        },
        {
            "name": "Image comprehension",
            "superproblems": "<map object at 0x7f5a60798860>",
            "metrics": [
                {
                    "notes": "",
                    "target": 84.122371649179,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/vision.py#L81",
                    "target_label": null,
                    "url": "http://visualqa.org/",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "COCO Visual Question Answering (VQA) 1.0 open ended",
                    "target_source": "https://arxiv.org/abs/1505.00468",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/vision.py",
                    "parent": "Problem(Image comprehension)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-05-03",
                            "papername": "VQA: Visual Question Answering",
                            "value": 58.2,
                            "url": "https://arxiv.org/abs/1505.00468v1",
                            "min_date": null,
                            "maxval": 58.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved",
                            "minval": 58.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "LSTM Q+I",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "LSTM Q+I"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-15",
                            "papername": "Simple Baseline for Visual Question Answering",
                            "value": 55.89,
                            "url": "https://arxiv.org/abs/1512.02167",
                            "min_date": "2015-12-07",
                            "maxval": 55.89,
                            "max_date": "2015-12-15",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved",
                            "minval": 55.89,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "iBOWIMG baseline",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "iBOWIMG baseline"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-26",
                            "papername": "Stacked Attention Networks for Image Question Answering",
                            "value": 58.9,
                            "url": "https://arxiv.org/abs/1511.02274v2",
                            "min_date": null,
                            "maxval": 58.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved",
                            "minval": 58.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SAN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SAN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-03-09",
                            "papername": "Image Captioning and Visual Question Answering Based on Attributes and Their Related External Knowledge",
                            "value": 59.5,
                            "url": "https://arxiv.org/abs/1603.02814v1",
                            "min_date": null,
                            "maxval": 59.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved",
                            "minval": 59.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "CNN-RNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CNN-RNN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-03-19",
                            "papername": "Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering",
                            "value": 58.24,
                            "url": "https://arxiv.org/abs/1511.05234v2",
                            "min_date": null,
                            "maxval": 58.24,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved",
                            "minval": 58.24,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SMem-VQA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SMem-VQA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-06",
                            "papername": "A Focused Dynamic Attention Model for Visual Question Answering",
                            "value": 59.5,
                            "url": "https://arxiv.org/abs/1604.01485v1",
                            "min_date": null,
                            "maxval": 59.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved",
                            "minval": 59.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "FDA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "FDA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-05-31",
                            "papername": "Hierarchical Co-Attention for Visual Question Answering",
                            "value": 62.1,
                            "url": "https://arxiv.org/abs/1606.00061v1",
                            "min_date": null,
                            "maxval": 62.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved",
                            "minval": 62.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "HQI+ResNet",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "HQI+ResNet"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-06-06",
                            "papername": "Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding",
                            "value": 66.5,
                            "url": "https://arxiv.org/abs/1606.01847v1",
                            "min_date": null,
                            "maxval": 66.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved",
                            "minval": 66.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "MCB 7 att.",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "https://github.com/akirafukui/vqa-mcb",
                            "label": "MCB 7 att."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-08-06",
                            "papername": "Training Recurrent Answering Units with Joint Loss Minimization for VQA",
                            "value": 63.2,
                            "url": "https://arxiv.org/abs/1606.03647",
                            "min_date": "2016-06-12",
                            "maxval": 63.2,
                            "max_date": "2016-09-30",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 open ended) not solved",
                            "minval": 63.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "joint-loss",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "joint-loss"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/vision.py#L82",
                    "target_label": null,
                    "url": "http://visualqa.org/",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "COCO Visual Question Answering (VQA) 1.0 multiple choice",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/vision.py",
                    "parent": "Problem(Image comprehension)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-05-03",
                            "papername": "VQA: Visual Question Answering",
                            "value": 63.1,
                            "url": "https://arxiv.org/abs/1505.00468v1",
                            "min_date": null,
                            "maxval": 63.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 multiple choice)?",
                            "minval": 63.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "LSTM Q+I",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "LSTM Q+I"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-15",
                            "papername": "Simple Baseline for Visual Question Answering",
                            "value": 61.97,
                            "url": "https://arxiv.org/abs/1512.02167",
                            "min_date": "2015-12-07",
                            "maxval": 61.97,
                            "max_date": "2015-12-15",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 multiple choice)?",
                            "minval": 61.97,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "iBOWIMG baseline",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "iBOWIMG baseline"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-06",
                            "papername": "A Focused Dynamic Attention Model for Visual Question Answering",
                            "value": 64.2,
                            "url": "https://arxiv.org/abs/1604.01485v1",
                            "min_date": null,
                            "maxval": 64.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 multiple choice)?",
                            "minval": 64.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "FDA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "FDA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-05-31",
                            "papername": "Hierarchical Co-Attention for Visual Question Answering",
                            "value": 66.1,
                            "url": "https://arxiv.org/abs/1606.00061v1",
                            "min_date": null,
                            "maxval": 66.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 multiple choice)?",
                            "minval": 66.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "HQI+ResNet",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "HQI+ResNet"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-06-06",
                            "papername": "Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding",
                            "value": 70.1,
                            "url": "https://arxiv.org/abs/1606.01847v1",
                            "min_date": null,
                            "maxval": 70.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 multiple choice)?",
                            "minval": 70.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "MCB 7 att.",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "https://github.com/akirafukui/vqa-mcb",
                            "label": "MCB 7 att."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-08-06",
                            "papername": "Training Recurrent Answering Units with Joint Loss Minimization for VQA",
                            "value": 67.3,
                            "url": "https://arxiv.org/abs/1606.03647",
                            "min_date": "2016-06-12",
                            "maxval": 67.3,
                            "max_date": "2016-09-30",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(COCO Visual Question Answering (VQA) 1.0 multiple choice)?",
                            "minval": 67.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "joint-loss",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "joint-loss"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/vision.py#L49",
                    "target_label": null,
                    "url": "http://www.cs.toronto.edu/~mren/imageqa/data/cocoqa/",
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Toronto COCO-QA",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Image comprehension)",
                    "measures": []
                },
                {
                    "notes": "",
                    "target": 60.27,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/vision.py#L50",
                    "target_label": null,
                    "url": "https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/vision-and-language/visual-turing-challenge/",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "DAQUAR",
                    "target_source": "https://arxiv.org/abs/1505.02074",
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Image comprehension)",
                    "measures": []
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/vision.py#L86",
                    "target_label": null,
                    "url": "http://visualgenome.org",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Top-1 precision",
                    "name": "Visual Genome (pairs)",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/vision.py",
                    "parent": "Problem(Image comprehension)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-11-30",
                            "papername": "Modeling Relationships in Referential Expressions with Compositional Modular Networks",
                            "value": 28.52,
                            "url": "https://arxiv.org/abs/1611.09978v1",
                            "min_date": null,
                            "maxval": 28.52,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Visual Genome (pairs))                               ?",
                            "minval": 28.52,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "CMN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CMN"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/vision.py#L87",
                    "target_label": null,
                    "url": "http://visualgenome.org",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Top-1 precision",
                    "name": "Visual Genome (subjects)",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/vision.py",
                    "parent": "Problem(Image comprehension)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-11-30",
                            "papername": "Modeling Relationships in Referential Expressions with Compositional Modular Networks",
                            "value": 44.24,
                            "url": "https://arxiv.org/abs/1611.09978v1",
                            "min_date": null,
                            "maxval": 44.24,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Visual Genome (subjects))                            ?",
                            "minval": 44.24,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "CMN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CMN"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/vision.py#L85",
                    "target_label": null,
                    "url": "https://arxiv.org/abs/1511.03416",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "Visual7W",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/vision.py",
                    "parent": "Problem(Image comprehension)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-06-06",
                            "papername": "Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding",
                            "value": 62.2,
                            "url": "https://arxiv.org/abs/1606.01847v1",
                            "min_date": null,
                            "maxval": 62.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Visual7W)                                            ?",
                            "minval": 62.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "MCB+Att.",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MCB+Att."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-11-30",
                            "papername": "Modeling Relationships in Referential Expressions with Compositional Modular Networks",
                            "value": 72.53,
                            "url": "https://arxiv.org/abs/1611.09978v1",
                            "min_date": null,
                            "maxval": 72.53,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Visual7W)                                            ?",
                            "minval": 72.53,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "CMN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CMN"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/vision.py#L55",
                    "target_label": null,
                    "url": "http://idl.baidu.com/FM-IQA.html",
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "FM-IQA",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Image comprehension)",
                    "measures": []
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/vision.py#L56",
                    "target_label": null,
                    "url": "http://tamaraberg.com/visualmadlibs/",
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Visual Madlibs",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Image comprehension)",
                    "measures": []
                }
            ],
            "subproblems": "<map object at 0x7f5a60798dd8>",
            "url": null,
            "solved": false,
            "attributes": [
                "agi",
                "vision",
                "language",
                "world-modelling"
            ]
        },
        {
            "notes": "\nThis metric is the ability to automatically update the ipython Notebook you are reading by spotting results in pdfs uploaded to arxiv.org.\nPull requests demonstrating solutions are welcome :)\n",
            "name": "Extract major numerical results or progress claims from a STEM paper",
            "superproblems": "<map object at 0x7f5a60798828>",
            "metrics": [
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/stem.py#L12",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Automatically find new relevant ML results on arXiv",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Extract major numerical results or progress claims from a STEM paper)",
                    "measures": []
                }
            ],
            "subproblems": "<map object at 0x7f5a60798a90>",
            "url": null,
            "solved": false,
            "attributes": [
                "language",
                "world-modelling",
                "agi"
            ]
        },
        {
            "name": "Transfer of learning within simple arcade game paradigms",
            "superproblems": "<map object at 0x7f5a60798ba8>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a60798748>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "name": "Given desired circuit characteristics, and many examples, design new circuits to spec",
            "superproblems": "<map object at 0x7f5a607983c8>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a60798cf8>",
            "url": null,
            "solved": false,
            "attributes": [
                "agi",
                "math"
            ]
        },
        {
            "notes": "\nProviding explanations with techniques such as monte carlo analysis may in general\nbe easier than providing robust ones in natural language (since those may or may not\nexist in all cases)\n",
            "name": "Provide mathematical or technical explanations of decisions from classifiers",
            "superproblems": "<map object at 0x7f5a607980b8>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a60798940>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "notes": "\n  Complex abstract strategy games have been solved to super-human levels\n  by computer systems with extensive rule-hinting and heuristics,\n  in some cases combined with machine learning techniques.\n",
            "name": "Playing abstract games with extensive hints",
            "superproblems": "<map object at 0x7f5a610ccb00>",
            "metrics": [
                {
                    "notes": "",
                    "target": 2882,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/strategy_games.py#L59",
                    "target_label": "Best human play",
                    "url": null,
                    "scale": "ELO rating",
                    "solved": true,
                    "axis_label": "ELO rating",
                    "name": "Computer Chess",
                    "target_source": "https://en.wikipedia.org/w/index.php?title=Comparison_of_top_chess_players_throughout_history&oldid=777500496#Elo_system",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/strategy_games.py",
                    "parent": "Problem(Playing abstract games with extensive hints)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "1984-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 1631,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 1631,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 1631,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Novag Super Constellation 6502 4 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Novag Super Constellation..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "1985-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 1827,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 1827,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 1827,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Mephisto Amsterdam 68000 12 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Mephisto Amsterdam 68000 ..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "1986-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 1827,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 1827,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 1827,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Mephisto Amsterdam 68000 12 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Mephisto Amsterdam 68000 ..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "1987-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 1923,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 1923,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 1923,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Mephisto Dallas 68020 14 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Mephisto Dallas 68020 14 ..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "1988-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 1993,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 1993,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 1993,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Mephisto MM 4 Turbo Kit 6502 16 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Mephisto MM 4 Turbo Kit 6..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "1989-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2027,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2027,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2027,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Mephisto Portorose 68020 12 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Mephisto Portorose 68020 ..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "1990-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2138,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2138,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2138,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Mephisto Portorose 68030 36 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Mephisto Portorose 68030 ..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "1991-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2127,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2127,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2127,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Mephisto Vancouver 68030 36 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Mephisto Vancouver 68030 ..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "1992-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2174,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2174,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2174,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Chess Machine Schroder 3.0 ARM2 30 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Chess Machine Schroder 3...."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "1993-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2235,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2235,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2235,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Mephisto Genius 2.0 486/50-66 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Mephisto Genius 2.0 486/5..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "1995-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2306,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2306,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2306,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "MChess Pro 5.0 Pentium 90 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MChess Pro 5.0 Pentium 90..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "1996-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2337,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2337,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2337,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Rebel 8.0 Pentium 90 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Rebel 8.0 Pentium 90 MHz"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "1997-05-11",
                            "papername": "What was Deep Blue's Elo rating? - Quora",
                            "value": 2725,
                            "url": "https://www.quora.com/What-was-Deep-Blues-Elo-rating",
                            "min_date": null,
                            "maxval": 2750,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2700,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 25,
                            "name": "Deep Blue",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep Blue"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "1997-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2418,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2418,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2418,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "HIARCS 6.0 49MB P200 MMX",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "HIARCS 6.0 49MB P200 MMX"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "1998-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2460,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2460,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2460,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Fritz 5.0 PB29% 67MB P200 MMX",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Fritz 5.0 PB29% 67MB P200..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "1999-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2594,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2594,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2594,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Chess Tiger 12.0 DOS 128MB K6-2 450 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Chess Tiger 12.0 DOS 128M..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2000-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2607,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2607,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2607,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Fritz 6.0 128MB K6-2 450 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Fritz 6.0 128MB K6-2 450 ..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2001-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2709,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2709,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2709,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Chess Tiger 14.0 CB 256MB Athlon 1200",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Chess Tiger 14.0 CB 256MB..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2002-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2759,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2759,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2759,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Deep Fritz 7.0 256MB Athlon 1200 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep Fritz 7.0 256MB Athl..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2003-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2791,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2791,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2791,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Shredder 7.04 UCI 256MB Athlon 1200 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Shredder 7.04 UCI 256MB A..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2004-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2800,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2800,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2800,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Shredder 8.0 CB 256MB Athlon 1200 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Shredder 8.0 CB 256MB Ath..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2005-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2808,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2808,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2808,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Shredder 9.0 UCI 256MB Athlon 1200 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Shredder 9.0 UCI 256MB At..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2006-05-27",
                            "papername": "CCRL 40/40 - Complete list",
                            "value": 2995,
                            "url": "https://web.archive.org/web/20060531091049/http://www.computerchess.org.uk/ccrl/4040/rating_list_all.html",
                            "min_date": null,
                            "maxval": 3020,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2970,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 25,
                            "name": "Rybka 1.1 64bit",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Rybka 1.1 64bit"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2006-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2902,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2902,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2902,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Rybka 1.2 256MB Athlon 1200 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Rybka 1.2 256MB Athlon 12..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2007-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 2935,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 2935,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 2935,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Rybka 2.3.1 Arena 256MB Athlon 1200 MHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Rybka 2.3.1 Arena 256MB A..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2008-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 3238,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 3238,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 3238,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Deep Rybka 3 2GB Q6600 2.4 GHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep Rybka 3 2GB Q6600 2...."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2009-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 3232,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 3232,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 3232,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Deep Rybka 3 2GB Q6600 2.4 GHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep Rybka 3 2GB Q6600 2...."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2010-08-07",
                            "papername": "CCRL 40/40 - Complete list",
                            "value": 3269,
                            "url": "https://web.archive.org/web/20100923131123/http://www.computerchess.org.uk/ccrl/4040/rating_list_all.html",
                            "min_date": null,
                            "maxval": 3291,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 3247,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 22,
                            "name": "Rybka 4 64bit",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Rybka 4 64bit"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2010-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 3227,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 3227,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 3227,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Deep Rybka 3 2GB Q6600 2.4 GHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep Rybka 3 2GB Q6600 2...."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2011-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 3216,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 3216,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 3216,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Deep Rybka 4 2GB Q6600 2.4 GHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep Rybka 4 2GB Q6600 2...."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 3221,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 3221,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 3221,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Deep Rybka 4 x64 2GB Q6600 2.4 GHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep Rybka 4 x64 2GB Q660..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-07-20",
                            "papername": "Wayback Machine",
                            "value": 3248,
                            "url": "https://web.archive.org/web/20130415000000*/http://www.computerchess.org.uk/ccrl/4040/rating_list_all.html",
                            "min_date": null,
                            "maxval": 3264,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 3232,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 16,
                            "name": "Houdini 3 64bit",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Houdini 3 64bit"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 3241,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 3241,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 3241,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Komodo 5.1 MP x64 2GB Q6600 2.4 GHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Komodo 5.1 MP x64 2GB Q66..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 3295,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 3295,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 3295,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Komodo 7.0 MP x64 2GB Q6600 2.4 GHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Komodo 7.0 MP x64 2GB Q66..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-04",
                            "papername": "CCRL 40/40 - Complete list",
                            "value": 3332,
                            "url": "https://web.archive.org/web/20150708104805/http://www.computerchess.org.uk/ccrl/4040/rating_list_all.html",
                            "min_date": null,
                            "maxval": 3356,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 3308,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 24,
                            "name": "Komodo 9",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Komodo 9"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 3334,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 3334,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 3334,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Stockfish 6 MP x64 2GB Q6600 2.4 GHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Stockfish 6 MP x64 2GB Q6..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-31",
                            "papername": "Swedish Chess Computer Association - Wikipedia",
                            "value": 3366,
                            "url": "https://en.wikipedia.org/wiki/Swedish_Chess_Computer_Association#Rating_list_year-end_leaders",
                            "min_date": null,
                            "maxval": 3366,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 3366,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Komodo 9.1 MP x64 2GB Q6600 2.4 GHz",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Komodo 9.1 MP x64 2GB Q66..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-02-27",
                            "papername": "CCRL 40/40 - Index",
                            "value": 3393,
                            "url": "https://web.archive.org/web/20170227044521/http://www.computerchess.org.uk/ccrl/4040/",
                            "min_date": null,
                            "maxval": 3443,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Computer Chess)                                      SOLVED",
                            "minval": 3343,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 50,
                            "name": "Stockfish",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Stockfish"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 3632,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/strategy_games.py#L16",
                    "target_label": "Best human play",
                    "url": null,
                    "scale": "ELO rating",
                    "solved": true,
                    "axis_label": "ELO rating",
                    "name": "Computer Go",
                    "target_source": "https://www.goratings.org/en/history/",
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Playing abstract games with extensive hints)",
                    "measures": []
                }
            ],
            "subproblems": "<map object at 0x7f5a610cc940>",
            "url": null,
            "solved": true,
            "attributes": [
                "abstract-games"
            ]
        },
        {
            "name": "Language comprehension and question-answering",
            "superproblems": "<map object at 0x7f5a610ccb38>",
            "metrics": [
                {
                    "notes": "",
                    "target": 99,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L128",
                    "target_label": "Excellent performance",
                    "url": "http://fb.ai/babi",
                    "scale": "Percentage correct",
                    "solved": true,
                    "axis_label": "Percentage correct",
                    "name": "bAbi 20 QA (10k training examples)",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Language comprehension and question-answering)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-19",
                            "papername": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks",
                            "value": 93.3,
                            "url": "https://arxiv.org/abs/1502.05698v1",
                            "min_date": null,
                            "maxval": 93.3,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi 20 QA (10k training examples))                  SOLVED",
                            "minval": 93.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "MemNN-AM+NG+NL (1k + strong supervision)",
                            "long_label": true,
                            "not_directly_comparable": true,
                            "replicated_url": "",
                            "label": "MemNN-AM+NG+NL (1k + strong supervision)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-03-31",
                            "papername": "End-To-End Memory Networks",
                            "value": 93.4,
                            "url": "https://arxiv.org/abs/1503.08895",
                            "min_date": "2015-03-31",
                            "maxval": 93.4,
                            "max_date": "2015-11-24",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi 20 QA (10k training examples))                  SOLVED",
                            "minval": 93.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "MemN2N-PE+LS+RN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MemN2N-PE+LS+RN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-01-05",
                            "papername": null,
                            "value": 96.2,
                            "url": "https://www.gwern.net/docs/2016-graves.pdf",
                            "min_date": null,
                            "maxval": 96.2,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi 20 QA (10k training examples))                  SOLVED",
                            "minval": 96.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DNC",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DNC"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-06-30",
                            "papername": "Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes",
                            "value": 97.2,
                            "url": "https://arxiv.org/abs/1607.00036",
                            "min_date": "2016-06-30",
                            "maxval": 97.2,
                            "max_date": "2017-03-17",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi 20 QA (10k training examples))                  SOLVED",
                            "minval": 97.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DMN+",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DMN+"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-09-27",
                            "papername": "Query-Reduction Networks for Question Answering",
                            "value": 97.1,
                            "url": "https://arxiv.org/abs/1606.04582v4",
                            "min_date": null,
                            "maxval": 97.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi 20 QA (10k training examples))                  SOLVED",
                            "minval": 97.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SDNC",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SDNC"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-09",
                            "papername": "Query-Reduction Networks for Question Answering",
                            "value": 99.7,
                            "url": "https://arxiv.org/abs/1606.04582v4",
                            "min_date": null,
                            "maxval": 99.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi 20 QA (10k training examples))                  SOLVED",
                            "minval": 99.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "QRN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "QRN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-12",
                            "papername": "Tracking the World State with Recurrent Entity Networks",
                            "value": 99.5,
                            "url": "https://arxiv.org/abs/1612.03969",
                            "min_date": "2016-12-12",
                            "maxval": 99.5,
                            "max_date": "2017-05-10",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi 20 QA (10k training examples))                  SOLVED",
                            "minval": 99.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "EntNet",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "EntNet"
                        }
                    ]
                },
                {
                    "notes": "\nA synthetic environment inspired by text adventures and SHRDLU, which enables generation\nof ground truths, describing sentences, and inferential questions. Includes:\nsupporting facts, relations, yes/no questions, counting, lists/sets, negation, indefiniteness,\nconference, conjunction, time, basic deduction and induction, reasoning about position, size,\npath finding and motivation.\n\nTable 3 of https://arxiv.org/abs/1502.05698 actually breaks this down into 20 submeasures\nbut initially we're lumping all of this together.\n\nOriginally \"solving\" bABI was defined as 95% accuracy (or perhaps) 95% accuracy on all submeasures,\nbut clearly humans and now algorithms are better than that.\n\nTODO: bAbi really needs to be decomposed into semi-supervised and unsupervised variants, and \nby amount of training data provided\n",
                    "target": 99,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L127",
                    "target_label": "Excellent performance",
                    "url": "http://fb.ai/babi",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "bAbi 20 QA (1k training examples)",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Language comprehension and question-answering)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-03-31",
                            "papername": "End-To-End Memory Networks",
                            "value": 86.1,
                            "url": "https://arxiv.org/abs/1503.08895",
                            "min_date": "2015-03-31",
                            "maxval": 86.1,
                            "max_date": "2015-11-24",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi 20 QA (1k training examples))                   not solved",
                            "minval": 86.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "MemN2N-PE+LS+RN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MemN2N-PE+LS+RN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-06-24",
                            "papername": "Ask Me Anything: Dynamic Memory Networks for Natural Language Processing",
                            "value": 93.6,
                            "url": "https://arxiv.org/abs/1506.07285",
                            "min_date": "2015-06-24",
                            "maxval": 93.6,
                            "max_date": "2016-03-05",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi 20 QA (1k training examples))                   not solved",
                            "minval": 93.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DMN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DMN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-09",
                            "papername": "Query-Reduction Networks for Question Answering",
                            "value": 66.8,
                            "url": "https://arxiv.org/abs/1606.04582v4",
                            "min_date": "2016-06-30",
                            "maxval": 66.8,
                            "max_date": null,
                            "src_name": "Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes",
                            "algorithm_src_url": "https://arxiv.org/abs/1607.00036",
                            "metric": "Metric(bAbi 20 QA (1k training examples))                   not solved",
                            "minval": 66.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DMN+",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "https://github.com/therne/dmn-tensorflow",
                            "label": "DMN+"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-09",
                            "papername": "Query-Reduction Networks for Question Answering",
                            "value": 90.1,
                            "url": "https://arxiv.org/abs/1606.04582v4",
                            "min_date": null,
                            "maxval": 90.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi 20 QA (1k training examples))                   not solved",
                            "minval": 90.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "QRN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "QRN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-12",
                            "papername": "Tracking the World State with Recurrent Entity Networks",
                            "value": 89.1,
                            "url": "https://arxiv.org/abs/1612.03969",
                            "min_date": "2016-12-12",
                            "maxval": 89.1,
                            "max_date": "2017-05-10",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi 20 QA (1k training examples))                   not solved",
                            "minval": 89.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "EntNet",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "EntNet"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L138",
                    "target_label": null,
                    "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/MCTest_EMNLP2013.pdf",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "Reading comprehension MCTest-160-all",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Language comprehension and question-answering)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-10-01",
                            "papername": "MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text",
                            "value": 69.16,
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/MCTest_EMNLP2013.pdf",
                            "min_date": null,
                            "maxval": 69.16,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Reading comprehension MCTest-160-all)                ?",
                            "minval": 69.16,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SW+D+RTE",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SW+D+RTE"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-26",
                            "papername": "Machine Comprehension with Discourse Relations",
                            "value": 73.27,
                            "url": "https://people.csail.mit.edu/regina/my_papers/MCDR15.pdf",
                            "min_date": null,
                            "maxval": 73.27,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Reading comprehension MCTest-160-all)                ?",
                            "minval": 73.27,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Narasimhan-model3",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Narasimhan-model3"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-26",
                            "papername": "A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data",
                            "value": 75.27,
                            "url": "https://arxiv.org/abs/1603.08884",
                            "min_date": null,
                            "maxval": 75.27,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Reading comprehension MCTest-160-all)                ?",
                            "minval": 75.27,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Wang-et-al",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Wang-et-al"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-03-29",
                            "papername": "A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data",
                            "value": 74.58,
                            "url": "https://arxiv.org/abs/1603.08884",
                            "min_date": null,
                            "maxval": 74.58,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Reading comprehension MCTest-160-all)                ?",
                            "minval": 74.58,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Parallel-Hierarchical",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Parallel-Hierarchical"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L145",
                    "target_label": null,
                    "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/MCTest_EMNLP2013.pdf",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "Reading comprehension MCTest-500-all",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Language comprehension and question-answering)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-10-01",
                            "papername": "MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text",
                            "value": 63.33,
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/MCTest_EMNLP2013.pdf",
                            "min_date": null,
                            "maxval": 63.33,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Reading comprehension MCTest-500-all)                ?",
                            "minval": 63.33,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SW+D+RTE",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SW+D+RTE"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-26",
                            "papername": "Machine Comprehension with Discourse Relations",
                            "value": 63.75,
                            "url": "https://people.csail.mit.edu/regina/my_papers/MCDR15.pdf",
                            "min_date": null,
                            "maxval": 63.75,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Reading comprehension MCTest-500-all)                ?",
                            "minval": 63.75,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Narasimhan-model3",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Narasimhan-model3"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-26",
                            "papername": "Learning Answer-Entailing Structures for Machine Comprehension",
                            "value": 67.83,
                            "url": "https://pdfs.semanticscholar.org/f26e/088bc4659a9b7fce28b6604d26de779bcf93.pdf",
                            "min_date": null,
                            "maxval": 67.83,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Reading comprehension MCTest-500-all)                ?",
                            "minval": 67.83,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "LSSVM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "LSSVM"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-26",
                            "papername": "A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data",
                            "value": 69.94,
                            "url": "https://arxiv.org/abs/1603.08884",
                            "min_date": null,
                            "maxval": 69.94,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Reading comprehension MCTest-500-all)                ?",
                            "minval": 69.94,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Wang-et-al",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Wang-et-al"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-03-29",
                            "papername": "A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data",
                            "value": 71.0,
                            "url": "https://arxiv.org/abs/1603.08884",
                            "min_date": null,
                            "maxval": 71.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Reading comprehension MCTest-500-all)                ?",
                            "minval": 71.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Parallel-Hierarchical",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Parallel-Hierarchical"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 81.6,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L194",
                    "target_label": null,
                    "url": "http://fb.ai/babi",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "bAbi Children's Book comprehension CBtest NE",
                    "target_source": "https://arxiv.org/abs/1511.02301",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Language comprehension and question-answering)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-03-04",
                            "papername": "Text Understanding with the Attention Sum Reader Network",
                            "value": 70.6,
                            "url": "https://arxiv.org/abs/1603.01547v1",
                            "min_date": null,
                            "maxval": 70.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved",
                            "minval": 70.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "AS reader (avg)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "AS reader (avg)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-03-04",
                            "papername": "Text Understanding with the Attention Sum Reader Network",
                            "value": 71.0,
                            "url": "https://arxiv.org/abs/1603.01547v1",
                            "min_date": null,
                            "maxval": 71.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved",
                            "minval": 71.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "AS reader (greedy)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "AS reader (greedy)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-06-05",
                            "papername": "Gated-Attention Readers for Text Comprehension",
                            "value": 71.9,
                            "url": "https://arxiv.org/abs/1606.01549v1",
                            "min_date": null,
                            "maxval": 71.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved",
                            "minval": 71.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "GA reader",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "GA reader"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-06-07",
                            "papername": "Natural Language Comprehension with the EpiReader",
                            "value": 69.7,
                            "url": "https://arxiv.org/abs/1606.02270",
                            "min_date": "2016-06-07",
                            "maxval": 69.7,
                            "max_date": "2016-06-10",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved",
                            "minval": 69.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "EpiReader",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "EpiReader"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-06-07",
                            "papername": "Iterative Alternating Neural Attention for Machine Reading",
                            "value": 71.0,
                            "url": "https://arxiv.org/abs/1606.02245v1",
                            "min_date": null,
                            "maxval": 71.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved",
                            "minval": 71.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "AIA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "AIA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-06-07",
                            "papername": "Iterative Alternating Neural Attention for Machine Reading",
                            "value": 72.0,
                            "url": "https://arxiv.org/abs/1606.02245v1",
                            "min_date": null,
                            "maxval": 72.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved",
                            "minval": 72.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "AIA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "AIA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-08-04",
                            "papername": "Attention-over-Attention Neural Networks for Reading Comprehension",
                            "value": 72.0,
                            "url": "https://arxiv.org/abs/1607.04423",
                            "min_date": "2016-07-15",
                            "maxval": 72.0,
                            "max_date": "2017-06-06",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved",
                            "minval": 72.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "AoA reader",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "AoA reader"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-01",
                            "papername": "Gated-Attention Readers for Text Comprehension",
                            "value": 73.2,
                            "url": "https://arxiv.org/abs/1606.01549v2",
                            "min_date": "2016-07-04",
                            "maxval": 73.2,
                            "max_date": null,
                            "src_name": "Neural Semantic Encoders",
                            "algorithm_src_url": "https://arxiv.org/abs/1607.04315",
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved",
                            "minval": 73.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "NSE",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "NSE"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-01",
                            "papername": "Gated-Attention Readers for Text Comprehension",
                            "value": 74.9,
                            "url": "https://arxiv.org/abs/1606.01549v2",
                            "min_date": null,
                            "maxval": 74.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi Children's Book comprehension CBtest NE)        not solved",
                            "minval": 74.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "GA +feature, fix L(w)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "GA +feature, fix L(w)"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 81.6,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L196",
                    "target_label": null,
                    "url": "http://fb.ai/babi",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "bAbi Children's Book comprehension CBtest CN",
                    "target_source": "https://arxiv.org/abs/1511.02301",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Language comprehension and question-answering)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-03-04",
                            "papername": "Text Understanding with the Attention Sum Reader Network",
                            "value": 67.5,
                            "url": "https://arxiv.org/abs/1603.01547v1",
                            "min_date": null,
                            "maxval": 67.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi Children's Book comprehension CBtest CN)        not solved",
                            "minval": 67.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "AS reader (greedy)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "AS reader (greedy)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-03-04",
                            "papername": "Text Understanding with the Attention Sum Reader Network",
                            "value": 68.9,
                            "url": "https://arxiv.org/abs/1603.01547v1",
                            "min_date": null,
                            "maxval": 68.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi Children's Book comprehension CBtest CN)        not solved",
                            "minval": 68.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "AS reader (avg)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "AS reader (avg)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-06-05",
                            "papername": "Gated-Attention Readers for Text Comprehension",
                            "value": 69.4,
                            "url": "https://arxiv.org/abs/1606.01549v1",
                            "min_date": null,
                            "maxval": 69.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi Children's Book comprehension CBtest CN)        not solved",
                            "minval": 69.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "GA reader",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "GA reader"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-06-07",
                            "papername": "Natural Language Comprehension with the EpiReader",
                            "value": 67.4,
                            "url": "https://arxiv.org/abs/1606.02270",
                            "min_date": "2016-06-07",
                            "maxval": 67.4,
                            "max_date": "2016-06-10",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi Children's Book comprehension CBtest CN)        not solved",
                            "minval": 67.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "EpiReader",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "EpiReader"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-08-04",
                            "papername": "Attention-over-Attention Neural Networks for Reading Comprehension",
                            "value": 69.4,
                            "url": "https://arxiv.org/abs/1607.04423",
                            "min_date": "2016-07-15",
                            "maxval": 69.4,
                            "max_date": "2017-06-06",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi Children's Book comprehension CBtest CN)        not solved",
                            "minval": 69.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "AoA reader",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "AoA reader"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-01",
                            "papername": "Gated-Attention Readers for Text Comprehension",
                            "value": 70.7,
                            "url": "https://arxiv.org/abs/1606.01549v2",
                            "min_date": null,
                            "maxval": 70.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(bAbi Children's Book comprehension CBtest CN)        not solved",
                            "minval": 70.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "GA +feature, fix L(w)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "GA +feature, fix L(w)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-01",
                            "papername": "Gated-Attention Readers for Text Comprehension",
                            "value": 71.9,
                            "url": "https://arxiv.org/abs/1606.01549v2",
                            "min_date": "2016-07-04",
                            "maxval": 71.9,
                            "max_date": null,
                            "src_name": "Neural Semantic Encoders",
                            "algorithm_src_url": "https://arxiv.org/abs/1607.04315",
                            "metric": "Metric(bAbi Children's Book comprehension CBtest CN)        not solved",
                            "minval": 71.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "NSE",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "NSE"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L190",
                    "target_label": null,
                    "url": "https://github.com/deepmind/rc-data/",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "CNN Comprehension test",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Language comprehension and question-answering)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-06-10",
                            "papername": "Teaching Machines to Read and Comprehend",
                            "value": 63.0,
                            "url": "https://arxiv.org/abs/1506.03340",
                            "min_date": "2015-06-10",
                            "maxval": 63.0,
                            "max_date": "2015-11-19",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CNN Comprehension test)                              ?",
                            "minval": 63.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Attentive reader",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Attentive reader"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-06-10",
                            "papername": "Teaching Machines to Read and Comprehend",
                            "value": 63.8,
                            "url": "https://arxiv.org/abs/1506.03340",
                            "min_date": "2015-06-10",
                            "maxval": 63.8,
                            "max_date": "2015-11-19",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CNN Comprehension test)                              ?",
                            "minval": 63.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Impatient reader",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Impatient reader"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-03-04",
                            "papername": "Text Understanding with the Attention Sum Reader Network",
                            "value": 74.8,
                            "url": "https://arxiv.org/abs/1603.01547v1",
                            "min_date": null,
                            "maxval": 74.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CNN Comprehension test)                              ?",
                            "minval": 74.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "AS reader (greedy)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "AS reader (greedy)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-03-04",
                            "papername": "Text Understanding with the Attention Sum Reader Network",
                            "value": 75.4,
                            "url": "https://arxiv.org/abs/1603.01547v1",
                            "min_date": null,
                            "maxval": 75.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CNN Comprehension test)                              ?",
                            "minval": 75.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "AS reader (avg)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "AS reader (avg)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-06-05",
                            "papername": "Gated-Attention Readers for Text Comprehension",
                            "value": 77.4,
                            "url": "https://arxiv.org/abs/1606.01549v1",
                            "min_date": null,
                            "maxval": 77.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CNN Comprehension test)                              ?",
                            "minval": 77.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "GA reader",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "GA reader"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-06-07",
                            "papername": "Natural Language Comprehension with the EpiReader",
                            "value": 74.0,
                            "url": "https://arxiv.org/abs/1606.02270",
                            "min_date": "2016-06-07",
                            "maxval": 74.0,
                            "max_date": "2016-06-10",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CNN Comprehension test)                              ?",
                            "minval": 74.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "EpiReader",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "EpiReader"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-06-07",
                            "papername": "Iterative Alternating Neural Attention for Machine Reading",
                            "value": 75.7,
                            "url": "https://arxiv.org/abs/1606.02245v1",
                            "min_date": null,
                            "maxval": 75.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CNN Comprehension test)                              ?",
                            "minval": 75.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "AIA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "AIA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-08-04",
                            "papername": "Attention-over-Attention Neural Networks for Reading Comprehension",
                            "value": 74.4,
                            "url": "https://arxiv.org/abs/1607.04423",
                            "min_date": "2016-07-15",
                            "maxval": 74.4,
                            "max_date": "2017-06-06",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CNN Comprehension test)                              ?",
                            "minval": 74.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "AoA reader",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "AoA reader"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-08-08",
                            "papername": "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task",
                            "value": 77.6,
                            "url": "https://arxiv.org/abs/1606.02858",
                            "min_date": "2016-06-09",
                            "maxval": 77.6,
                            "max_date": "2016-08-08",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CNN Comprehension test)                              ?",
                            "minval": 77.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Attentive+relabling+ensemble",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Attentive+relabling+ensem..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-11-09",
                            "papername": "Iterative Alternating Neural Attention for Machine Reading",
                            "value": 76.1,
                            "url": "https://arxiv.org/abs/1606.02245v4",
                            "min_date": null,
                            "maxval": 76.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CNN Comprehension test)                              ?",
                            "minval": 76.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "AIA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "AIA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-01",
                            "papername": "Gated-Attention Readers for Text Comprehension",
                            "value": 77.9,
                            "url": "https://arxiv.org/abs/1606.01549v2",
                            "min_date": null,
                            "maxval": 77.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(CNN Comprehension test)                              ?",
                            "minval": 77.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "GA update L(w)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "GA update L(w)"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L192",
                    "target_label": null,
                    "url": "https://github.com/deepmind/rc-data/",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "Daily Mail Comprehension test",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Language comprehension and question-answering)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-06-10",
                            "papername": "Teaching Machines to Read and Comprehend",
                            "value": 68.0,
                            "url": "https://arxiv.org/abs/1506.03340",
                            "min_date": "2015-06-10",
                            "maxval": 68.0,
                            "max_date": "2015-11-19",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Daily Mail Comprehension test)                       ?",
                            "minval": 68.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Impatient reader",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Impatient reader"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-06-10",
                            "papername": "Teaching Machines to Read and Comprehend",
                            "value": 69.0,
                            "url": "https://arxiv.org/abs/1506.03340",
                            "min_date": "2015-06-10",
                            "maxval": 69.0,
                            "max_date": "2015-11-19",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Daily Mail Comprehension test)                       ?",
                            "minval": 69.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Attentive reader",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Attentive reader"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-03-04",
                            "papername": "Text Understanding with the Attention Sum Reader Network",
                            "value": 77.1,
                            "url": "https://arxiv.org/abs/1603.01547v1",
                            "min_date": null,
                            "maxval": 77.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Daily Mail Comprehension test)                       ?",
                            "minval": 77.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "AS reader (avg)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "AS reader (avg)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-03-04",
                            "papername": "Text Understanding with the Attention Sum Reader Network",
                            "value": 77.7,
                            "url": "https://arxiv.org/abs/1603.01547v1",
                            "min_date": null,
                            "maxval": 77.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Daily Mail Comprehension test)                       ?",
                            "minval": 77.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "AS reader (greedy)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "AS reader (greedy)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-06-05",
                            "papername": "Gated-Attention Readers for Text Comprehension",
                            "value": 78.1,
                            "url": "https://arxiv.org/abs/1606.01549v1",
                            "min_date": null,
                            "maxval": 78.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Daily Mail Comprehension test)                       ?",
                            "minval": 78.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "GA reader",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "GA reader"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-08-08",
                            "papername": "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task",
                            "value": 79.2,
                            "url": "https://arxiv.org/abs/1606.02858",
                            "min_date": "2016-06-09",
                            "maxval": 79.2,
                            "max_date": "2016-08-08",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Daily Mail Comprehension test)                       ?",
                            "minval": 79.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Attentive+relabling+ensemble",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Attentive+relabling+ensem..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-01",
                            "papername": "Gated-Attention Readers for Text Comprehension",
                            "value": 80.9,
                            "url": "https://arxiv.org/abs/1606.01549v2",
                            "min_date": null,
                            "maxval": 80.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Daily Mail Comprehension test)                       ?",
                            "minval": 80.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "GA update L(w)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "GA update L(w)"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L258",
                    "target_label": null,
                    "url": "https://stanford-qa.com/",
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Stanford Question Answering Dataset EM test",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Language comprehension and question-answering)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-11-04",
                            "papername": "Dynamic Coattention Networks For Question Answering",
                            "value": 66.233,
                            "url": "https://arxiv.org/abs/1611.01604v1",
                            "min_date": null,
                            "maxval": 66.233,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 66.233,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Dynamic Coattention Networks (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Dynamic Coattention Netwo..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-11-04",
                            "papername": "Dynamic Coattention Networks For Question Answering",
                            "value": 71.625,
                            "url": "https://arxiv.org/abs/1611.01604v1",
                            "min_date": null,
                            "maxval": 71.625,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 71.625,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Dynamic Coattention Networks (ensemble)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Dynamic Coattention Netwo..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-11-07",
                            "papername": "Machine Comprehension Using Match-LSTM and Answer Pointer",
                            "value": 67.901,
                            "url": "https://arxiv.org/abs/1608.07905v2",
                            "min_date": null,
                            "maxval": 67.901,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 67.901,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Match-LSTM+Ans-Ptr",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Match-LSTM+Ans-Ptr"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-11-29",
                            "papername": "Bidirectional Attention Flow for Machine Comprehension",
                            "value": 68.478,
                            "url": "https://arxiv.org/abs/1611.01603",
                            "min_date": "2016-11-05",
                            "maxval": 68.478,
                            "max_date": "2017-02-24",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 68.478,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "BiDAF (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "BiDAF (single model)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-13",
                            "papername": "Multi-Perspective Context Matching for Machine Comprehension",
                            "value": 70.387,
                            "url": "https://arxiv.org/abs/1612.04211",
                            "min_date": null,
                            "maxval": 70.387,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 70.387,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "MPM (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MPM (single model)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-13",
                            "papername": "Multi-Perspective Context Matching for Machine Comprehension",
                            "value": 73.765,
                            "url": "https://arxiv.org/abs/1612.04211",
                            "min_date": null,
                            "maxval": 73.765,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 73.765,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "MPM (ensemble)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MPM (ensemble)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-29",
                            "papername": "Making Neural QA as Simple as Possible but not Simpler",
                            "value": 68.436,
                            "url": "https://arxiv.org/abs/1703.04816",
                            "min_date": "2017-03-14",
                            "maxval": 68.436,
                            "max_date": "2017-06-08",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 68.436,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "FastQA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "FastQA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-29",
                            "papername": "Making Neural QA as Simple as Possible but not Simpler",
                            "value": 70.849,
                            "url": "https://arxiv.org/abs/1703.04816",
                            "min_date": "2017-03-14",
                            "maxval": 70.849,
                            "max_date": "2017-06-08",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 70.849,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "FastQAExt",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "FastQAExt"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-02-24",
                            "papername": "Bidirectional Attention Flow for Machine Comprehension",
                            "value": 73.744,
                            "url": "https://arxiv.org/abs/1611.01603",
                            "min_date": "2016-11-05",
                            "maxval": 73.744,
                            "max_date": "2017-02-24",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 73.744,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "BiDAF (ensemble)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "BiDAF (ensemble)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-08",
                            "papername": null,
                            "value": 74.614,
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf",
                            "min_date": null,
                            "maxval": 74.614,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 74.614,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "r-net (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "r-net (single model)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-08",
                            "papername": null,
                            "value": 76.922,
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf",
                            "min_date": null,
                            "maxval": 76.922,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 76.922,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "r-net (ensemble)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "r-net (ensemble)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-31",
                            "papername": "Reading Wikipedia to Answer Open-Domain Questions",
                            "value": 70.733,
                            "url": "https://arxiv.org/abs/1704.00051",
                            "min_date": "2017-03-31",
                            "maxval": 70.733,
                            "max_date": "2017-04-28",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 70.733,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Document Reader (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Document Reader (single m..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-04-20",
                            "papername": "Structural Embedding of Syntactic Trees for Machine Comprehension",
                            "value": 68.478,
                            "url": "https://arxiv.org/abs/1703.00572",
                            "min_date": "2017-03-02",
                            "maxval": 68.478,
                            "max_date": "2017-04-20",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 68.478,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SEDT+BiDAF (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SEDT+BiDAF (single model)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-04-20",
                            "papername": "Structural Embedding of Syntactic Trees for Machine Comprehension",
                            "value": 73.723,
                            "url": "https://arxiv.org/abs/1703.00572",
                            "min_date": "2017-03-02",
                            "maxval": 73.723,
                            "max_date": "2017-04-20",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 73.723,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SEDT+BiDAF (ensemble)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SEDT+BiDAF (ensemble)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-04-24",
                            "papername": "Ruminating Reader: Reasoning with Gated Multi-Hop Attention",
                            "value": 70.639,
                            "url": "https://arxiv.org/abs/1704.07415",
                            "min_date": null,
                            "maxval": 70.639,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 70.639,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Ruminating Reader (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Ruminating Reader (single..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-05-08",
                            "papername": "Mnemonic Reader for Machine Comprehension",
                            "value": 69.863,
                            "url": "https://arxiv.org/abs/1705.02798",
                            "min_date": null,
                            "maxval": 69.863,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 69.863,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Mnemonic reader (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Mnemonic reader (single m..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-05-08",
                            "papername": "Mnemonic Reader for Machine Comprehension",
                            "value": 73.754,
                            "url": "https://arxiv.org/abs/1705.02798",
                            "min_date": null,
                            "maxval": 73.754,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 73.754,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Mnemonic reader (ensemble)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Mnemonic reader (ensemble)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-05-31",
                            "papername": "Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering",
                            "value": 70.607,
                            "url": "https://arxiv.org/abs/1703.04617",
                            "min_date": "2017-05-01",
                            "maxval": 70.607,
                            "max_date": "2017-03-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 70.607,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "jNet (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "jNet (single model)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-05-31",
                            "papername": "Learning Recurrent Span Representations for Extractive Question Answering",
                            "value": 70.849,
                            "url": "https://arxiv.org/abs/1611.01436",
                            "min_date": "2017-05-01",
                            "maxval": 70.849,
                            "max_date": "2017-03-17",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 70.849,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "RaSoR (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RaSoR (single model)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-05-31",
                            "papername": "Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering",
                            "value": 73.01,
                            "url": "https://arxiv.org/abs/1703.04617",
                            "min_date": "2017-05-01",
                            "maxval": 73.01,
                            "max_date": "2017-03-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset EM test)         ?",
                            "minval": 73.01,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "jNet (ensemble)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "jNet (ensemble)"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L259",
                    "target_label": null,
                    "url": "https://stanford-qa.com/",
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Stanford Question Answering Dataset F1 test",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Language comprehension and question-answering)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-11-04",
                            "papername": "Dynamic Coattention Networks For Question Answering",
                            "value": 75.896,
                            "url": "https://arxiv.org/abs/1611.01604v1",
                            "min_date": null,
                            "maxval": 75.896,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 75.896,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Dynamic Coattention Networks (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Dynamic Coattention Netwo..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-11-04",
                            "papername": "Dynamic Coattention Networks For Question Answering",
                            "value": 80.383,
                            "url": "https://arxiv.org/abs/1611.01604v1",
                            "min_date": null,
                            "maxval": 80.383,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 80.383,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Dynamic Coattention Networks (ensemble)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Dynamic Coattention Netwo..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-11-07",
                            "papername": "Machine Comprehension Using Match-LSTM and Answer Pointer",
                            "value": 77.022,
                            "url": "https://arxiv.org/abs/1608.07905v2",
                            "min_date": null,
                            "maxval": 77.022,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 77.022,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Match-LSTM+Ans-Ptr",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Match-LSTM+Ans-Ptr"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-11-29",
                            "papername": "Bidirectional Attention Flow for Machine Comprehension",
                            "value": 77.971,
                            "url": "https://arxiv.org/abs/1611.01603",
                            "min_date": "2016-11-05",
                            "maxval": 77.971,
                            "max_date": "2017-02-24",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 77.971,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "BiDAF (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "BiDAF (single model)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-13",
                            "papername": "Multi-Perspective Context Matching for Machine Comprehension",
                            "value": 78.784,
                            "url": "https://arxiv.org/abs/1612.04211",
                            "min_date": null,
                            "maxval": 78.784,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 78.784,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "MPM (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MPM (single model)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-13",
                            "papername": "Multi-Perspective Context Matching for Machine Comprehension",
                            "value": 81.257,
                            "url": "https://arxiv.org/abs/1612.04211",
                            "min_date": null,
                            "maxval": 81.257,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 81.257,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "MPM (ensemble)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MPM (ensemble)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-29",
                            "papername": "Making Neural QA as Simple as Possible but not Simpler",
                            "value": 77.07,
                            "url": "https://arxiv.org/abs/1703.04816",
                            "min_date": "2017-03-14",
                            "maxval": 77.07,
                            "max_date": "2017-06-08",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 77.07,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "FastQA",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "FastQA"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-12-29",
                            "papername": "Making Neural QA as Simple as Possible but not Simpler",
                            "value": 78.857,
                            "url": "https://arxiv.org/abs/1703.04816",
                            "min_date": "2017-03-14",
                            "maxval": 78.857,
                            "max_date": "2017-06-08",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 78.857,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "FastQAExt",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "FastQAExt"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-02-24",
                            "papername": "Bidirectional Attention Flow for Machine Comprehension",
                            "value": 81.525,
                            "url": "https://arxiv.org/abs/1611.01603",
                            "min_date": "2016-11-05",
                            "maxval": 81.525,
                            "max_date": "2017-02-24",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 81.525,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "BiDAF (ensemble)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "BiDAF (ensemble)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-08",
                            "papername": null,
                            "value": 82.458,
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf",
                            "min_date": null,
                            "maxval": 82.458,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 82.458,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "r-net (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "r-net (single model)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-08",
                            "papername": null,
                            "value": 84.006,
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf",
                            "min_date": null,
                            "maxval": 84.006,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 84.006,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "r-net (ensemble)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "r-net (ensemble)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-31",
                            "papername": "Reading Wikipedia to Answer Open-Domain Questions",
                            "value": 79.353,
                            "url": "https://arxiv.org/abs/1704.00051",
                            "min_date": "2017-03-31",
                            "maxval": 79.353,
                            "max_date": "2017-04-28",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 79.353,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Document Reader (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Document Reader (single m..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-04-20",
                            "papername": "Structural Embedding of Syntactic Trees for Machine Comprehension",
                            "value": 77.971,
                            "url": "https://arxiv.org/abs/1703.00572",
                            "min_date": "2017-03-02",
                            "maxval": 77.971,
                            "max_date": "2017-04-20",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 77.971,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SEDT+BiDAF (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SEDT+BiDAF (single model)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-04-20",
                            "papername": "Structural Embedding of Syntactic Trees for Machine Comprehension",
                            "value": 81.53,
                            "url": "https://arxiv.org/abs/1703.00572",
                            "min_date": "2017-03-02",
                            "maxval": 81.53,
                            "max_date": "2017-04-20",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 81.53,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SEDT+BiDAF (ensemble)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SEDT+BiDAF (ensemble)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-04-24",
                            "papername": "Ruminating Reader: Reasoning with Gated Multi-Hop Attention",
                            "value": 79.821,
                            "url": "https://arxiv.org/abs/1704.07415",
                            "min_date": null,
                            "maxval": 79.821,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 79.821,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Ruminating Reader (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Ruminating Reader (single..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-05-08",
                            "papername": "Mnemonic Reader for Machine Comprehension",
                            "value": 79.207,
                            "url": "https://arxiv.org/abs/1705.02798",
                            "min_date": null,
                            "maxval": 79.207,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 79.207,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Mnemonic reader (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Mnemonic reader (single m..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-05-08",
                            "papername": "Mnemonic Reader for Machine Comprehension",
                            "value": 81.863,
                            "url": "https://arxiv.org/abs/1705.02798",
                            "min_date": null,
                            "maxval": 81.863,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 81.863,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Mnemonic reader (ensemble)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Mnemonic reader (ensemble)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-05-31",
                            "papername": "Learning Recurrent Span Representations for Extractive Question Answering",
                            "value": 78.741,
                            "url": "https://arxiv.org/abs/1611.01436",
                            "min_date": "2017-05-01",
                            "maxval": 78.741,
                            "max_date": "2017-03-17",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 78.741,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "RaSoR (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RaSoR (single model)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-05-31",
                            "papername": "Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering",
                            "value": 79.456,
                            "url": "https://arxiv.org/abs/1703.04617",
                            "min_date": "2017-05-01",
                            "maxval": 79.456,
                            "max_date": "2017-03-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 79.456,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "jNet (single model)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "jNet (single model)"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-05-31",
                            "papername": "Exploring Question Understanding and Adaptation in Neural-Network-Based Question Answering",
                            "value": 81.517,
                            "url": "https://arxiv.org/abs/1703.04617",
                            "min_date": "2017-05-01",
                            "maxval": 81.517,
                            "max_date": "2017-03-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Stanford Question Answering Dataset F1 test)         ?",
                            "minval": 81.517,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "jNet (ensemble)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "jNet (ensemble)"
                        }
                    ]
                }
            ],
            "subproblems": "<map object at 0x7f5a610cceb8>",
            "url": null,
            "solved": false,
            "attributes": [
                "language",
                "world-modelling",
                "agi"
            ]
        },
        {
            "name": "Games that require both understanding and speaking a language",
            "superproblems": "<map object at 0x7f5a610cccc0>",
            "metrics": [
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/video_games.py#L10",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "Starcraft",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Games that require both understanding and speaking a language)",
                    "measures": []
                }
            ],
            "subproblems": "<map object at 0x7f5a610ccf28>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "name": "Learn a several tasks without undermining performance on a first task, avoiding catastrophic forgetting",
            "superproblems": "<map object at 0x7f5a610cc748>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a610cc5f8>",
            "url": "https://arxiv.org/abs/1612.00796",
            "solved": false,
            "attributes": []
        },
        {
            "notes": "\nSometimes, even doing something once is catastrophic. In such situations, how can an RL agent or some other AI system\nlearn about the catastrophic consequences without even taking the action once? This is an ability that most humans acquire\nat some point between childhood and adolescence.\n",
            "name": "Safe exploration",
            "superproblems": "<map object at 0x7f5a610ccbe0>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a610cc2e8>",
            "url": "https://arxiv.org/abs/1606.06565",
            "solved": false,
            "attributes": [
                "safety",
                "agi",
                "world-modelling"
            ]
        },
        {
            "name": "Solve vaguely or under-constrained technical problems",
            "superproblems": "<map object at 0x7f5a610cce80>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a610cc278>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "name": "Speech Recognition",
            "superproblems": "<map object at 0x7f5a610cc978>",
            "metrics": [
                {
                    "notes": "",
                    "target": 5.9,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/acoustics.py#L41",
                    "target_label": null,
                    "url": null,
                    "scale": "Percentage error",
                    "solved": true,
                    "axis_label": "Percentage error",
                    "name": "Word error rate on Switchboard trained against the Hub5'00 dataset",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/acoustics.py",
                    "parent": "Problem(Speech Recognition)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2011-08-31",
                            "papername": null,
                            "value": 16.1,
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/CD-DNN-HMM-SWB-Interspeech2011-Pub.pdf",
                            "min_date": null,
                            "maxval": 16.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED",
                            "minval": 16.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "CD-DNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CD-DNN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-04-27",
                            "papername": null,
                            "value": 18.5,
                            "url": "https://pdfs.semanticscholar.org/ce25/00257fda92338ec0a117bea1dbc0381d7c73.pdf?_ga=1.195375081.452266805.1483390947",
                            "min_date": null,
                            "maxval": 18.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED",
                            "minval": 18.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DNN-HMM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DNN-HMM"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-08-25",
                            "papername": null,
                            "value": 12.6,
                            "url": "http://www.danielpovey.com/files/2013_interspeech_dnn.pdf",
                            "min_date": null,
                            "maxval": 12.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED",
                            "minval": 12.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DNN sMBR",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DNN sMBR"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-08-25",
                            "papername": null,
                            "value": 12.9,
                            "url": "http://www.danielpovey.com/files/2013_interspeech_dnn.pdf",
                            "min_date": null,
                            "maxval": 12.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED",
                            "minval": 12.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DNN MMI",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DNN MMI"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-08-25",
                            "papername": null,
                            "value": 12.9,
                            "url": "http://www.danielpovey.com/files/2013_interspeech_dnn.pdf",
                            "min_date": null,
                            "maxval": 12.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED",
                            "minval": 12.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DNN MPE",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DNN MPE"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-08-25",
                            "papername": null,
                            "value": 12.9,
                            "url": "http://www.danielpovey.com/files/2013_interspeech_dnn.pdf",
                            "min_date": null,
                            "maxval": 12.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED",
                            "minval": 12.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DNN BMMI",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DNN BMMI"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-06-30",
                            "papername": "Increasing Deep Neural Network Acoustic Model Size for Large Vocabulary Continuous Speech Recognition",
                            "value": 16,
                            "url": "https://arxiv.org/abs/1406.7806v1",
                            "min_date": null,
                            "maxval": 16,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED",
                            "minval": 16,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "DNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "DNN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-12-07",
                            "papername": "Deep Speech: Scaling up end-to-end speech recognition",
                            "value": 12.6,
                            "url": "https://arxiv.org/abs/1412.5567",
                            "min_date": "2014-12-17",
                            "maxval": 12.6,
                            "max_date": "2014-12-19",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED",
                            "minval": 12.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Deep Speech + FSH",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep Speech + FSH"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-12-07",
                            "papername": "Deep Speech: Scaling up end-to-end speech recognition",
                            "value": 20,
                            "url": "https://arxiv.org/abs/1412.5567",
                            "min_date": "2014-12-17",
                            "maxval": 20,
                            "max_date": "2014-12-19",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED",
                            "minval": 20,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Deep Speech",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep Speech"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-05-21",
                            "papername": "The IBM 2015 English Conversational Telephone Speech Recognition System",
                            "value": 8.0,
                            "url": "https://arxiv.org/abs/1505.05899",
                            "min_date": null,
                            "maxval": 8.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED",
                            "minval": 8.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "IBM 2015",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "IBM 2015"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-04-27",
                            "papername": "The IBM 2016 English Conversational Telephone Speech Recognition System",
                            "value": 6.9,
                            "url": "https://arxiv.org/abs/1604.08242v1",
                            "min_date": null,
                            "maxval": 6.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED",
                            "minval": 6.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "IBM 2016",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "IBM 2016"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-10-17",
                            "papername": "Achieving Human Parity in Conversational Speech Recognition",
                            "value": 5.9,
                            "url": "https://arxiv.org/abs/1610.05256",
                            "min_date": "2016-10-17",
                            "maxval": 5.9,
                            "max_date": "2017-02-17",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED",
                            "minval": 5.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "CNN-LSTM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CNN-LSTM"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-10-17",
                            "papername": "Achieving Human Parity in Conversational Speech Recognition",
                            "value": 6.6,
                            "url": "https://arxiv.org/abs/1610.05256",
                            "min_date": "2016-10-17",
                            "maxval": 6.6,
                            "max_date": "2017-02-17",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED",
                            "minval": 6.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "CNN-LSTM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "CNN-LSTM"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-02-17",
                            "papername": "The Microsoft 2016 Conversational Speech Recognition System",
                            "value": 6.2,
                            "url": "https://arxiv.org/abs/1609.03528",
                            "min_date": "2016-09-12",
                            "maxval": 6.2,
                            "max_date": "2017-01-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED",
                            "minval": 6.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Microsoft 2016",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Microsoft 2016"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-02-17",
                            "papername": "The Microsoft 2016 Conversational Speech Recognition System",
                            "value": 6.9,
                            "url": "https://arxiv.org/abs/1609.03528",
                            "min_date": "2016-09-12",
                            "maxval": 6.9,
                            "max_date": "2017-01-25",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Word error rate on Switchboard trained against the Hub5'00 dataset)SOLVED",
                            "minval": 6.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "RNNLM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RNNLM"
                        }
                    ]
                }
            ],
            "subproblems": "<map object at 0x7f5a610cc9b0>",
            "url": null,
            "solved": true,
            "attributes": [
                "language",
                "agi"
            ]
        },
        {
            "name": "Function correctly in novel environments (robustness to distributional change)",
            "superproblems": "<map object at 0x7f5a610ccef0>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a610ccb70>",
            "url": "https://arxiv.org/abs/1606.06565",
            "solved": false,
            "attributes": [
                "safety",
                "agi"
            ]
        },
        {
            "name": "Solve technical problems with clear constraints (proofs, circuit design, aerofoil design, etc)",
            "superproblems": "<map object at 0x7f5a610cc518>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a610ccc88>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "name": "Read a scientific or technical paper, and comprehend its contents",
            "superproblems": "<map object at 0x7f5a610cc588>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a610cc080>",
            "url": null,
            "solved": false,
            "attributes": [
                "language",
                "world-modelling",
                "super"
            ]
        },
        {
            "name": "Scalable supervision of a learning system",
            "superproblems": "<map object at 0x7f5a610cc2b0>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a610cc7f0>",
            "url": "https://arxiv.org/abs/1606.06565",
            "solved": false,
            "attributes": [
                "safety",
                "agi"
            ]
        },
        {
            "name": "Translation between human langauges",
            "superproblems": "<map object at 0x7f5a610cc0b8>",
            "metrics": [
                {
                    "notes": "",
                    "target": 50,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L288",
                    "target_label": "Identical to professional human translations",
                    "url": "http://aclweb.org/anthology/P/P02/P02-1040.pdf",
                    "scale": "BLEU score",
                    "solved": false,
                    "axis_label": "BLEU score",
                    "name": "news-test-2014 En-Fr BLEU",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Translation between human langauges)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-02-24",
                            "papername": "Edinburgh\u2019s phrase-based machine translation systems for WMT-14",
                            "value": 37,
                            "url": "http://www.anthology.aclweb.org/W/W14/W14-33.pdf",
                            "min_date": null,
                            "maxval": 37,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved",
                            "minval": 37,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "PBMT",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "PBMT"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-09-01",
                            "papername": "Neural Machine Translation by Jointly Learning to Align and Translate",
                            "value": 36.15,
                            "url": "https://arxiv.org/abs/1409.0473",
                            "min_date": "2014-09-01",
                            "maxval": 36.15,
                            "max_date": "2016-05-19",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved",
                            "minval": 36.15,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "RNN-search50*",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RNN-search50*"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-09-10",
                            "papername": "Sequence to Sequence Learning with Neural Networks",
                            "value": 34.81,
                            "url": "https://arxiv.org/abs/1409.3215v1",
                            "min_date": null,
                            "maxval": 34.81,
                            "max_date": null,
                            "src_name": "http://www.bioinf.jku.at/publications/older/2604.pdf",
                            "algorithm_src_url": "http://www.bioinf.jku.at/publications/older/2604.pdf",
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved",
                            "minval": 34.81,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "LSTM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "LSTM"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-09-10",
                            "papername": "Sequence to Sequence Learning with Neural Networks",
                            "value": 36.5,
                            "url": "https://arxiv.org/abs/1409.3215v1",
                            "min_date": null,
                            "maxval": 36.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved",
                            "minval": 36.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "SMT+LSTM5",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "SMT+LSTM5"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-10-30",
                            "papername": "Addressing the Rare Word Problem in Neural Machine Translation",
                            "value": 37.5,
                            "url": "https://arxiv.org/abs/1410.8206",
                            "min_date": "2014-10-30",
                            "maxval": 37.5,
                            "max_date": "2015-05-30",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved",
                            "minval": 37.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "LSTM6 + PosUnk",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "LSTM6 + PosUnk"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-07-23",
                            "papername": "Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation",
                            "value": 39.2,
                            "url": "https://arxiv.org/abs/1606.04199",
                            "min_date": "2016-06-14",
                            "maxval": 39.2,
                            "max_date": "2016-07-23",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved",
                            "minval": 39.2,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Deep-Att + PosUnk",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep-Att + PosUnk"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-09-26",
                            "papername": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation",
                            "value": 39.92,
                            "url": "https://arxiv.org/abs/1609.08144",
                            "min_date": "2016-09-26",
                            "maxval": 39.92,
                            "max_date": "2016-10-08",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved",
                            "minval": 39.92,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "GNMT+RL",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "GNMT+RL"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-01-23",
                            "papername": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer",
                            "value": 40.56,
                            "url": "https://arxiv.org/abs/1701.06538",
                            "min_date": null,
                            "maxval": 40.56,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved",
                            "minval": 40.56,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "MoE 2048",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MoE 2048"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-05-12",
                            "papername": "Convolutional Sequence to Sequence Learning",
                            "value": 41.29,
                            "url": "https://arxiv.org/abs/1705.03122v2",
                            "min_date": null,
                            "maxval": 41.29,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(news-test-2014 En-Fr BLEU)                           not solved",
                            "minval": 41.29,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ConvS2S ensemble",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ConvS2S ensemble"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 50,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L292",
                    "target_label": "Identical to professional human translations",
                    "url": "http://aclweb.org/anthology/P/P02/P02-1040.pdf",
                    "scale": "BLEU score",
                    "solved": false,
                    "axis_label": "BLEU score",
                    "name": "news-test-2014 En-De BLEU",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Translation between human langauges)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-02-24",
                            "papername": "Edinburgh\u2019s phrase-based machine translation systems for WMT-14",
                            "value": 20.7,
                            "url": "http://www.anthology.aclweb.org/W/W14/W14-33.pdf",
                            "min_date": null,
                            "maxval": 20.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(news-test-2014 En-De BLEU)                           not solved",
                            "minval": 20.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "PBMT",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "PBMT"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-07-14",
                            "papername": "Neural Semantic Encoders",
                            "value": 17.93,
                            "url": "https://arxiv.org/abs/1607.04315v1",
                            "min_date": null,
                            "maxval": 17.93,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(news-test-2014 En-De BLEU)                           not solved",
                            "minval": 17.93,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "NSE-NSE",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "NSE-NSE"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-07-23",
                            "papername": "Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation",
                            "value": 20.7,
                            "url": "https://arxiv.org/abs/1606.04199",
                            "min_date": "2016-06-14",
                            "maxval": 20.7,
                            "max_date": "2016-07-23",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(news-test-2014 En-De BLEU)                           not solved",
                            "minval": 20.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Deep-Att",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep-Att"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-09-26",
                            "papername": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation",
                            "value": 26.3,
                            "url": "https://arxiv.org/abs/1609.08144",
                            "min_date": "2016-09-26",
                            "maxval": 26.3,
                            "max_date": "2016-10-08",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(news-test-2014 En-De BLEU)                           not solved",
                            "minval": 26.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "GNMT+RL",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "GNMT+RL"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-01-23",
                            "papername": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer",
                            "value": 26.03,
                            "url": "https://arxiv.org/abs/1701.06538",
                            "min_date": null,
                            "maxval": 26.03,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(news-test-2014 En-De BLEU)                           not solved",
                            "minval": 26.03,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "MoE 2048",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MoE 2048"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-05-12",
                            "papername": "Convolutional Sequence to Sequence Learning",
                            "value": 26.36,
                            "url": "https://arxiv.org/abs/1705.03122v2",
                            "min_date": null,
                            "maxval": 26.36,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(news-test-2014 En-De BLEU)                           not solved",
                            "minval": 26.36,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ConvS2S ensemble",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ConvS2S ensemble"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 50,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L295",
                    "target_label": "Identical to professional human translations",
                    "url": "http://www.statmt.org/wmt16/book.pdf",
                    "scale": "BLEU score",
                    "solved": false,
                    "axis_label": "BLEU score",
                    "name": "news-test-2016 En-Ro BLEU",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Translation between human langauges)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-07-11",
                            "papername": "The QT21/HimL Combined Machine Translation System",
                            "value": 28.9,
                            "url": "http://www.statmt.org/wmt16/pdf/W16-2320.pdf",
                            "min_date": null,
                            "maxval": 28.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(news-test-2016 En-Ro BLEU)                           not solved",
                            "minval": 28.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "GRU BPE90k",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "GRU BPE90k"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-05-12",
                            "papername": "Convolutional Sequence to Sequence Learning",
                            "value": 29.88,
                            "url": "https://arxiv.org/abs/1705.03122v2",
                            "min_date": null,
                            "maxval": 29.88,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(news-test-2016 En-Ro BLEU)                           not solved",
                            "minval": 29.88,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "ConvS2S BPE40k",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "ConvS2S BPE40k"
                        }
                    ]
                }
            ],
            "subproblems": "<map object at 0x7f5a60785710>",
            "url": null,
            "solved": false,
            "attributes": [
                "agi",
                "language"
            ]
        },
        {
            "name": "Avoiding undesirable side effects",
            "superproblems": "<map object at 0x7f5a60785358>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a60785198>",
            "url": "https://arxiv.org/abs/1606.06565",
            "solved": false,
            "nodes": "\nMany important constraints on good behaviour will not be explicitly\nencoded in goal specification, either because they are too hard to capture\nor simply because there are so many of them and they are hard to enumerate\n",
            "attributes": [
                "safety"
            ]
        },
        {
            "name": "Abstract strategy games",
            "superproblems": "<map object at 0x7f5a607859e8>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a60785940>",
            "url": null,
            "solved": true,
            "attributes": [
                "agi",
                "abstract-games"
            ]
        },
        {
            "name": "Transfer learning: apply relevant knowledge from a prior setting to a new slightly different one",
            "superproblems": "<map object at 0x7f5a60785860>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a60785390>",
            "url": null,
            "solved": false,
            "attributes": []
        },
        {
            "name": "Accurate modelling of human language.",
            "superproblems": "<map object at 0x7f5a607857b8>",
            "metrics": [
                {
                    "notes": "",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L24",
                    "target_label": null,
                    "url": null,
                    "scale": "Perplexity",
                    "solved": false,
                    "axis_label": "Perplexity",
                    "name": "Penn Treebank (Perplexity when parsing English sentences)",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Accurate modelling of human language.)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-04-07",
                            "papername": null,
                            "value": 125.7,
                            "url": "http://www.fit.vutbr.cz/~imikolov/rnnlm/google.pdf",
                            "min_date": null,
                            "maxval": 125.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?",
                            "minval": 125.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "KN5+cache baseline",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "KN5+cache baseline"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-04-07",
                            "papername": null,
                            "value": 78.8,
                            "url": "http://www.fit.vutbr.cz/~imikolov/rnnlm/google.pdf",
                            "min_date": null,
                            "maxval": 78.8,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?",
                            "minval": 78.8,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "KN5+RNNME ensemble",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "KN5+RNNME ensemble"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-27",
                            "papername": null,
                            "value": 124.7,
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2012/07/rnn_ctxt_TR.sav_.pdf",
                            "min_date": null,
                            "maxval": 124.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?",
                            "minval": 124.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "RNNLM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RNNLM"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-27",
                            "papername": null,
                            "value": 113.7,
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2012/07/rnn_ctxt_TR.sav_.pdf",
                            "min_date": null,
                            "maxval": 113.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?",
                            "minval": 113.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "RNN-LDA LM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RNN-LDA LM"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-27",
                            "papername": null,
                            "value": 92.0,
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2012/07/rnn_ctxt_TR.sav_.pdf",
                            "min_date": null,
                            "maxval": 92.0,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?",
                            "minval": 92.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "RNN-LDA LM+KN5+cache",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RNN-LDA LM+KN5+cache"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-27",
                            "papername": null,
                            "value": 80.1,
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2012/07/rnn_ctxt_TR.sav_.pdf",
                            "min_date": null,
                            "maxval": 80.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?",
                            "minval": 80.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "RNN-LDA ensemble",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RNN-LDA ensemble"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2012-07-27",
                            "papername": null,
                            "value": 74.1,
                            "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2012/07/rnn_ctxt_TR.sav_.pdf",
                            "min_date": null,
                            "maxval": 74.1,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?",
                            "minval": 74.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "RNN-LDA+all",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RNN-LDA+all"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-12-20",
                            "papername": "How to Construct Deep Recurrent Neural Networks",
                            "value": 107.5,
                            "url": "https://arxiv.org/abs/1312.6026",
                            "min_date": "2013-12-20",
                            "maxval": 107.5,
                            "max_date": "2014-04-24",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?",
                            "minval": 107.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Deep RNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Deep RNN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2014-09-08",
                            "papername": "Recurrent Neural Network Regularization",
                            "value": 68.7,
                            "url": "https://arxiv.org/abs/1409.2329v1",
                            "min_date": null,
                            "maxval": 68.7,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?",
                            "minval": 68.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "RNN Dropout Regularization",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RNN Dropout Regularization"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-09-26",
                            "papername": "Pointer Sentinel Mixture Models",
                            "value": 70.9,
                            "url": "https://arxiv.org/abs/1609.07843v1",
                            "min_date": null,
                            "maxval": 70.9,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?",
                            "minval": 70.9,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Pointer Sentinel-LSTM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Pointer Sentinel-LSTM"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-10-05",
                            "papername": "A Theoretically Grounded Application of Dropout in Recurrent Neural Networks",
                            "value": 73.4,
                            "url": "https://arxiv.org/abs/1512.05287v5",
                            "min_date": null,
                            "maxval": 73.4,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?",
                            "minval": 73.4,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Variational LSTM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Variational LSTM"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-10-27",
                            "papername": "Recurrent Highway Networks",
                            "value": 68.5,
                            "url": "https://arxiv.org/abs/1607.03474v3",
                            "min_date": null,
                            "maxval": 68.5,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?",
                            "minval": 68.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "RHN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RHN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-10-27",
                            "papername": "Recurrent Highway Networks",
                            "value": 66,
                            "url": "https://arxiv.org/abs/1607.03474v3",
                            "min_date": null,
                            "maxval": 66,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?",
                            "minval": 66,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "RHN+WT",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RHN+WT"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-01-06",
                            "papername": "Recurrent Highway Networks",
                            "value": 71.3,
                            "url": "https://arxiv.org/abs/1607.03474",
                            "min_date": "2016-07-12",
                            "maxval": 71.3,
                            "max_date": "2017-07-04",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Penn Treebank (Perplexity when parsing English sentences))?",
                            "minval": 71.3,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Variational RHN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Variational RHN"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 1.3,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L39",
                    "target_label": null,
                    "url": null,
                    "scale": "Model Entropy",
                    "solved": false,
                    "axis_label": "Model Entropy",
                    "name": "Hutter Prize (bits per character to encode English text)",
                    "target_source": null,
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Accurate modelling of human language.)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2011-06-28",
                            "papername": null,
                            "value": 1.6,
                            "url": "http://www.cs.utoronto.ca/~ilya/pubs/2011/LANG-RNN.pdf",
                            "min_date": null,
                            "maxval": 1.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved",
                            "minval": 1.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "RNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RNN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2013-08-04",
                            "papername": "Generating Sequences With Recurrent Neural Networks",
                            "value": 1.67,
                            "url": "https://arxiv.org/abs/1308.0850",
                            "min_date": "2013-08-04",
                            "maxval": 1.67,
                            "max_date": "2014-06-05",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved",
                            "minval": 1.67,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "RNN, LSTM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "RNN, LSTM"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-02-15",
                            "papername": "Gated Feedback Recurrent Neural Networks",
                            "value": 1.58,
                            "url": "https://arxiv.org/abs/1502.02367",
                            "min_date": "2015-02-09",
                            "maxval": 1.58,
                            "max_date": "2015-06-17",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved",
                            "minval": 1.58,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Gated Feedback RNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Gated Feedback RNN"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2015-07-06",
                            "papername": "Grid Long Short-Term Memory",
                            "value": 1.47,
                            "url": "https://arxiv.org/abs/1507.01526",
                            "min_date": "2015-07-06",
                            "maxval": 1.47,
                            "max_date": "2016-01-07",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved",
                            "minval": 1.47,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Grid LSTM",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Grid LSTM"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-07-12",
                            "papername": "Recurrent Highway Networks",
                            "value": 1.32,
                            "url": "https://arxiv.org/abs/1607.03474",
                            "min_date": "2016-07-12",
                            "maxval": 1.32,
                            "max_date": "2017-07-04",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved",
                            "minval": 1.32,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Recurrent Highway Networks",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Recurrent Highway Networks"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-09-06",
                            "papername": "Hierarchical Multiscale Recurrent Neural Networks",
                            "value": 1.32,
                            "url": "https://arxiv.org/abs/1609.01704",
                            "min_date": "2016-09-06",
                            "maxval": 1.32,
                            "max_date": "2017-03-09",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved",
                            "minval": 1.32,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": " Hierarchical Multiscale RNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": " Hierarchical Multiscale ..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-09-27",
                            "papername": "HyperNetworks",
                            "value": 1.39,
                            "url": "https://arxiv.org/abs/1609.09106",
                            "min_date": "2016-09-27",
                            "maxval": 1.39,
                            "max_date": "2016-12-01",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved",
                            "minval": 1.39,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Hypernetworks",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Hypernetworks"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-10-19",
                            "papername": "Surprisal-Driven Feedback in Recurrent Networks",
                            "value": 1.37,
                            "url": "https://arxiv.org/abs/1608.06027",
                            "min_date": "2016-08-22",
                            "maxval": 1.37,
                            "max_date": "2016-10-19",
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved",
                            "minval": 1.37,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Surprisal-Driven Feedback RNN",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Surprisal-Driven Feedback..."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2016-10-31",
                            "papername": null,
                            "value": 1.313,
                            "url": "https://pdfs.semanticscholar.org/e9bc/83f9ff502bec9cffb750468f76fdfcf5dd05.pdf",
                            "min_date": null,
                            "maxval": 1.313,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(Hutter Prize (bits per character to encode English text))not solved",
                            "minval": 1.313,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Surprisal-Driven Zoneout",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Surprisal-Driven Zoneout"
                        }
                    ]
                },
                {
                    "notes": "",
                    "target": 86,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/language.py#L47",
                    "target_label": null,
                    "url": "https://arxiv.org/abs/1606.06031",
                    "scale": "Percentage correct",
                    "solved": false,
                    "axis_label": "Percentage correct",
                    "name": "LAMBADA prediction of words in discourse",
                    "target_source": "https://arxiv.org/abs/1610.08431v3",
                    "graphed": true,
                    "changeable": false,
                    "data_path": "/home/pde/aip/data/language.py",
                    "parent": "Problem(Accurate modelling of human language.)",
                    "measures": [
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-02-16",
                            "papername": "Broad Context Language Modeling as Reading Comprehension",
                            "value": 21.7,
                            "url": "https://arxiv.org/abs/1610.08431v3",
                            "min_date": "2016-06-09",
                            "maxval": 21.7,
                            "max_date": null,
                            "src_name": "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task",
                            "algorithm_src_url": "https://arxiv.org/abs/1606.02858",
                            "metric": "Metric(LAMBADA prediction of words in discourse)            not solved",
                            "minval": 21.7,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Stanford Reader",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Stanford Reader"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-02-16",
                            "papername": "Broad Context Language Modeling as Reading Comprehension",
                            "value": 32.1,
                            "url": "https://arxiv.org/abs/1610.08431v3",
                            "min_date": "2016-06-09",
                            "maxval": 32.1,
                            "max_date": null,
                            "src_name": "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task",
                            "algorithm_src_url": "https://arxiv.org/abs/1606.02858",
                            "metric": "Metric(LAMBADA prediction of words in discourse)            not solved",
                            "minval": 32.1,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "Modified Stanford",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "Modified Stanford"
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-02-16",
                            "papername": "Broad Context Language Modeling as Reading Comprehension",
                            "value": 44.5,
                            "url": "https://arxiv.org/abs/1610.08431v3",
                            "min_date": "2016-03-04",
                            "maxval": 44.5,
                            "max_date": null,
                            "src_name": "Text Understanding with the Attention Sum Reader Network",
                            "algorithm_src_url": "https://arxiv.org/abs/1603.01547",
                            "metric": "Metric(LAMBADA prediction of words in discourse)            not solved",
                            "minval": 44.5,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "AS + feat.",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "AS + feat."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-02-16",
                            "papername": "Broad Context Language Modeling as Reading Comprehension",
                            "value": 49.0,
                            "url": "https://arxiv.org/abs/1610.08431v3",
                            "min_date": "2016-12-01",
                            "maxval": 49.0,
                            "max_date": null,
                            "src_name": "Gated-Attention Readers for Text Comprehension",
                            "algorithm_src_url": "https://arxiv.org/abs/1606.01549v2",
                            "metric": "Metric(LAMBADA prediction of words in discourse)            not solved",
                            "minval": 49.0,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "GA + feat.",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "GA + feat."
                        },
                        {
                            "notes": "",
                            "withdrawn": false,
                            "date": "2017-03-07",
                            "papername": "Linguistic Knowledge as Memory for Recurrent Neural Networks",
                            "value": 51.6,
                            "url": "https://arxiv.org/abs/1703.02620v1",
                            "min_date": null,
                            "maxval": 51.6,
                            "max_date": null,
                            "src_name": null,
                            "algorithm_src_url": "",
                            "metric": "Metric(LAMBADA prediction of words in discourse)            not solved",
                            "minval": 51.6,
                            "opensource": false,
                            "algorithms": [],
                            "uncertainty": 0,
                            "name": "MAGE (48)",
                            "long_label": false,
                            "not_directly_comparable": false,
                            "replicated_url": "",
                            "label": "MAGE (48)"
                        }
                    ]
                }
            ],
            "subproblems": "<map object at 0x7f5a60785be0>",
            "url": null,
            "solved": false,
            "attributes": [
                "language",
                "agi"
            ]
        },
        {
            "name": "Superhuman mastery of arbitrary abstract strategy games",
            "superproblems": "<map object at 0x7f5a60785518>",
            "metrics": [
                {
                    "notes": "\n  Beating all humans at chess, given a corpus of past play amongst masters,\n  but no human-crafted policy constraints and heuristics. This will probably fall out\n  immediately once learning_abstract_game_rules is solved, since playing_with_hints\n  has been solved.\n",
                    "target": null,
                    "data_url": "https://github.com/AI-metrics/AI-metrics/edit/master//home/pde/aip/data/strategy_games.py#L63",
                    "target_label": null,
                    "url": null,
                    "scale": "Score",
                    "solved": false,
                    "axis_label": "Score",
                    "name": "mastering chess",
                    "target_source": null,
                    "graphed": false,
                    "changeable": false,
                    "data_path": null,
                    "parent": "Problem(Superhuman mastery of arbitrary abstract strategy games)",
                    "measures": []
                }
            ],
            "subproblems": "<map object at 0x7f5a607853c8>",
            "url": null,
            "solved": false,
            "attributes": [
                "super",
                "abstract-games"
            ]
        },
        {
            "name": "Detect security-related bugs in codebases",
            "superproblems": "<map object at 0x7f5a607856a0>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a60785208>",
            "url": null,
            "solved": false,
            "attributes": [
                "safety",
                "security",
                "unsafe"
            ]
        },
        {
            "name": "One shot learning: ingest important truths from a single example",
            "superproblems": "<map object at 0x7f5a60785a90>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a607851d0>",
            "url": null,
            "solved": false,
            "attributes": [
                "agi",
                "world-modelling"
            ]
        },
        {
            "notes": "\nIt is clearly important is ensuring that the state of the art in defensive technology is deployed everywhere\nthat matters, including systems that perform important functions or have sensitive data on them (smartphones, for instance), and \nsystems that have signifcant computational resources. This \"Problem\" isn't \n",
            "name": "Deploy automated defensive security tools to protect valuable systems",
            "superproblems": "<map object at 0x7f5a60785978>",
            "metrics": [],
            "subproblems": "<map object at 0x7f5a607856d8>",
            "url": null,
            "solved": false,
            "attributes": []
        }
    ]
}