{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# A notebook for organising AI progress metrics\n",
    "\n",
    "from datetime import date\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "# We have the following structures:\n",
    "#\n",
    "# problem \n",
    "#     \\   \\\n",
    "#      \\   metrics  -  measures \n",
    "#       \\\n",
    "#        - subproblems\n",
    "#             \\\n",
    "#           metrics\n",
    "#              \\\n",
    "#             measures\n",
    "#\n",
    "# problems are tagged with attributes:\n",
    "# eg, vision, abstract-games, language, world-modelling, safety\n",
    "#     agi       -- most capable humans can do this, so AGIs can do this\n",
    "#     super     -- the very best humans can do this, or human organisations have solved this\n",
    "#     verysuper -- neither humans nor human orgs have solved this\n",
    "#\n",
    "# problems can have \"subproblems\", including simpler cases and preconditions\n",
    "#\n",
    "# a \"metric\" is one way of measuring progress on a problem. There will often be several metrics\n",
    "# for a given problem, but in some cases we'll start out with zero metrics and will need to start\n",
    "# proposing some...\n",
    "#\n",
    "# a measure[ment] is a score on a given metric, by a particular codebase/team/project, at a particular\n",
    "# time\n",
    "\n",
    "problems = {}\n",
    "metrics = {}\n",
    "measurements = set() # we don't try to guarantee unique names for these, so use a set\n",
    "all_attributes = set()\n",
    "\n",
    "class Problem:\n",
    "    def __init__(self, name, attributes=[], solved=False, url=None):\n",
    "        self.name = name\n",
    "        self.attributes = attributes\n",
    "        for a in attributes:\n",
    "            global all_attributes\n",
    "            all_attributes.add(a)\n",
    "        self.subproblems = []\n",
    "        self.superproblems = []\n",
    "        self.metrics = []\n",
    "        self.solved = solved\n",
    "        self.url = url\n",
    "        global problems, metrics\n",
    "        problems[name] = self\n",
    "        \n",
    "    def subproblem(self, other_problem):\n",
    "        self.superproblems.append(other_problem)\n",
    "        other_problem.subproblems.append(self)\n",
    "        \n",
    "    def metric(self, *args, **kwargs):\n",
    "        m = Metric(*args, **kwargs)\n",
    "        m.parent = self\n",
    "        self.metrics.append(m)\n",
    "        return m\n",
    "    \n",
    "    def check_solved(self):\n",
    "        if all(m.solved for m in self.metrics + self.subproblems):\n",
    "            self.solved = True\n",
    "            for p in self.superproblems:\n",
    "                p.check_solved()\n",
    "\n",
    "\n",
    "# Different metrics and measurements for progress are made on very different types of scales\n",
    "# we have some helper functions to regularise these a little bit, so we can tell (for instance)\n",
    "# whether progress on some metric appears to be accelerating or decelerating.\n",
    "\n",
    "# Interface:\n",
    "#    improvement(score1, score2): retrns a consistent measure of how much better score2 is than score1\n",
    "#    pseudolinear(score): returns a modified version of score where we would expect vaguely linear progress\n",
    "\n",
    "class Linear:\n",
    "    def improvement(self, score1, score2):\n",
    "        return score2 - score1\n",
    "    def pseudolinear(self, score):\n",
    "        return score\n",
    "linear = Linear()\n",
    "\n",
    "class ELO:\n",
    "    def improvement(self, score1, score2):\n",
    "        \"\"\"\n",
    "        Normalise an ELO score\n",
    "        \n",
    "        An ELO increase of 400 improves your odds by 10x, so we could justify something like\n",
    "        return 10.0 ** ((score2 - score1)/400.)\n",
    "        However, it seems that at least for chess ELO progress has been roughly linear over\n",
    "        time, both for humans and computers (though with different coefficients). Perhaps this\n",
    "        tracks exponential increases in ability to search the game's state space, driven directly\n",
    "        by Moore's law on the computer side, and indirectly for humans by access to better training\n",
    "        tools and more profound libraries of past play.\n",
    "        \n",
    "        So for now let's treat this as linear? But ELO is not a chess-specific measure, and in other\n",
    "        contexts we may want to do exponentiation as documented above?\n",
    "        \"\"\"\n",
    "        return score2 - score1\n",
    "    def pseudolinear(self, score):\n",
    "        return score\n",
    "    \n",
    "elo = ELO()\n",
    "\n",
    "class ErrorRate:\n",
    "    \"\"\"Many labelling contests use these measures\"\"\"\n",
    "    def improvement(self, score1, score2):\n",
    "        # 0.5 / 0.25\n",
    "        return score1 / score2\n",
    "    def pseudolinear(self, score):\n",
    "        # The choice of base here is arbitrary. But since this is computer science, let's use base2!\n",
    "        from math import log\n",
    "        return log(score) / log(2.0)\n",
    "error_rate = ErrorRate()\n",
    "\n",
    "class CorrectRate:\n",
    "    \"100 - error rate\"\n",
    "    def erate(self, score):\n",
    "        return (100. - score)/100.\n",
    "\n",
    "    def improvement(self, score1, score2):\n",
    "        return self.erate(score1) / self.erate(score2)\n",
    "    \n",
    "    def pseudolinear(self, score):\n",
    "        from math import log\n",
    "        return log(self.erate(score)) / log(2.0)\n",
    "correct_rate = CorrectRate()\n",
    "    \n",
    "class Metric:\n",
    "    def __init__(self, name, url=None, solved=False, notes=\"\", scale=linear, target=None, parent=None):\n",
    "        self.name = name\n",
    "        self.measures = []\n",
    "        self.solved = solved\n",
    "        self.url = url\n",
    "        self.notes = notes\n",
    "        self.scale = scale\n",
    "        self.target = target\n",
    "        global metrics\n",
    "        metrics[name] = self\n",
    "        self.parent = parent\n",
    "        \n",
    "    def measure(self, *args, **kwargs):\n",
    "        m = Measurement(*args, **kwargs)\n",
    "        self.measures.append(m)\n",
    "        if self.target:\n",
    "            if self.scale.improvement(self.target, m.value) >= 0:\n",
    "                self.solved = True\n",
    "                self.parent.check_solved()\n",
    "        return m\n",
    "\n",
    "\n",
    "class Measurement:\n",
    "    def __init__(self, date, value, name, url, algorithms=[], uncertainty=0, minval=None, maxval=None, opensource=False, replicated=\"\"):\n",
    "        self.date = date\n",
    "        self.value = value\n",
    "        assert isinstance(value, float) or isinstance(value, int), \"Measurements on metrics need to be numbers\"\n",
    "        self.name = name\n",
    "        self.url = url\n",
    "        self.minval = minval if minval else value - uncertainty\n",
    "        self.maxval = maxval if maxval else value + uncertainty\n",
    "        self.opensource = opensource\n",
    "        self.replicated_url = replicated\n",
    "        self.algorithms = []\n",
    "        global measurements\n",
    "        measurements.add(self)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Sources to incorporate\n",
    "\n",
    "* ☑ Jack Clark's collection of progress measurements \n",
    "* ☐ Sarah Constantin's [Performance Trends in AI](https://srconstantin.wordpress.com/2017/01/28/performance-trends-in-ai/)\n",
    "* ☐ Katja Grace's [Algorithmic Progress in Six Domains](https://intelligence.org/files/AlgorithmicProgress.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BEGIN ACTUALLY CLASSIFYING PROBLEMS\n",
    "\n",
    "scene_description = Problem(\"Scene description\", [\"agi\", \"vision\", \"language\", \"world-modelling\"])\n",
    "image_classification = Problem(\"Image classification\", [\"vision\", \"agi\"])\n",
    "scene_description.subproblem(image_classification)\n",
    "\n",
    "imagenet = image_classification.metric(\"imagenet\", \"http://image-net.org\", scale=error_rate)\n",
    "imagenet.notes = \"\"\"\n",
    "Correctly label images from the Imagenet dataset. As of 2016, this includes:\n",
    " - Object localization for 1000 categories.\n",
    " - Object detection for 200 fully labeled categories.\n",
    " - Object detection from video for 30 fully labeled categories.\n",
    " - Scene classification for 365 scene categories (Joint with MIT Places team) on Places2 Database http://places2.csail.mit.edu.\n",
    " - Scene parsing for 150 stuff and discrete object categories (Joint with MIT Places team).\n",
    "WARNING: these subchallenges were added in successive years of the Imagenet challenge, so results from years are not directly\n",
    "comparable; however progress should probably be understated by comparing them?\n",
    "\"\"\"\n",
    "\n",
    "# Data points gathered by Jack Clark:\n",
    "imagenet.measure(date(2010,8,31), 0.28191, \"NEC UIUC\", \"http://image-net.org/challenges/LSVRC/2010/results\")\n",
    "imagenet.measure(date(2015,12,10), 0.03567, \"MSRA\", \"http://image-net.org/challenges/LSVRC/2015/results\", algorithms=[\"residual-networks\"])\n",
    "\n",
    "\"\"\"\n",
    "** 2010: 0.28191**\n",
    "**NEC UIUC**\n",
    "http://image-net.org/challenges/LSVRC/2010/results\n",
    "\n",
    "** 2011: 0.25770\n",
    " XRCE**\n",
    "\n",
    "** 2012: 0.16422**\n",
    "** Supervision**\n",
    "http://image-net.org/challenges/LSVRC/2012/results.html\n",
    "\n",
    "** 2013: 0.11743 **\n",
    "**Clarifai**\n",
    "http://www.image-net.org/challenges/LSVRC/2013/results.php\n",
    "\n",
    "** 2014: 0.07405**\n",
    "**VGG**\n",
    "http://image-net.org/challenges/LSVRC/2014/index\n",
    " \n",
    "\n",
    "**2015: 0.03567**\n",
    "**MSRA**\n",
    "http://image-net.org/challenges/LSVRC/2015/results\n",
    "\n",
    "** 2016: 0.02991**\n",
    "**Trimps-Soushen**\n",
    "http://image-net.org/challenges/LSVRC/2016/results\n",
    "* * *\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Abstract games like chess, go, checkers etc can be played with no knowldege of the human world.\n",
    "# Although this domain has largely been solved to super-human performance levels, there are a\n",
    "# few ends that need to be tied up, especially in terms of having agents learn rules for arbitrary \n",
    "# abstract games effectively\n",
    "\n",
    "abstract_strategy_games = Problem(\"Abstract strategy games\", [\"agi\", \"abstract-games\"])\n",
    "\n",
    "playing_with_hints = Problem(\"Playing abstract games with extensive hints\", [\"abstract-games\"], solved=True)\n",
    "playing_with_hints.notes = \"\"\"\n",
    "  Complex abstract strategy games have been solved to super-human levels\n",
    "  by computer systems with extensive rule-hinting and heuristics,\n",
    "  in some cases combined with machine learning techniques.\n",
    "\"\"\"\n",
    "computer_chess = playing_with_hints.metric(\"computer chess\", scale=elo)\n",
    "# For some caveats, see https://en.wikipedia.org/w/index.php?title=Chess_engine&oldid=764341963#Ratings\n",
    "computer_chess.measure(date(2017,02,27), 3393, \"Stockfish\", uncertainty=50,\n",
    "                           url=\"https://web.archive.org/web/20170227044521/http://www.computerchess.org.uk/ccrl/4040/\")\n",
    "computer_chess.measure(date(1997,05,11), 2725, \"Deep Blue\", uncertainty=25,\n",
    "                           url=\"https://www.quora.com/What-was-Deep-Blues-Elo-rating\")\n",
    "\n",
    "mastering_historical_games = Problem(\"Mastering human abstract strategy games\", [\"super\", \"abstract-games\"])\n",
    "mastering_chess = mastering_historical_games.metric(\"mastering chess\")\n",
    "mastering_chess.notes = \"\"\"\n",
    "  Beating all humans at chess, given a corpus of past play amongst masters,\n",
    "  but no human-crafted policy constraints and heuristics. This will probably fall out\n",
    "  immediately once learning_abstract_game_rules is solved, since playing_with_hints\n",
    "  has been solved.\n",
    "\"\"\"\n",
    "\n",
    "# Are there any published metrics for these yet?\n",
    "learning_abstract_game_rules = Problem(\"Learning the rules of complex strategy games from examples\", [\"agi\", \"abstract-games\"])\n",
    "learning_chess = learning_abstract_game_rules.metric(\"learning chess\")\n",
    "learning_chess.notes = \"\"\"\n",
    "  Chess software contains hard-coded policy constraints for valid play; this metric is whether RL\n",
    "  or other agents can correctly build those policy constraints from examples or oracles\"\"\"\n",
    "learning_go = learning_abstract_game_rules.metric(\"learning go\")\n",
    "learning_go.notes = \"\"\"\n",
    "  Go software contains policy constraints for valid play and evaluating the number of\n",
    "  liberties for groups. This metric is whether RL or other agents can correctly build those \n",
    "  policy constraints from examples or oracles\"\"\"\n",
    "learning_arbitrary_abstract_games = Problem(\"Play an arbitrary abstract game, first learning the rules\", [\"agi\", \"abstract-games\"])\n",
    "                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Measurement instance at 0x7fa8641d4c20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Speech recognition\n",
    "\n",
    "\"\"\"\n",
    "        http://melodi.ee.washington.edu/s3tp/\n",
    "\n",
    "* * *\n",
    "**_Word error rate on Switchboard (specify details): [Month, Year: Score [SWB]: Team].  Compiled by Jack Clark._**\n",
    "\n",
    "A note about measurement: We're measuring Switchboard (SWB) and Call Home (CH) performance from the Hub5'00 dataset, with main scores assesses in terms of word error rate on SWB. We also create \n",
    "\n",
    "Why do we care: Reflects the improvement of audio processing systems on speech over time.\n",
    "\n",
    "\"\"\"\n",
    "speech_recognition = Problem(name=\"Speech Recognition\", attributes=[\"language\", \"agi\"])\n",
    "switchboard_metric = speech_recognition.metric(name=\"Word error rate on Switchboard\",\n",
    "                                               scale=error_rate, target=0.0)\n",
    "switchboard_metric.measure(date=date(2011,8,31), value=16.1,\n",
    "                           name=\"Conversational Speech Transcription Using Context-Dependent Neural Networks\",\n",
    "                           url=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/CD-DNN-HMM-SWB-Interspeech2011-Pub.pdf\")\n",
    "switchboard_metric.measure(date=date(2012,4,27), value=18.5,\n",
    "                           name=\"Deep Neural Networks for Acoustic Modeling in Speech Recognition\",\n",
    "                           url=\"https://pdfs.semanticscholar.org/ce25/00257fda92338ec0a117bea1dbc0381d7c73.pdf?_ga=1.195375081.452266805.1483390947\")\n",
    "switchboard_metric.measure(date=date(2013,1,1), value=12.9,\n",
    "                           name=\"Sequence discriniative training of deep neural networks\",\n",
    "                           url=\"http://www.danielpovey.com/files/2013_interspeech_dnn.pdf\")\n",
    "switchboard_metric.measure(date=date(2014,6,30), value=16, \n",
    "                           name=\"Increasing Deep Neural Network Acoustic Model Size for Large Vocabulary Continuous Speech Recognition\",\n",
    "                           url=\"https://arxiv.org/abs/1406.7806v1\")\n",
    "switchboard_metric.measure(date=date(2014,12,7), value=20,\n",
    "                           name=\"Deep Speech\", url=\"https://arxiv.org/abs/1412.5567\")\n",
    "switchboard_metric.measure(date=date(2014,12,7), value=12.6,\n",
    "                           name=\"Deep Speech\", url=\"https://arxiv.org/abs/1412.5567\")\n",
    "switchboard_metric.measure(date=date(2015,5,21), value=8.0,\n",
    "                           name=\"The IBM 2015 English Conversational Telephone Speech Recognition System\",\n",
    "                           url=\"https://arxiv.org/abs/1505.05899\")\n",
    "switchboard_metric.measure(date=date(2016,4,27), value=6.9,\n",
    "                           name=\"The IBM 2016 English Conversational Telephone Speech Recognition System\",\n",
    "                           url=\"https://arxiv.org/abs/1604.08242v1\")\n",
    "switchboard_metric.measure(date=date(2017,2,17), value=6.9,\n",
    "                           name=\"Microsoft 2016 Conversational Speech Recognition System\",\n",
    "                           url=\"https://arxiv.org/abs/1609.03528\")\n",
    "switchboard_metric.measure(date=date(2017,2,17), value=6.2,\n",
    "                           name=\"Microsoft 2016 Conversational Speech Recognition System\",\n",
    "                           url=\"https://arxiv.org/abs/1609.03528\")\n",
    "switchboard_metric.measure(date=date(2016,10,17), value=6.6,\n",
    "                           name=\"Achieving Human Parity in Conversational Speech Recognition\",\n",
    "                           url=\"https://arxiv.org/abs/1610.05256\")\n",
    "switchboard_metric.measure(date=date(2016,10,17), value=5.9,\n",
    "                           name=\"Achieving Human Parity in Conversational Speech Recognition\",\n",
    "                           url=\"https://arxiv.org/abs/1610.05256\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Measurement instance at 0x7fa8641e6320>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image Generation\n",
    "\n",
    "\"\"\" \n",
    "* * *\n",
    "**_Generative models of CIFAR-10 Natural Images _****[Year: bits-per-subpixel, method]. Compiled by Durk Kingma.**\n",
    "\n",
    "**Why we care:**\n",
    "(1) The compression=prediction=understanding=intelligence view (see Hutter prize, etc.). (Note that perplexity, log-likelihood, and #bits are all equivalent measurements.)\n",
    "(2) Learning a generative model is a prominent auxiliary task towards semi-supervised learning. Current SOTA semi-supervised classification results utilize generative models.\n",
    "3) You're finding patterns in the data that let you compress it more efficiently. Ultimate pattern recognition benchmark because you're trying to find the patterns in all the data. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "image_generation = Problem(\"Generative models of CIFAR-10 Natural Images\", [\"vision\", \"agi\"])\n",
    "# note: this section is not on scene generation, but making the distinction seemed like a good idea.\n",
    "scene_generation = Problem(\"Be able to generate complex scene e.g. a baboon receiving their degree at convocatoin.\", [\"vision\", \"world-modelling\", \"agi\"])\n",
    "scene_generation.subproblem(image_generation)\n",
    "\n",
    "# Note: scale, and target need to be checked\n",
    "image_generation_metric = image_generation.metric(name=\"bits-per-subpixel\", solved=False, scale=error_rate, target=1.0)\n",
    "\n",
    "image_generation_metric.measure(date=date(2014,10,30), value=4.48, name=\"NICE\", url=\"https://arxiv.org/abs/1410.8516\")\n",
    "image_generation_metric.measure(date=date(2015,2,16), value=4.13, name=\"DRAW\", url=\"https://arxiv.org/abs/1502.04623\")\n",
    "image_generation_metric.measure(date=(2016,5,27), value=3.49, name=\"Real NVP\", url=\"https://arxiv.org/abs/1605.08803\")\n",
    "image_generation_metric.measure(date=2016, value=3.11, name=\"VAE with IAF\", url=\"https://papers.nips.cc/paper/6581-improved-variational-inference-with-inverse-autoregressive-flow\")\n",
    "image_generation_metric.measure(date=date(2016,5,27), value=3.0, name=\"PixelRNN\", url=\"https://arxiv.org/abs/1605.08803\")\n",
    "image_generation_metric.measure(date=date(2016,11,4), value=2.92, name=\"PixelCNN++\", url=\"https://openreview.net/forum?id=BJrFC6ceg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should add an English text compression metric here. Shannon's [classic 1951 paper]() obtained an expiermental measure of human text compression performance at 0.6 - 1.3 bits per character. More recent work ([Moradi 1998](https://pdfs.semanticscholar.org/48bc/ce35ceb72068723d5f360f388a073aadadca.pdf), Cover 1978) provides estimates that are text-relative and in the 1.3 bits per character (and for some texts, much higher) range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "**_Perplixity on Penn Treebank [Year, perplexity score]. Compiled by Jack._**\n",
    "**Why do we care: **perplexity gives us a sense of how well the computer has been able to model language. Lower perplexity indicates less confusion on the part of the model about what language to use to complete a sentence. \n",
    "\n",
    " 2012: 124.7\n",
    "mikolov & zweig\n",
    "https://pdfs.semanticscholar.org/04e0/fefb859f4b02b017818915a2645427bfbdb2.pdf\n",
    "\n",
    " 2013: 107.5\n",
    "pascanu test\n",
    "how to construct deep RNNs, https://arxiv.org/abs/1312.6026\n",
    "\n",
    " 2014: 78.4, validation: 82.2\n",
    "zaremba et all.\n",
    "https://arxiv.org/abs/1409.2329\n",
    "\n",
    " 2015: test: 73.4\n",
    " variational LSTM (large, untied, MC)\n",
    "https://arxiv.org/pdf/1512.05287v5.pdf\n",
    "\n",
    " 2016: test: 70.9\n",
    "pointer sentinel-lstm\n",
    "https://arxiv.org/pdf/1609.07843v1.pdf\n",
    "\n",
    " 2016: test: 66\n",
    " recurrent highway networks\n",
    "https://arxiv.org/pdf/1607.03474v3.pd (https://arxiv.org/pdf/1607.03474v3.pdf)\n",
    "\"\"\"\n",
    "penn_treebank_perplexity = Problem(\"Perplexity gives us a sense of how well the computer has been able to model language. Lower perplexity indicates less confusion on the part of the model about what language to use to complete a sentence.\", [\"language\", \"agi\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* * *\n",
    "**_Perplixity on Penn Treebank [Year, perplexity score]. Compiled by Jack._**\n",
    "\n",
    "**Why do we care: **perplexity gives us a sense of how well the computer has been able to model language. Lower perplexity indicates less confusion on the part of the model about what language to use to complete a sentence. \n",
    "\n",
    "\n",
    " 2012: 124.7\n",
    "mikolov & zweig\n",
    "https://pdfs.semanticscholar.org/04e0/fefb859f4b02b017818915a2645427bfbdb2.pdf\n",
    "\n",
    " 2013: 107.5\n",
    "pascanu test\n",
    "how to construct deep RNNs, https://arxiv.org/abs/1312.6026\n",
    "\n",
    " 2014: 78.4, validation: 82.2\n",
    "zaremba et all.\n",
    "https://arxiv.org/abs/1409.2329\n",
    "\n",
    " 2015: test: 73.4\n",
    " variational LSTM (large, untied, MC)\n",
    "https://arxiv.org/pdf/1512.05287v5.pdf\n",
    "\n",
    " 2016: test: 70.9\n",
    "pointer sentinel-lstm\n",
    "https://arxiv.org/pdf/1609.07843v1.pdf\n",
    "\n",
    " 2016: test: 66\n",
    " recurrent highway networks\n",
    "https://arxiv.org/pdf/1607.03474v3.pd (https://arxiv.org/pdf/1607.03474v3.pdf)\n",
    "* * *\n",
    "**_Bits-per-character on enwik8 dataset to measure Hutter Prize compression progression_**\n",
    "[Year, bits-per-character]. Compiled by Jack\n",
    "\n",
    "Why we care about this: relationship between compression and intelligence?\n",
    "\n",
    "2011: 1.60\n",
    "Paper: Generating text with recurrent neural networks\n",
    "Url: \n",
    "https://www.google.com/search?q=Generating+text+with+recurrent+neural+networks&oq=Generating+text+with+recurrent+neural+networks&aqs=chrome..69i57.196j0j4&sourceid=chrome&ie=UTF-8\n",
    "\n",
    "**2013:**\n",
    "\n",
    "2013: 1.67\n",
    "Paper: Generating sequences with recurrent neural networks\n",
    "Url: https://arxiv.org/abs/1308.0850\n",
    "\n",
    "**2015:**\n",
    "\n",
    "February, 2015: 1.58 \n",
    "Paper: Gated Feedback Recurrent Neural Networks\n",
    "Url: https://arxiv.org/abs/1502.02367\n",
    "\n",
    "July, 2015: 1.47 \n",
    "Paper:  Grid Long Short-Term Memory\n",
    "Url: https://arxiv.org/abs/1507.01526\n",
    "\n",
    "**2016:**\n",
    "\n",
    "July, 2016: 1.32\n",
    "Recurrent highway networks\n",
    "https://arxiv.org/abs/1607.03474\n",
    "\n",
    "September, 2016:  1.32\n",
    "Paper: Hierarchical Multiscale Recurrent Neural Networks\n",
    "Url: https://arxiv.org/abs/1609.01704\n",
    "\n",
    "September, 2016: 1.39\n",
    "hypernetworks / hyperlstm\n",
    "https://arxiv.org/abs/1609.09106\n",
    "\n",
    "October, 2016: 1.37\n",
    "Paper: surprisal-driven feedback in recurrent neural networks, \n",
    "Url: https://arxiv.org/pdf/1608.06027.pdf\n",
    "\n",
    "2016 - surprisal driven zoneout, test: 1.313\n",
    "https://pdfs.semanticscholar.org/e9bc/83f9ff502bec9cffb750468f76fdfcf5dd05.pdf?_ga=1.27297145.452266805.1483390947\n",
    "\n",
    "**Human/Algo best performance:**\n",
    "\n",
    "**cmix v11, test 1.245 BPC**\n",
    "CMIX (SOTA) uses neural nets. Both LSTM and fully connected. Uses 1,746 independent models, majority of which come from other OSS compression progs eg paq8l, paq8pxd, paq8hp12\n",
    " http://www.byronknoll.com/cmix.html\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is bAbi solved? True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('How is bAbi solved?', True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reading_comprehension = Problem(\"Language comprehension and question-answering\", [\"language\", \"world-modelling\", \"agi\"])\n",
    "\n",
    "bAbi = reading_comprehension.metric(\"bAbi\", url=\"http://fb.ai/babi\", scale=correct_rate, target=99)\n",
    "bAbi.notes = \"\"\"\n",
    "A synthetic environment inspired by text adventures and SHRDLU, which enables generation\n",
    "of ground truths, describing sentences, and inferential questions. Includes:\n",
    "supporting facts, relations, yes/no questions, counting, lists/sets, negation, indefiniteness,\n",
    "conference, conjunction, time, basic deduction and induction, reasoning about position, size,\n",
    "path finding and motivation.\n",
    "\n",
    "Table 3 of https://arxiv.org/abs/1502.05698 actually breaks this down into 20 submeasures\n",
    "but initially we're lumping all of this together.\n",
    "\n",
    "Originally \"solving\" bABI was defined as 95% accuracy (or perhaps) 95% accuracy on all submeasures,\n",
    "but clearly humans and now algorithms are better than that.\n",
    "\n",
    "TODO: bAbi really needs to be decomposed into semi-supervised and unsupervised variants, and \n",
    "by amount of training data provided\n",
    "\"\"\"\n",
    "bAbi.measure(date(2015,2,19),  93.3, \"MemNN-AM+NG+NL\",  \"https://arxiv.org/abs/1502.05698\")\n",
    "bAbi.measure(date(2015,3,31),  93.4, \"MemN2N-PE+LS+RN\", \"https://arxiv.org/abs/1503.08895\")\n",
    "bAbi.measure(date(2015,6,24),  93.6, \"DMN\",             \"https://arxiv.org/abs/1506.07285\")\n",
    "bAbi.measure(date(2016,1,5),   96.2, \"DNC\",             \"https://www.gwern.net/docs/2016-graves.pdf\")\n",
    "bAbi.measure(date(2016,6,30),  97.2, \"DMN+\",            \"https://arxiv.org/abs/1607.00036\")\n",
    "bAbi.measure(date(2016,9,27),  97.1, \"SDNC\",            \"https://arxiv.org/abs/1606.04582v4\")\n",
    "bAbi.measure(date(2016,12,12), 99.5, \"EntNet\",          \"https://arxiv.org/abs/1612.03969\")\n",
    "bAbi.measure(date(2016,12,9),  99.7, \"QRN\",             \"https://arxiv.org/abs/1606.04582v4\")\n",
    "print \"How is bAbi solved?\", bAbi.solved\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "* * *\n",
    "**_Task completion and average error score for Facebook's BAbI dataset to measure limited question answering. Compiled by Jack._**\n",
    "[Year, failed tasks#, mean error%, paper]\n",
    " \n",
    "[note: a task is defined as failed if error is higher than 5%. Mean error is error across all tasks ]\n",
    "\n",
    "**Why we care about this:** helps us understand how well AI can be trained to deduce facts from a large dataset corpus. \n",
    "(Measurement note - the pathfinding and positional reasoning Qs are much harder for AI than other qs, so watching this perf improve is significant)\n",
    "\n",
    "February, 2015:\n",
    "Failed tasks: 4\n",
    "Mean error: 8%\n",
    "Paper: Towards ai-complete question answering: a set of prerequisite toy tasks \n",
    "Url: https://arxiv.org/abs/1502.05698\n",
    "\n",
    "March, 2015: \n",
    "Failed tasks: 4\n",
    "Mean error: 7.2%\n",
    "(MemNN WSH) 39.2 / 17 < find out what WSH means \n",
    "(Strongly supervised MemNN) 3.2 / 2 \n",
    "Paper: End-to-end memory networks \n",
    "Url: https://arxiv.org/abs/1503.08895\n",
    "\n",
    "June, 2015:\n",
    "Failed tasks: 2\n",
    "Mean error: 6.4%\n",
    "Paper: Ask me anything dynamic memory networks for natural language processing (v1)\n",
    "Url: https://arxiv.org/abs/1506.07285\n",
    "\n",
    "January, 2016: \n",
    "Failed tasks: 2\n",
    "Mean error: 4.3%\n",
    "Paper:  Hybrid computing using a neural network with dynamic external memory\n",
    "Url: http://www.nature.com/nature/journal/v538/n7626/full/nature20101.html#tables\n",
    "\n",
    "June, 2016 \n",
    "Failed tasks: 1\n",
    "Mean error: 2.81%\n",
    "Paper: Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes\n",
    "Url: https://arxiv.org/pdf/1607.00036.pdf\n",
    "\n",
    "2016, October - scaling memory-augmented neural networks with sparse read and writes \n",
    "https://arxiv.org/pdf/1610.09027v1.pdf\n",
    "\n",
    "November, 2016:\n",
    "Failed tasks: 2\n",
    "Mean error: 3.7%\n",
    "Paper: gated end-to-end memory networks\n",
    "Url: https://arxiv.org/pdf/1610.04211.pdf\n",
    "\n",
    "December, 2016: \n",
    "Failed tasks: 0 \n",
    "Mean error: 0.5%\n",
    "Paper:  tracking the world state with recurrent entity networks\n",
    "Url: https://arxiv.org/abs/1612.03969\n",
    "\n",
    "Feb, 2017:\n",
    "Failed tasks: 0\n",
    "Mean error: 0.3%\n",
    "Paper:  Query-Reduction Networks for Question Answering v5 \n",
    "Url: https://arxiv.org/abs/1606.04582\n",
    "\n",
    "\"\"\"\n",
    "(\"How is bAbi solved?\", bAbi.solved)\n",
    "\n",
    "# More papers:\n",
    "# https://www.aclweb.org/anthology/D/D13/D13-1020.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Safety problems!\n",
    "\n",
    "adversarial_examples = Problem(\"Resistance to adversarial examples\", [\"safety\", \"agi\"], url=\"https://arxiv.org/abs/1312.6199\")\n",
    "\n",
    "adversarial_examples.notes = \"\"\"\n",
    "We know that humans have significant resistance to adversarial examples.  Although methods like camouflage sometimes\n",
    "work to fool us into thinking one thing is another, those\n",
    "\"\"\"\n",
    "\n",
    "# This section is essentially on teaching ML systems ethics and morality. Amodei et al call this \"scaleable supervision\".\n",
    "\n",
    "cirl = Problem(\"Cooperative inverse reinforcement learning of objective functions\", [\"safety\", \"agi\"])\n",
    "\n",
    "\n",
    "\n",
    "safe_exploration = Problem(\"Safe exploration\", [\"safety\", \"agi\"])\n",
    "safe_exploration.notes = \"\"\"\n",
    "Sometimes, even doing something once is catastrophic. In such situations, how can an RL agent or some other AI system\n",
    "learn about the catastrophic consequences without even taking the action once?\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Included thus far:\n",
      "=================================\n",
      "15 problems\n",
      "8 metrics\n",
      "30 measurements\n",
      "=================================\n",
      "\n",
      "Problems by Type:\n",
      "=================================\n",
      "agi 13 solved: 1\n",
      "language 4 solved: 1\n",
      "world-modelling 3 solved: 1\n",
      "safety 3 solved: 0\n",
      "abstract-games 5 solved: 1\n",
      "super 1 solved: 0\n",
      "vision 4 solved: 0\n"
     ]
    }
   ],
   "source": [
    "print \"Included thus far:\"\n",
    "print \"=================================\"\n",
    "print len(problems), \"problems\"\n",
    "print len(metrics), \"metrics\"\n",
    "print len(measurements), \"measurements\"\n",
    "print \"=================================\\n\"\n",
    "print \"Problems by Type:\"\n",
    "print \"=================================\"\n",
    "\n",
    "by_attr = {}\n",
    "solved_by_attr = {}\n",
    "for a in all_attributes:\n",
    "    print a, len([p for p in problems.values() if a in p.attributes]), \"solved:\", len([p for p in problems.values() if p.solved and a in p.attributes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TclError",
     "evalue": "couldn't open \"/usr/share/matplotlib/mpl-data/images/matplotlib.gif\": no such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f1a5e765ade1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib_venn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvenn3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mvenn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Language Problems'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'World-Modelling Problems'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Vision Problems'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/matplotlib_venn/_venn3.pyc\u001b[0m in \u001b[0;36mvenn3\u001b[0;34m(subsets, set_labels, set_colors, alpha, normalize_to, ax, subset_label_formatter)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0max\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0mprepare_venn_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mgca\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mgca\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \"\"\"\n\u001b[0;32m--> 828\u001b[0;31m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mgcf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfigManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0mfignum_exists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pylab_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_fignum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mfigure\u001b[0;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m                                         \u001b[0mframeon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                                         \u001b[0mFigureClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFigureClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                                         **kwargs)\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfigLabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/matplotlib/backends/backend_tkagg.pyc\u001b[0m in \u001b[0;36mnew_figure_manager\u001b[0;34m(num, *args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mFigureClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FigureClass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mfigure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFigureClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_figure_manager_given_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/matplotlib/backends/backend_tkagg.pyc\u001b[0m in \u001b[0;36mnew_figure_manager_given_figure\u001b[0;34m(num, figure)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# http://mail.python.org/pipermail/tkinter-discuss/2006-November/000954.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0micon_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datapath'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'matplotlib.gif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0micon_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPhotoImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0micon_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iconphoto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0micon_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/lib-tk/Tkinter.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, cnf, master, **kw)\u001b[0m\n\u001b[1;32m   3373\u001b[0m         \u001b[0mValid\u001b[0m \u001b[0mresource\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3374\u001b[0m         width.\"\"\"\n\u001b[0;32m-> 3375\u001b[0;31m         \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'photo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mblank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3377\u001b[0m         \u001b[0;34m\"\"\"Display a transparent image.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/lib-tk/Tkinter.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, imgtype, name, cnf, master, **kw)\u001b[0m\n\u001b[1;32m   3327\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3328\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3329\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'create'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTclError\u001b[0m: couldn't open \"/usr/share/matplotlib/mpl-data/images/matplotlib.gif\": no such file or directory"
     ]
    }
   ],
   "source": [
    "lang = set(p for p in problems.values() if \"language\" in p.attributes)\n",
    "world = set(p for p in problems.values() if \"world-modelling\" in p.attributes)\n",
    "vision = set(p for p in problems.values() if \"vision\" in p.attributes)\n",
    "\n",
    "from matplotlib_venn import venn3\n",
    "venn3((lang, world, vision), ('Language Problems', 'World-Modelling Problems', 'Vision Problems'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
