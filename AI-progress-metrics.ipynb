{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A notebook for organising AI progress metrics\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "# We have the following structures:\n",
    "#\n",
    "# problem \n",
    "#     \\   \\\n",
    "#      \\   metrics  -  measures \n",
    "#       \\\n",
    "#        - subproblems\n",
    "#             \\\n",
    "#           metrics\n",
    "#              \\\n",
    "#             measures\n",
    "#\n",
    "# problems are tagged with attributes:\n",
    "# eg, vision, abstract-games, language, world-modelling, safety\n",
    "#     agi       -- most capable humans can do this, so AGIs can do this\n",
    "#     super     -- the very best humans can do this, or human organisations have solved this\n",
    "#     verysuper -- neither humans nor human orgs have solved this\n",
    "#\n",
    "# problems can have \"subproblems\", including simpler cases and preconditions\n",
    "\n",
    "class Problem:\n",
    "    def __init__(self, name, attributes=[], solved=False):\n",
    "        self.name = name\n",
    "        self.attributes = attributes\n",
    "        self.subproblems = []\n",
    "        self.superproblems = []\n",
    "        self.metrics = []\n",
    "        \n",
    "    def subproblem(self, other_problem):\n",
    "        self.superproblems.append(other_problem)\n",
    "        other_problem.subproblems.append(self)\n",
    "        \n",
    "    def metric(self, *args, **kwargs):\n",
    "        m = Metric(*args, **kwargs)\n",
    "        self.metrics.append(m)\n",
    "        return m\n",
    "\n",
    "class Metric:\n",
    "    def __init__(self, name, url=None, solved=False, notes=\"\"):\n",
    "        self.name = name\n",
    "        self.measures = []\n",
    "        self.solved = solved\n",
    "        self.url = url\n",
    "        self.notes = notes\n",
    "        \n",
    "    def measure(self, *args, **kwargs):\n",
    "        m = Measurement(*args, **kwargs)\n",
    "        self.measures.append(m)\n",
    "        # Add logic for detection solutions at this point\n",
    "        return m\n",
    "        \n",
    "class Measurement:\n",
    "    def __init__(self, date, value, name, url):\n",
    "        self.date = date\n",
    "        self.value = value\n",
    "        self.name = name\n",
    "        self.url = url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BEGIN ACTUALLY CLASSIFYING PROBLEMS\n",
    "\n",
    "scene_description = Problem(\"Scene description\", [\"agi\", \"vision\", \"language\", \"world-modelling\"])\n",
    "image_classification = Problem(\"Image classification\", [\"vision\", \"agi\"])\n",
    "scene_description.subproblem(image_classification)\n",
    "\n",
    "imagenet = image_classification.metric(\"imagenet\", \"http://image-net.org\")\n",
    "imagenet.notes = \"\"\"\n",
    "Correctly label images from the Imagenet dataset. As of 2016, this includes:\n",
    " - Object localization for 1000 categories.\n",
    " - Object detection for 200 fully labeled categories.\n",
    " - Object detection from video for 30 fully labeled categories.\n",
    " - Scene classification for 365 scene categories (Joint with MIT Places team) on Places2 Database http://places2.csail.mit.edu.\n",
    " - Scene parsing for 150 stuff and discrete object categories (Joint with MIT Places team).\n",
    "WARNING: these subchallenges were added in successive years of the Imagenet challenge, so results from years are not directly\n",
    "comparable; however progress should probably be understated by comparing them?\n",
    "\"\"\"\n",
    "imagenet.measure(date(2010,8,31), 0.28191, \"NEC UIUC\", \"http://image-net.org/challenges/LSVRC/2010/results\")\n",
    "\"\"\"\n",
    "** 2010: 0.28191**\n",
    "**NEC UIUC**\n",
    "http://image-net.org/challenges/LSVRC/2010/results\n",
    "\n",
    "** 2011: 0.25770\n",
    " XRCE**\n",
    "\n",
    "** 2012: 0.16422**\n",
    "** Supervision**\n",
    "http://image-net.org/challenges/LSVRC/2012/results.html\n",
    "\n",
    "** 2013: 0.11743 **\n",
    "**Clarifai**\n",
    "http://www.image-net.org/challenges/LSVRC/2013/results.php\n",
    "\n",
    "** 2014: 0.07405**\n",
    "**VGG**\n",
    "http://image-net.org/challenges/LSVRC/2014/index\n",
    " \n",
    "\n",
    "**2015: 0.03567**\n",
    "**MSRA**\n",
    "http://image-net.org/challenges/LSVRC/2015/results\n",
    "\n",
    "** 2016: 0.02991**\n",
    "**Trimps-Soushen**\n",
    "http://image-net.org/challenges/LSVRC/2016/results\n",
    "* * *\n",
    "\"\"\"\n",
    "None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
