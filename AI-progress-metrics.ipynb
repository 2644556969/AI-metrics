{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# A notebook for organising AI progress metrics\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "# We have the following structures:\n",
    "#\n",
    "# problem \n",
    "#     \\   \\\n",
    "#      \\   metrics  -  measures \n",
    "#       \\\n",
    "#        - subproblems\n",
    "#             \\\n",
    "#           metrics\n",
    "#              \\\n",
    "#             measures\n",
    "#\n",
    "# problems are tagged with attributes:\n",
    "# eg, vision, abstract-games, language, world-modelling, safety\n",
    "#     agi       -- most capable humans can do this, so AGIs can do this\n",
    "#     super     -- the very best humans can do this, or human organisations have solved this\n",
    "#     verysuper -- neither humans nor human orgs have solved this\n",
    "#\n",
    "# problems can have \"subproblems\", including simpler cases and preconditions\n",
    "#\n",
    "# a \"metric\" is one way of measuring progress on a problem. There will often be several metrics\n",
    "# for a given problem, but in some cases we'll start out with zero metrics and will need to start\n",
    "# proposing some...\n",
    "#\n",
    "# a measure[ment] is a score on a given metric, by a particular codebase/team/project, at a particular\n",
    "# time\n",
    "\n",
    "class Problem:\n",
    "    def __init__(self, name, attributes=[], solved=False):\n",
    "        self.name = name\n",
    "        self.attributes = attributes\n",
    "        self.subproblems = []\n",
    "        self.superproblems = []\n",
    "        self.metrics = []\n",
    "        self.solved = solved\n",
    "        \n",
    "    def subproblem(self, other_problem):\n",
    "        self.superproblems.append(other_problem)\n",
    "        other_problem.subproblems.append(self)\n",
    "        \n",
    "    def metric(self, *args, **kwargs):\n",
    "        m = Metric(*args, **kwargs)\n",
    "        self.metrics.append(m)\n",
    "        return m\n",
    "\n",
    "\n",
    "# Different metrics and measurements for progress are made on very different types of scales\n",
    "# we have some helper functions to regularise these a little bit, so we can tell (for instance)\n",
    "# whether progress on some metric appears to be accelerating or decelerating.\n",
    "\n",
    "# Interface:\n",
    "#    improvement(score1, score2): retrns a consistent measure of how much better score2 is than score1\n",
    "#    pseudolinear(score): returns a modified version of score where we would expect vaguely linear progress\n",
    "\n",
    "class Linear:\n",
    "    def improvement(self, score1, score2):\n",
    "        return score2 - score1\n",
    "    def pseudolinear(self, score):\n",
    "        return score\n",
    "linear = Linear()\n",
    "\n",
    "class ELO:\n",
    "    def improvement(self, score1, score2):\n",
    "        \"\"\"\n",
    "        Normalise an ELO score\n",
    "        \n",
    "        An ELO increase of 400 improves your odds by 10x, so we could justify something like\n",
    "        return 10.0 ** ((score2 - score1)/400.)\n",
    "        However, it seems that at least for chess ELO progress has been roughly linear over\n",
    "        time, both for humans and computers (though with different coefficients). Perhaps this\n",
    "        tracks exponential increases in ability to search the game's state space, driven directly\n",
    "        by Moore's law on the computer side, and indirectly for humans by access to better training\n",
    "        tools and more profound libraries of past play.\n",
    "        \n",
    "        So for now let's treat this as linear? But ELO is not a chess-specific measure, and in other\n",
    "        contexts we may want to do exponentiation as documented above?\n",
    "        \"\"\"\n",
    "        return score2 - score1\n",
    "    def pseudolinear(self, score):\n",
    "        return score\n",
    "    \n",
    "elo = ELO()\n",
    "\n",
    "class ErrorRate:\n",
    "    \"\"\"Many labelling contests use these measures\"\"\"\n",
    "    def improvement(self, score1, score2):\n",
    "        # 0.5 / 0.25\n",
    "        return score1 / score2\n",
    "    def pseudolinear(self, score):\n",
    "        # The choice of base here is arbitrary. But since this is computer science, let's use base2!\n",
    "        from math import log\n",
    "        return log(score) / log(2.0)\n",
    "error_rate = ErrorRate()\n",
    "    \n",
    "class Metric:\n",
    "    def __init__(self, name, url=None, solved=False, notes=\"\", scale=linear):\n",
    "        self.name = name\n",
    "        self.measures = []\n",
    "        self.solved = solved\n",
    "        self.url = url\n",
    "        self.notes = notes\n",
    "        self.scale = scale\n",
    "        \n",
    "    def measure(self, *args, **kwargs):\n",
    "        m = Measurement(*args, **kwargs)\n",
    "        self.measures.append(m)\n",
    "        # Add logic for detection solutions at this point\n",
    "        return m\n",
    "\n",
    "\n",
    "class Measurement:\n",
    "    def __init__(self, date, value, name, url, uncertainty=0, minval=None, maxval=None):\n",
    "        self.date = date\n",
    "        self.value = value\n",
    "        self.name = name\n",
    "        self.url = url\n",
    "        self.minval = minval if minval else value - uncertainty\n",
    "        self.maxval = maxval if maxval else value + uncertainty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Sources to incorporate\n",
    "\n",
    "* Jack Clark's collection of progress measurements (elsewhere in this repo, partially imported)\n",
    "* Sarah Constantin's [Performance Trends in AI](https://srconstantin.wordpress.com/2017/01/28/performance-trends-in-ai/)\n",
    "* Katja Grace's [Algorithmic Progress in Six Domains](https://intelligence.org/files/AlgorithmicProgress.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# BEGIN ACTUALLY CLASSIFYING PROBLEMS\n",
    "\n",
    "scene_description = Problem(\"Scene description\", [\"agi\", \"vision\", \"language\", \"world-modelling\"])\n",
    "image_classification = Problem(\"Image classification\", [\"vision\", \"agi\"])\n",
    "scene_description.subproblem(image_classification)\n",
    "\n",
    "imagenet = image_classification.metric(\"imagenet\", \"http://image-net.org\", scale=error_rate)\n",
    "imagenet.notes = \"\"\"\n",
    "Correctly label images from the Imagenet dataset. As of 2016, this includes:\n",
    " - Object localization for 1000 categories.\n",
    " - Object detection for 200 fully labeled categories.\n",
    " - Object detection from video for 30 fully labeled categories.\n",
    " - Scene classification for 365 scene categories (Joint with MIT Places team) on Places2 Database http://places2.csail.mit.edu.\n",
    " - Scene parsing for 150 stuff and discrete object categories (Joint with MIT Places team).\n",
    "WARNING: these subchallenges were added in successive years of the Imagenet challenge, so results from years are not directly\n",
    "comparable; however progress should probably be understated by comparing them?\n",
    "\"\"\"\n",
    "\n",
    "# Data points gathered by Jack Clark:\n",
    "imagenet.measure(date(2010,8,31), 0.28191, \"NEC UIUC\", \"http://image-net.org/challenges/LSVRC/2010/results\")\n",
    "\"\"\"\n",
    "** 2010: 0.28191**\n",
    "**NEC UIUC**\n",
    "http://image-net.org/challenges/LSVRC/2010/results\n",
    "\n",
    "** 2011: 0.25770\n",
    " XRCE**\n",
    "\n",
    "** 2012: 0.16422**\n",
    "** Supervision**\n",
    "http://image-net.org/challenges/LSVRC/2012/results.html\n",
    "\n",
    "** 2013: 0.11743 **\n",
    "**Clarifai**\n",
    "http://www.image-net.org/challenges/LSVRC/2013/results.php\n",
    "\n",
    "** 2014: 0.07405**\n",
    "**VGG**\n",
    "http://image-net.org/challenges/LSVRC/2014/index\n",
    " \n",
    "\n",
    "**2015: 0.03567**\n",
    "**MSRA**\n",
    "http://image-net.org/challenges/LSVRC/2015/results\n",
    "\n",
    "** 2016: 0.02991**\n",
    "**Trimps-Soushen**\n",
    "http://image-net.org/challenges/LSVRC/2016/results\n",
    "* * *\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Abstract games like chess, go, checkers etc can be played with no knowldege of the human world\n",
    "# Although this domain has largely been solved to super-human performance levels, there are a\n",
    "# few ends that need to be completed in terms of having agents learn rules for arbitrary \n",
    "# abstract games effectively\n",
    "\n",
    "abstract_strategy_games = Problem(\"Abstract strategy games\", [\"agi\", \"abstract-games\"])\n",
    "\n",
    "playing_with_hints = Problem(\"Playing abstract games with extensive hints\", [\"abstract-games\"], solved=True)\n",
    "playing_with_hints.notes = \"\"\"\n",
    "  Complex abstract strategy games have been solved to super-human levels\n",
    "  by computer systems with extensive rule-hinting and heuristics,\n",
    "  in some cases combined with machine learning techniques.\n",
    "\"\"\"\n",
    "computer_chess = playing_with_hints.metric(\"computer chess\", scale=elo)\n",
    "# For some caveats, see https://en.wikipedia.org/w/index.php?title=Chess_engine&oldid=764341963#Ratings\n",
    "computer_chess.measure(date(2017,02,27), 3393, \"Stockfish\", uncertainty=50,\n",
    "                           url=\"https://web.archive.org/web/20170227044521/http://www.computerchess.org.uk/ccrl/4040/\")\n",
    "computer_chess.measure(date(1997,05,11), 2725, \"Deep Blue\", uncertainty=25,\n",
    "                           url=\"https://www.quora.com/What-was-Deep-Blues-Elo-rating\")\n",
    "\n",
    "mastering_historical_games = Problem(\"Mastering human abstract strategy games\", [\"super\", \"abstract-games\"])\n",
    "mastering_chess = mastering_historical_games.metric(\"mastering chess\")\n",
    "mastering_chess.notes = \"\"\"\n",
    "  Beating all humans at chess, given a corpus of past play amongst masters,\n",
    "  but no human-crafted policy constraints and heuristics. This will probably fall out\n",
    "  immediately once learning_abstract_game_rules is solved, since playing_with_hints\n",
    "  has been solved.\n",
    "\"\"\"\n",
    "\n",
    "# Are there any published metrics for these yet?\n",
    "learning_abstract_game_rules = Problem(\"Learning the rules of complex strategy games from examples\", [\"agi\", \"abstract-games\"])\n",
    "learning_chess = learning_abstract_game_rules.metric(\"learning chess\")\n",
    "learning_chess.notes = \"\"\"\n",
    "  Chess software contains hard-coded policy constraints for valid play; this metric is whether RL\n",
    "  or other agents can correctly build those policy constraints from examples or oracles\"\"\"\n",
    "learning_go = learning_abstract_game_rules.metric(\"learning go\")\n",
    "learning_go.notes = \"\"\"\n",
    "  Go software contains policy constraints for valid play and evaluating the number of\n",
    "  liberties for groups. This metric is whether RL or other agents can correctly build those \n",
    "  policy constraints from examples or oracles\"\"\"\n",
    "learning_arbitrary_abstract_games = Problem(\"Play an arbitrary abstract game, first learning the rules\", [\"agi\", \"abstract-games\"])\n",
    "                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Speech recognition\n",
    "\n",
    "\"\"\"\n",
    "        http://melodi.ee.washington.edu/s3tp/\n",
    "\n",
    "* * *\n",
    "**_Word error rate on Switchboard (specify details): [Month, Year: Score [SWB]: Team].  Compiled by Jack Clark._**\n",
    "\n",
    "A note about measurement: We're measuring Switchboard (SWB) and Call Home (CH) performance from the Hub5'00 dataset, with main scores assesses in terms of word error rate on SWB. We also create \n",
    "\n",
    "Why do we care: Reflects the improvement of audio processing systems on speech over time.\n",
    "\n",
    "**2011 16.1%: Microsoft**\n",
    "16.1% SWB\n",
    "Who: Microsoft\n",
    "Technique: Microsoft: CD-DNN (Context Dependent Deep Neural Network)\n",
    "\n",
    "Paper: Conversational Speech Transcription Using Context-Dependent Neural Networks \n",
    "Url: https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/CD-DNN-HMM-SWB-Interspeech2011-Pub.pdf\n",
    "\n",
    "**2012:**\n",
    "\n",
    "**April, 2012: 18.5%: University of Toronto, Google, IBM< Microsoft**\n",
    "Who: University of Toronto, Google, IBM, Microsoft\n",
    "\n",
    "Paper: Deep Neural Networks for Acoustic Modeling in Speech Recognition\n",
    "Url: https://pdfs.semanticscholar.org/ce25/00257fda92338ec0a117bea1dbc0381d7c73.pdf?_ga=1.195375081.452266805.1483390947\n",
    "\n",
    "**2013:**\n",
    "\n",
    "**2013: 12.9%: Consortium of Universities**\n",
    "12.9% SWB, 24.5% CH, 18.7% \n",
    "Who: Brno University of Tech / University of Edinburgh / Johns Hopkins\n",
    "Technique: DNN BMMI  (deep neural network boosted minimum mutual information) \n",
    "\n",
    "Paper: Sequence discriniative training of deep neural networks \n",
    "Url: http://www.danielpovey.com/files/2013_interspeech_dnn.pdf\n",
    "\n",
    "\n",
    "**2014:**\n",
    "\n",
    "**June, 2014: 16.0%: Stanford**\n",
    "16.0% SWB, 23.7% CH, 19.9% EV\n",
    "Who: Stanford\n",
    "\n",
    "Paper: Increasing Deep Neural Network Acoustic Model Size For Large Vocabulary Continuous Speech Recognition\n",
    "\n",
    "Url: https://arxiv.org/abs/1406.7806v1\n",
    "\n",
    "**December, 2014: 12.6%: Baidu**\n",
    "Deep Speech SWB: 20.0% SWB, 31.8% CH, 25.9% blended.\n",
    "Deep Speech SWB + FSH: 12.6% SWB, 19.3% CH, 16.0% blended.\n",
    "\n",
    "Who: Baidu\n",
    "\n",
    "Paper: Deep Speech: Scaling up end-to-end speech recognition\n",
    "Url: https://arxiv.org/abs/1412.5567\n",
    "\n",
    "**2015:**\n",
    "\n",
    "**May, 2015: 8%: IBM**\n",
    "8.0% SWB, 14.1% CH, 11.0% blended.\n",
    "Who: IBM\n",
    "\n",
    "Paper: The IBM 2015 English Conversational Telephone Speech Recognition System\n",
    "Url: https://arxiv.org/abs/1505.05899\n",
    "\n",
    "**2016: **\n",
    "\n",
    "**June, 2016: 6.9%: IBM**\n",
    "n-gram + model M + NNLM: 6.9% SWB, 12.5% CH, 9.7% blended.\n",
    "\n",
    "Who: IBM\n",
    "Paper: The IBM 2016 English Conversational Telephone Speech Recognition System\n",
    "\n",
    "Url: https://arxiv.org/abs/1604.08242v1\n",
    "\n",
    "**September, 2016: 6.2%: Microsoft**\n",
    "Single model (ResNet): 6.9% SWB, 13.2% CH, 10.05% blended.\n",
    "Combination: 6.2% SWB, 12.0% CH, 9.1% blended \n",
    "\n",
    "Who: Microsoft\n",
    "Paper: The Microsoft 2016 Conversational Speech Recognition System\n",
    "Url: https://arxiv.org/abs/1609.03528\n",
    "\n",
    "**October 2016: 5.9%: Microsoft**\n",
    "Single model (ResNet): 6.6% SWB, 12.5% CH, 9.55% blended. \n",
    "Combination: 5.9% SWB, 11.1% CH, 8.5% blended.\n",
    "\n",
    "Who: Microsoft\n",
    "Paper: Achieving human parity in conversational speech recognition\n",
    "Url: https://arxiv.org/abs/1610.05256\n",
    "* * *\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Image Generation\n",
    "\n",
    "\"\"\" \n",
    "* * *\n",
    "**_Generative models of CIFAR-10 Natural Images _****[Year: bits-per-subpixel, method]. Compiled by Durk Kingma.**\n",
    "\n",
    "**Why we care:**\n",
    "(1) The compression=prediction=understanding=intelligence view (see Hutter prize, etc.). (Note that perplexity, log-likelihood, and #bits are all equivalent measurements.)\n",
    "(2) Learning a generative model is a prominent auxiliary task towards semi-supervised learning. Current SOTA semi-supervised classification results utilize generative models.\n",
    "3) You're finding patterns in the data that let you compress it more efficiently. Ultimate pattern recognition benchmark because you're trying to find the patterns in all the data. \n",
    "\n",
    "**2014: 4.48**\n",
    "Method: NICE\n",
    "\n",
    "Paper: NICE: Non-linear independent components estimation. \n",
    "arXiv preprint arXiv:1410.8516, 2014.\n",
    "\n",
    "**2015: 4.13**\n",
    "Method: DRAW\n",
    "\n",
    "Paper: Draw: A recurrent neural network for image generation.\n",
    " In International Confer- ence on Machine Learing (ICML), 2015.\n",
    "\n",
    "**2016: 3.49**\n",
    "Method: Real NVP\n",
    "\n",
    "Paper: Density estimation using real NVP. \n",
    "arXiv:1605.08803, 2016.\n",
    "\n",
    "**2016: 3.11**\n",
    "Method: VAE with IAF\n",
    "\n",
    "Paper: Improving variational inference with inverse autoregressive flow. \n",
    "Conference on Neural Information Processing Systems (NIPS), 2016.\n",
    "\n",
    "**2016: 3**\n",
    "Method: PixelRNN\n",
    "\n",
    "Paper: Density estimation using real NVP. \n",
    "arXiv:1605.08803, 2016. arXiv preprint arXiv:1605.08803, 2016.\n",
    "\n",
    "**2016: 2.92**\n",
    "Method: PixelCNN++\n",
    "\n",
    "Paper: PixelCNN++: A PixelCNN implementation with discretized logistic mixture likelihood and other modifications. \n",
    "URL: https://openreview.net/forum?id=BJrFC6ceg, 2016.\n",
    "\"\"\"\n",
    "\n",
    "image_generation = Problem(\"Generative models of CIFAR-10 Natural Images\", [\"vision\"])\n",
    "scene_generation = Problem(\"Be able to generate complex scene e.g. a baboon receiving their degree at convocatoin.\", [\"vision\", \"world-modelling\"])\n",
    "scene_generation.subproblem(image_generation)\n",
    "\n",
    "#image_generation.metric(\"\", \"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
